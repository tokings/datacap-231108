{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"DataCap","text":"DataCap is integrated software for data transformation, integration, and visualization. Support a variety of data sources, file types, big data related database, relational database, NoSQL database, etc. Through the software can realize the management of multiple data sources, the data under the source of various operations conversion, making data charts, monitoring data sources and other functions.               Get Started             Download             Join Us On GitHub             View online examples"},{"location":"index.html#overview","title":"Overview","text":"<p> Datacap is fast, lightweight, intuitive system. </p> <ul> <li> <p>Powerful yet easy to use </p> <p>Quickly and easily integrate and explore your data, using simple SQL IDE.</p> </li> <li> <p>Integrates with modern databases</p> <p>DataCap can connect to any SQL based datasource through JDBC and Native and Http.</p> </li> <li> <p>Highly Customizable</p> <p>DataCap can quickly connect to new data sources by implementing the methods provided by SPI.</p> </li> <li> <p>Join (DingTalk \uff5c WeChat)</p> <p> </p> </li> </ul>"},{"location":"index.html#supported-connectors","title":"Supported Connectors","text":""},{"location":"download.html","title":"Download","text":"The current datacap release is version . Learn more details from the release notes.  <ul> <li> <p> Server packages</p> <p>Utilize the <code>.tar.gz</code> package to manually deploy. See Installation datacap for complete install instructions.</p> <p></p> <p>datacap-server-1.16.0.tar.gz</p> </li> <li> <p> Command line client</p> <p>You can run queries using the interactive command line interface.</p> <p></p> <p>datacap-client-cli-1.16.0.jar</p> </li> <li> <p> More package</p> <p>See The source code to install for complete install instructions.</p> <p></p> <p>Source Code</p> </li> </ul> <ul> <li> <p>Community resources</p> <ul> <li>Chat On Slack: edurtio.slack.com</li> <li>Issues: GitHub issues</li> <li>DingTalk: 16160001608</li> </ul> </li> <li> <p>Getting help</p> <p>If you need help using or running dbm, please ask a question on Slack. Please report any issue you find with dbm.</p> </li> </ul>"},{"location":"powered_by.html","title":"Use cases","text":"Add Your or Company <p>Note</p> <p>There are many companies, individuals and open source organizations that use this program. Some of them are listed below.</p>"},{"location":"powered_by.html#open-project","title":"Open Project","text":"<ul> <li> <p> DataCap developer</p> <p>DataCap is integrated software for data transformation, integration and visualization.   Getting started</p> </li> </ul>"},{"location":"powered_by.html#personal-user","title":"Personal user","text":"<ul> <li> <p> qianmoQ</p> <p>Source code contributors who love open source projects.  Visit qianmoQ</p> </li> <li> <p> Stacey1018</p> <p>I can make it through the rain. I can stand up once again on my own.  Visit Stacey1018</p> </li> </ul>"},{"location":"developer_guide/env.html","title":"Development environment","text":"<p>The development environment is mainly divided into two services and a document module. The following is a detailed description of the construction of each service environment.</p> <p>Warning</p> <p>Before development, please import the format files of the code into the editor, they are in the <code>configure</code> directory</p>"},{"location":"developer_guide/env.html#server","title":"Server","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment","title":"Depends on the environment","text":"Environment Version Required <code>JDK</code> &gt;= 1.8 Need <code>Maven</code> &gt;= 3.5 Optional"},{"location":"developer_guide/env.html#source-code-preparation","title":"Source code preparation","text":"<p>Fork the code in the code warehouse and clone the code to the local, enter the source code directory</p> <pre><code>git clone git@github.com:&lt;GitHubUser&gt;/datacap.git\n</code></pre>"},{"location":"developer_guide/env.html#load-source-code","title":"Load source code","text":"<p>Open idea to load the project</p> <p></p> <p>After opening the project, the right menu displays the project directory</p> <p></p> <ul> <li><code>configure</code> Some configurations used by the project</li> <li><code>dist</code> Binary file storage path after the project is packaged</li> <li><code>docs</code> Project Documentation Source Code</li> <li><code>plugin</code> Project plug-in source code</li> <li><code>server</code> Project main service source code</li> <li><code>spi</code> Project plug-in integration core source code</li> <li><code>web</code> Project web front-end source code</li> </ul>"},{"location":"developer_guide/env.html#service-start","title":"Service start","text":"<p>Service startup needs to modify the specified configuration file directory</p> <p></p> <p>Add <code>--spring.config.location=</code> configuration in <code>Program arguments</code></p> <p>The content of the configuration file is the current project startup service configuration, and the configuration source code is in <code>server/src/main/etc/conf</code></p> <p>After the service is configured, it can be started. After the service is started, access <code>http://localhost:9096/</code></p>"},{"location":"developer_guide/env.html#web","title":"Web","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment_1","title":"Depends on the environment","text":"Environment Version Required <code>Node</code> &gt;= v16.x Need <code>Npm</code> &gt;= 7.x Need <p><code>console-fe</code> The web front-end source code is in this directory</p>"},{"location":"developer_guide/env.html#service-start_1","title":"Service start","text":"<ul> <li>Go to the source code directory</li> </ul> <pre><code>cd web/console-fe\n</code></pre> <ul> <li>Start service</li> </ul> <pre><code>yarn run dev\n</code></pre> <p>After the command is executed, the source code will be compiled, and something similar to the following will appear after compilation</p> <pre><code>...\nUse /* eslint-disable */ to ignore all warnings in a file.\n\nApp running at:\n- Local:   http://localhost:8080/ \n- Network: http://192.168.32.53:8080/\n\nNote that the development build is not optimized.\nTo create a production build, run yarn build.\n\nNo issues found.\n</code></pre> <p>Access <code>http://localhost:8080</code> through a browser to debug the source code, do not use the address returned by <code>Network</code></p>"},{"location":"developer_guide/env.html#docs","title":"Docs","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment_2","title":"Depends on the environment","text":"Environment Version Required <code>mkdocs</code> &gt;= 1.3.0 Need <p><code>docs/docs</code> Document source code is in this directory</p>"},{"location":"developer_guide/env.html#service-start_2","title":"Service start","text":"<ul> <li>Go to the source code directory</li> </ul> <pre><code>cd docs\n</code></pre> <ul> <li>Start service</li> </ul> <pre><code>mkdocs serve --dev-addr=0.0.0.0:8001\n</code></pre> <p>After the command is executed, the source code will be compiled, and something similar to the following will appear after compilation</p> <pre><code>...\nINFO     -  Documentation built in 1.07 seconds\nINFO     -  [13:16:03] Watching paths for changes: 'docs', 'mkdocs.yml'\nINFO     -  [13:16:03] Serving on http://0.0.0.0:8001/\nINFO     -  [13:16:03] Browser connected: http://0.0.0.0:8001/developer_guide/env.html\n</code></pre> <p>Access <code>http://0.0.0.0:8001</code> through a browser to debug the source code</p>"},{"location":"developer_guide/plugin-java.html","title":"Java Implementation","text":"<p>DataCap supports custom plug-ins, and users can write their own plug-ins and integrate them into the system. This document mainly explains how to quickly integrate a plug-in into the DataCap system.</p> <p>Note</p> <p>This article demonstrates by integrating the QuestDB data storage system based on the HTTP protocol.</p>"},{"location":"developer_guide/plugin-java.html#pomxml-depend","title":"<code>pom.xml</code> Depend","text":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-spi&lt;/artifactId&gt;\n    &lt;scope&gt;provided&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-common&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;commons-beanutils&lt;/groupId&gt;\n    &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.testcontainers&lt;/groupId&gt;\n    &lt;artifactId&gt;testcontainers&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>The above configuration adds <code>datacap-spi</code> and <code>datacap-common</code> modules, and others are some auxiliary dependencies.</p> <p>Warning</p> <p>It should be noted that if you open the project separately, you need to specify the version number of each dependency.</p>"},{"location":"developer_guide/plugin-java.html#plugin-loader","title":"Plugin Loader","text":"<pre><code>public class QuestDBPluginModule\n        extends AbstractPluginModule\n        implements PluginModule\n{\n    @Override\n    public String getName()\n    {\n        return \"QuestDB\";\n    }\n\n    @Override\n    public PluginType getType()\n    {\n        return PluginType.HTTP;\n    }\n\n    @Override\n    public AbstractPluginModule get()\n    {\n        return this;\n    }\n\n    protected void configure()\n    {\n        Multibinder&lt;Plugin&gt; plugin = Multibinder.newSetBinder(this.binder(), Plugin.class);\n        plugin.addBinding().to(QuestDBPlugin.class);\n    }\n}\n</code></pre> <p>The loader needs to inherit the <code>AbstractPluginModule</code> class and implement the <code>PluginModule</code> interface, so that the system will automatically load the plug-in into the system when it starts.</p> <p>Note</p> <p>It should be noted that you need to override the <code>configure()</code> method in the parent class and bind the plugin to the system.</p>"},{"location":"developer_guide/plugin-java.html#plugin-executor","title":"Plugin Executor","text":"<pre><code>@Slf4j\npublic class QuestDBPlugin\n        implements Plugin\n{\n    private HttpConfigure configure;\n    private HttpConnection connection;\n    private Response response;\n\n    @Override\n    public String name()\n    {\n        return \"QuestDB\";\n    }\n\n    @Override\n    public String description()\n    {\n        return \"Integrate QuestDB data sources\";\n    }\n\n    @Override\n    public PluginType type()\n    {\n        return PluginType.HTTP;\n    }\n\n    @Override\n    public void connect(Configure configure)\n    {\n        try {\n            this.response = new Response();\n            this.configure = new HttpConfigure();\n            BeanUtils.copyProperties(this.configure, configure);\n            this.connection = new HttpConnection(this.configure, this.response);\n        }\n        catch (Exception ex) {\n            this.response.setIsConnected(Boolean.FALSE);\n            this.response.setMessage(ex.getMessage());\n        }\n    }\n\n    @Override\n    public Response execute(String content)\n    {\n        if (ObjectUtils.isNotEmpty(this.connection)) {\n            log.info(\"Execute questdb plugin logic started\");\n            this.response = this.connection.getResponse();\n            QuestDBAdapter processor = new QuestDBAdapter(this.connection);\n            this.response = processor.handlerExecute(content);\n            log.info(\"Execute questdb plugin logic end\");\n        }\n        this.destroy();\n        return this.response;\n    }\n\n    @Override\n    public void destroy()\n    {\n        if (ObjectUtils.isNotEmpty(this.connection)) {\n            this.connection.destroy();\n        }\n    }\n}\n</code></pre> <p>The executor needs to implement the <code>Plugin</code> interface, which provides the following methods</p> <ul> <li><code>name()</code>: Plugins have unique names, and plugins with the same name will only take effect the first time they are loaded</li> <li><code>description()</code>: A description of the plugin</li> <li><code>type()</code>: Plugin type</li> <li><code>connect(Configure configure)</code>: Plug-ins need connection information in advance, such as the current plug-in plug-in, which is the connection phase of the plug-in (the system presets the HTTP connection method to be used directly).</li> <li><code>execute(String content)</code>: Execute the operation logic</li> <li><code>destroy()</code>:  The final destruction of the plug-in, note that the destruction needs to contain the information in the connection</li> </ul>"},{"location":"developer_guide/plugin-java.html#plugin-converter","title":"Plugin Converter","text":"<pre><code>@Slf4j\npublic class QuestDBAdapter\n        extends HttpAdapter\n{\n    public QuestDBAdapter(HttpConnection connection)\n    {\n        super(connection);\n    }\n\n    @Override\n    public Response handlerExecute(String content)\n    {\n        Time processorTime = new Time();\n        processorTime.setStart(new Date().getTime());\n        Response response = this.httpConnection.getResponse();\n        HttpConfigure configure = new HttpConfigure();\n        if (response.getIsConnected()) {\n            List&lt;String&gt; headers = new ArrayList&lt;&gt;();\n            List&lt;String&gt; types = new ArrayList&lt;&gt;();\n            List&lt;Object&gt; columns = new ArrayList&lt;&gt;();\n            try {\n                BeanUtils.copyProperties(configure, this.httpConnection.getConfigure());\n                configure.setAutoConnected(Boolean.FALSE);\n                configure.setRetry(0);\n                configure.setMethod(HttpMethod.GET);\n                configure.setPath(\"exec\");\n                Map&lt;String, String&gt; parameters = Maps.newHashMap();\n                parameters.put(\"query\", content);\n                configure.setParams(parameters);\n                configure.setDecoded(true);\n                HttpConnection httpConnection = new HttpConnection(configure, new Response());\n                HttpClient httpClient = HttpClient.getInstance(configure, httpConnection);\n                String body = httpClient.execute();\n                QuestDBResponse requestResponse = JSON.objectmapper.readValue(body, QuestDBResponse.class);\n                if (ObjectUtils.isNotEmpty(requestResponse.getQuery())) {\n                    response.setIsSuccessful(true);\n                    if (ObjectUtils.isNotEmpty(requestResponse.getColumns())) {\n                        requestResponse.getColumns()\n                                .forEach(schema -&gt; {\n                                    headers.add(schema.getName());\n                                    types.add(schema.getType());\n                                });\n                    }\n                    requestResponse.getDataset()\n                            .forEach(record -&gt; columns.add(handlerFormatter(configure.getFormat(), headers, record)));\n                }\n                else {\n                    response.setIsSuccessful(Boolean.FALSE);\n                    response.setMessage(requestResponse.getError());\n                }\n            }\n            catch (Exception ex) {\n                log.error(\"Execute content failed content {} exception \", content, ex);\n                response.setIsSuccessful(Boolean.FALSE);\n                response.setMessage(ex.getMessage());\n            }\n            finally {\n                response.setHeaders(headers);\n                response.setTypes(types);\n                response.setColumns(columns);\n            }\n        }\n        processorTime.setEnd(new Date().getTime());\n        response.setProcessor(processorTime);\n        return response;\n    }\n}\n</code></pre> <p>The plug-in converter is used to convert the result after the current plug-in is executed, and convert it into logic that can be used in DataCap. It is mainly used to encapsulate <code>Response</code> to return the result.</p> <p>This article is a JDBC-based plug-in, so some functions can be realized by directly inheriting the <code>HttpAdapter</code> parent class.</p>"},{"location":"developer_guide/plugin-java.html#spi-loader","title":"SPI loader","text":"<p>Add <code>META-INF</code> and <code>services</code> directory under <code>resources</code> source directory</p> <p>Warning</p> <p><code>services</code> needs to be in the <code>resources</code> directory</p> <p>Create the <code>io.edurt.datacap.spi.PluginModule</code> file, as follows</p> <pre><code>io.edurt.datacap.plugin.http.questdb.QuestDBPluginModule\n</code></pre> <p>The content of this file is the plugin loading module we defined.</p> <p>Warning</p> <p>The unit test of the plug-in can refer to the published plug-in for testing</p>"},{"location":"developer_guide/plugin-kotlin.html","title":"Kotlin Implementation","text":"<p>DataCap supports custom plug-ins, and users can write their own plug-ins and integrate them into the system. This document mainly explains how to quickly integrate a plug-in into the DataCap system.</p> <p>Note</p> <p>This article demonstrates by integrating the StarRocks data storage system based on the JDBC protocol.</p>"},{"location":"developer_guide/plugin-kotlin.html#pomxml-depend","title":"<code>pom.xml</code> Depend","text":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-spi&lt;/artifactId&gt;\n    &lt;scope&gt;provided&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-common&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;commons-beanutils&lt;/groupId&gt;\n    &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.testcontainers&lt;/groupId&gt;\n    &lt;artifactId&gt;testcontainers&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>The above configuration adds <code>datacap-spi</code> and <code>datacap-common</code> modules, and others are some auxiliary dependencies.</p> <p>Warning</p> <p>It should be noted that if you open the project separately, you need to specify the version number of each dependency.</p>"},{"location":"developer_guide/plugin-kotlin.html#plugin-loader","title":"Plugin Loader","text":"<pre><code>class StarRocksPluginModule : AbstractPluginModule(), PluginModule {\n    override fun getName(): String {\n        return \"StarRocks\"\n    }\n\n    override fun getType(): PluginType {\n        return PluginType.JDBC\n    }\n\n    override fun get(): AbstractPluginModule {\n        return this\n    }\n\n    override fun configure() {\n        val module = Multibinder.newSetBinder(binder(), String::class.java)\n        module.addBinding().toInstance(this.javaClass.simpleName)\n        val plugin: Multibinder&lt;Plugin&gt; = Multibinder.newSetBinder(binder(), Plugin::class.java)\n        plugin.addBinding().to(StarRocksPlugin::class.java)\n    }\n}\n</code></pre> <p>The loader needs to inherit the <code>AbstractPluginModule</code> class and implement the <code>PluginModule</code> interface, so that the system will automatically load the plug-in into the system when it starts.</p> <p>Note</p> <p>It should be noted that you need to override the <code>configure()</code> method in the parent class and bind the plugin to the system.</p>"},{"location":"developer_guide/plugin-kotlin.html#plugin-executor","title":"Plugin Executor","text":"<pre><code>class StarRocksPlugin : Plugin {\n    private val log = getLogger(StarRocksPlugin::class.java)\n\n    private var jdbcConfigure: JdbcConfigure? = null\n    private var jdbcConnection: JdbcConnection? = null\n    private var jdbcResponse: Response? = null\n\n    override fun name(): String {\n        return \"StarRocks\"\n    }\n\n    override fun description(): String {\n        return \"Integrate StarRocks data sources\"\n    }\n\n    override fun type(): PluginType {\n        return PluginType.JDBC\n    }\n\n    override fun connect(configure: Configure?) {\n        try {\n            log.info(\"Connecting to StarRocks\")\n            jdbcResponse = Response()\n            jdbcConfigure = JdbcConfigure()\n            BeanUtils.copyProperties(jdbcConfigure, configure)\n            jdbcConfigure!!.jdbcDriver = \"com.mysql.cj.jdbc.Driver\"\n            jdbcConfigure!!.jdbcType = \"mysql\"\n            jdbcConnection = object : JdbcConnection(jdbcConfigure, jdbcResponse) {}\n        } catch (ex: Exception) {\n            jdbcResponse!!.isConnected = false\n            jdbcResponse!!.message = ex.message\n        }\n    }\n\n    override fun execute(content: String?): Response {\n        if (ObjectUtils.isNotEmpty(jdbcConnection)) {\n            log.info(\"Execute starrocks plugin logic started\")\n            jdbcResponse = jdbcConnection?.response\n            val processor = JdbcAdapter(jdbcConnection)\n            jdbcResponse = processor.handlerExecute(content)\n            log.info(\"Execute starrocks plugin logic end\")\n        }\n        destroy()\n        return jdbcResponse!!\n    }\n\n    override fun destroy() {\n        if (ObjectUtils.isNotEmpty(jdbcConnection)) {\n            jdbcConnection?.destroy()\n            jdbcConnection = null\n        }\n    }\n}\n</code></pre> <p>The executor needs to implement the <code>Plugin</code> interface, which provides the following methods</p> <ul> <li><code>name()</code>: Plugins have unique names, and plugins with the same name will only take effect the first time they are loaded</li> <li><code>description()</code>: A description of the plugin</li> <li><code>type()</code>: Plugin type</li> <li><code>connect(Configure configure)</code>: Plug-ins need connection information in advance, such as the current plug-in plug-in, which is the connection phase of the plug-in (the system presets the HTTP connection method to be used directly).</li> <li><code>execute(String content)</code>: Execute the operation logic</li> <li><code>destroy()</code>:  The final destruction of the plug-in, note that the destruction needs to contain the information in the connection</li> </ul>"},{"location":"developer_guide/plugin-kotlin.html#plugin-converter","title":"Plugin Converter","text":"<p>The plug-in converter is used to convert the result after the current plug-in is executed, and convert it into logic that can be used in DataCap. It is mainly used to encapsulate <code>Response</code> to return the result.</p> <p>This article is a JDBC-based plug-in, so some functions can be realized by directly inheriting the <code>JdbcAdapter</code> parent class.</p>"},{"location":"developer_guide/plugin-kotlin.html#spi-loader","title":"SPI loader","text":"<p>Add <code>META-INF</code> and <code>services</code> directory under <code>resources</code> source directory</p> <p>Warning</p> <p><code>services</code> needs to be in the <code>resources</code> directory</p> <p>Create the <code>io.edurt.datacap.spi.PluginModule</code> file, as follows</p> <pre><code>io.edurt.datacap.plugin.jdbc.starrocks.StarRocksPluginModule\n</code></pre> <p>The content of this file is the plugin loading module we defined.</p> <p>Warning</p> <p>The unit test of the plug-in can refer to the published plug-in for testing</p>"},{"location":"developer_guide/pipeline/home.html","title":"Pipeline","text":"<p>In the DataCap system, users can configure the pipeline function at will and adjust it arbitrarily according to the version of the low-level executor. The system will automatically identify and compile the final configuration according to the configuration and send it to the executor.</p> <p>The configurations we can provide are:</p> Field Type Description <code>field</code> <code>String</code> Field name <code>origin</code> <code>String</code> The default is equal to the field value, and the custom column name is used. If it is in <code>host|port</code> format, the system will splice the fields through <code>:</code> <code>required</code> <code>Boolean</code> When the value is <code>true</code>, it means that the field is required <code>override</code> <code>Boolean</code> If this flag is <code>true</code>, it means that the field is extracted through user configuration, the default data will be discarded <code>input</code> <code>Boolean</code> Whether it is an input parameter <code>width</code> <code>Integer</code> Component width, default <code>300</code> <code>type</code> <code>FieldType</code> Field type, default <code>INPUT</code> <code>tooltip</code> <code>String</code> Prompt message <code>description</code> <code>String</code> Description <code>value</code> <code>Object</code> The result of the current configuration input <code>hidden</code> <code>Boolean</code> If this configuration item is <code>true</code>, the front end will not be displayed and will only be displayed after enabling it. <code>defaultValues</code> <code>Array</code> If the type is SELECT , you need to pass in default data <p>Danger</p> <p>We do not recommend users to modify the above configurations by themselves. If there are any configuration abnormalities, the plug-in will not be able to use this function.</p>"},{"location":"reference/admin/datasource/home.html","title":"Data Source","text":"<p>Note</p> <p>Through the data source feature, you can add support for various custom data sources, perform subsequent data source operations, and so on.</p> <p>Move the mouse over the <code>Admin</code> logo of the top menu, the drop-down box will pop up, click the first submenu in the drop-down box. A window similar to the following pops up, the default list is empty, you need to add it yourself.</p> <p></p> <p>If you added a data source, a page similar to the following appears</p> <p></p>"},{"location":"reference/admin/datasource/home.html#add-a-data-source","title":"Add a data source","text":"<p>Click the Add button on the right side of the list display area (it is a <code>+</code> icon), and after clicking it, the Add Data Source window will pop up as follows</p> <p></p> <p>When we select a certain type of data source, the data source configuration information will be displayed in the top tab bar, different data sources have different configuration items, and its configuration order is in the specified directory of service startup.</p> <p>When we select the source of type <code>MySQL</code>, a window similar to the following pops up</p> <p></p> <p>4 tabs appear in the configuration page, click on the different tabs to fill in the relevant information, and then click the <code>Test</code> button at the bottom, the following page will pop up:</p> <p></p> <p>When the data source is successfully tested, the version number of the current service will be displayed at the top, and you can save the data by clicking the <code>Save</code> button at the bottom.</p> <p>Note</p> <p>After the data source is saved, the list of data sources is automatically refreshed.</p>"},{"location":"reference/admin/datasource/home.html#modify-the-data-source","title":"Modify the data source","text":"<p>Click the first button in <code>Action</code> in a data source in the list to modify the data source, similar to the <code>Add Data Source</code> action</p>"},{"location":"reference/admin/datasource/home.html#delete-the-data-source","title":"Delete the data source","text":"<p>Click the second button in <code>Action</code> for a data source in the list to delete the data source, and the following will pop up after clicking</p> <p></p> <p>Click the small pop-up window and click <code>OK</code> to delete the selected data source.</p> <p>Danger</p> <p>It is important to note that when a data source is deleted, the query history associated with the data source is deleted.</p>"},{"location":"reference/admin/datasource/home.html#data-source-management","title":"Data source management","text":"<p>Click the third or fourth button in the <code>Action</code> of the data source in the list to jump to the data source management page.</p> <p></p> <p>The page is divided into two parts: left and right. The left side mainly displays the basic information of the data source, including:</p> <ul> <li>Select the relevant metadata for the data source</li> </ul>"},{"location":"reference/admin/datasource/home.html#information-module","title":"Information module","text":"<p>When we select the database and data table on the left, the content on the right is displayed as follows</p> <p></p> <p>Two tabs appear in the right content:</p> <ul> <li><code>Info</code>\uff08Default options\uff09</li> <li><code>Data</code></li> </ul> <p>Note</p> <p>By default, information about the current table is displayed under the Current tab.</p>"},{"location":"reference/admin/datasource/home.html#data-modules","title":"Data modules","text":"<p>Click the <code>Data</code> tab and a page similar to the following will appear, which displays the relevant data of the currently selected table.</p> <p></p> <p>The four buttons at the top are:</p> <ul> <li><code>First Page</code></li> <li><code>Previous Page</code></li> <li><code>Next Page</code></li> <li><code>Last Page</code></li> </ul> <p>The next button is to set the configuration for the data query:</p> <p></p> <ul> <li><code>Jump to Page</code></li> <li><code>Show Page Size</code></li> </ul> <p>Once the configuration is populated, click the <code>Apply</code> button to apply the current configuration information.</p> <p>There is also a button on the right, which will display the detailed <code>SQL</code> content used by the current query</p> <p></p> <p>Note</p> <p>The current SQL generation is based on the order in which it is synchronized to the metadata.</p> <p>Danger</p> <p>At present, not all data sources support management, you can add your own templates if needed. If you are interested, you can contribute the source code to us.</p>"},{"location":"reference/admin/functions/home.html","title":"Functions","text":"<p>Note</p> <p>We can enhance the automatic prompt function of the code editor through the function module provided by the system.</p>"},{"location":"reference/admin/functions/home.html#system-default-function","title":"System default function","text":"<p>The system has built-in the following data source functions by default (it does not mean that it is the most complete function of the new version, if there is something missing, please submit issues or pr to fix it):</p> <ul> <li>ClickHouse</li> <li>MySQL</li> <li>Hive</li> <li>Trino &amp; Presto (fit a part)</li> </ul>"},{"location":"reference/admin/functions/home.html#add-function","title":"Add function","text":"<p>After entering the system, click the corresponding <code>Function</code> submenu under the top <code>Settings</code> menu to go to the function configuration function</p> <p></p> <p>Click the Add button on the top right to add a new function, and the following window will pop up after clicking:</p> <p></p> <p>The following is a detailed parameter description:</p> <ul> <li><code>Name</code>: The name used to mark the function prompt, the suggestion is English</li> <li><code>Plugin</code>: The plugin this function applies to, multiple options can be selected</li> <li><code>Content</code>: The specific content of the function, which will be entered into the editor</li> <li><code>Description</code>: Description of the function</li> <li><code>Type</code>: Type of function, can be: <code>KeyWord</code>, <code>Operator</code>, <code>Function</code>, default is <code>KeyWord</code></li> <li><code>Example</code>: For the use example of this function, it is convenient for users to understand how to use the function</li> </ul> <p>When the above content is written, click the <code>Submit</code> button at the bottom to save the operation, and you can use it in the editor later.</p>"},{"location":"reference/admin/functions/home.html#batch-operation","title":"Batch operation","text":"<p>The system provides a way to import functions in batches. Currently, it supports the import of content and URI addresses. Next, let's take a look at how to do it.</p> <p>We perform the batch import function by clicking the import button on the top right.</p>"},{"location":"reference/admin/functions/home.html#content-import","title":"Content import","text":"<p>The content import method allows us to enter a list of functions, and they are divided according to each line. Adding the following keywords we need to import:</p> <pre><code>SHOW\nUSE\n</code></pre> <p>In <code>Plugin</code>, we choose to use the <code>ClickHouse</code> plug-in, and in <code>Type</code>, we choose <code>KeyWord</code>. After the operation is completed, we click the <code>Submit</code> button at the bottom to use the import function of the current input function.</p>"},{"location":"reference/admin/functions/home.html#uri-import","title":"URI import","text":"<p>The URI import method is relatively simple. We can import data in batches by specifying the remote server URI address, which can be your local server address or the address provided by the software.</p> <p>The URI address format provided by the software by default is</p> <pre><code>(http|https)://datacap.edurt.io/resources/functions/plugin/keywords.txt\n(http|https)://datacap.edurt.io/resources/functions/plugin/operators.txt\n(http|https)://datacap.edurt.io/resources/functions/plugin/functions.txt\n</code></pre> <p>We only need to replace the value of plugin in the address with the name of the plugin that needs to be imported.</p> <p>Warning</p> <p>It should be noted that due to local network problems, the URI import method may be slow.</p>"},{"location":"reference/admin/history/query/home.html","title":"Query history","text":"<p>Move the mouse over the <code>Admin</code> logo in the top menu, the drop-down box will pop up, click the <code>History</code> submenu in the drop-down box. A window similar to the following pops up, the default list is empty, and records can be automatically added by querying through the query page.</p> <p></p>"},{"location":"reference/admin/history/query/home.html#review-executing-sql","title":"Review Executing SQL","text":"<p>Click the first button in <code>Action</code> in a data in the list to view the specific code snippet content, and a dialog box will pop up, which is roughly as follows</p> <p></p> <p>The specific SQL statements queried in this query are displayed in the window.</p>"},{"location":"reference/admin/history/query/home.html#review-the-execution-errors","title":"Review the execution errors","text":"<p>Danger</p> <p>You can view error information only if the query is exceptional.</p> <p>Click the second button in <code>Action</code> in one of the data in the list to view the error message</p> <p></p>"},{"location":"reference/admin/pipeline/home.html","title":"Pipeline","text":"<p>In the DataCap software, the pipeline is a tool for users to perform some data operations such as data migration.</p>"},{"location":"reference/admin/pipeline/home.html#build-pipeline","title":"Build pipeline","text":"<p>After entering the system, click the corresponding <code>Pipeline</code> submenu under the <code>Admin</code> menu at the top to enter the pipeline list by default. Similar to the picture below:</p> <p></p> <p>Click the <code>+ Create</code> button on the right side of the list, and the system will pop up the configuration page:</p> <p></p> <p>The configuration page is divided into three configuration modules, namely:</p> <ul> <li><code>Description</code> mainly configures the SQL executed by the user</li> <li><code>From</code> configures the data access source</li> <li><code>To</code> configure data output source</li> </ul> <p>Each data source has different configuration properties. After selecting the data source, just follow the prompts to configure the relevant properties.</p> <p>When the task is successfully published, the task list will be refreshed by default, as shown in the following figure:</p> <p></p>"},{"location":"reference/admin/pipeline/home.html#pipeline-management","title":"Pipeline management","text":"<p>After the task is released, it will be started by default. The <code>Action</code> operation on the right side of the task contains the following functions:</p>"},{"location":"reference/admin/pipeline/home.html#view-errors","title":"View errors","text":"<p>When we click the first button in <code>Action</code>, the system will pop up an error message page.</p> <p>This feature will only be enabled if the task fails</p> <p></p>"},{"location":"reference/admin/pipeline/home.html#view-log","title":"View log","text":"<p>When we click the second button in <code>Action</code>, the system will pop up the log page.</p> <p></p>"},{"location":"reference/admin/pipeline/home.html#task-stopped","title":"Task stopped","text":"<p>When we click the third button in <code>Action</code>, the system will pop up the stop task page.</p> <p>This feature will only be enabled when the task is running</p> <p></p> <p>We enter the task name according to the information prompted in the window and click the <code>Stop</code> button.</p>"},{"location":"reference/admin/pipeline/home.html#task-deletion","title":"Task deletion","text":"<p>When we click the fourth button in <code>Action</code>, the system will pop up the delete task page.</p> <p></p> <p>We enter the task name according to the information prompted in the window and click the <code>Delete</code> button.</p>"},{"location":"reference/admin/processor/home.html","title":"Processor","text":"<p>Note</p> <p>Through the process monitoring function, you can view some specific processes currently being executed by the data source</p>"},{"location":"reference/admin/processor/home.html#view-all-processes","title":"View all processes","text":"<p>After entering the system, click the corresponding <code>Processor</code> submenu under the top <code>Admin</code> menu to go to the function configuration function</p> <p></p> <p>Select the data source we need to view the process through the drop-down box at the top, and it will be refreshed and displayed in the content area below</p> <p></p> <p>Danger</p> <p>It should be noted that different data sources have different presentation methods</p>"},{"location":"reference/admin/processor/home.html#not-support","title":"Not support","text":"<p>When we view the unsupported data source, the content of the page is as follows:</p> <p></p> <p>The system will prompt us to add SQL template or submit issues to support it</p>"},{"location":"reference/admin/profile/home.html","title":"Personal Data","text":"<p>Note</p> <p>The profile feature provides an overview of some of the query history and data source usage of individual users.</p> <p>Hover the mouse over the avatar menu on the far right of the top menu, a drop-down box will pop up, click the first submenu in the drop-down box. A window similar to the following pops up:</p> <p></p> <p>First of all, the top chart we see is the query calendar chart for the past year. It is calculated based on the summary of the total number of queries per day.</p> <p>The second chart shows the data source usage in the last 7 days. It is calculated based on a daily summary of data source usage.</p>"},{"location":"reference/admin/profile/home.html#profile","title":"Profile","text":"<p>When you click on the profile button (the first button on the left menu), you will see a pop-up window like this:</p> <p></p> <p>This page mainly displays the basic information of the profile.</p>"},{"location":"reference/admin/profile/home.html#login-logs","title":"Login logs","text":"<p>When you click the login log button (the second button on the left menu), the following window will pop up:</p> <p></p> <p>This page displays the login logs of the current user, including the login time, login location, and login method.</p>"},{"location":"reference/admin/profile/home.html#account-settings","title":"Account Settings","text":"<p>When you click on the Account Settings button (the third button on the left menu), the following window will pop up:</p> <p></p> <p>This page mainly shows some of the configuration functions that users can make.</p>"},{"location":"reference/admin/profile/home.html#username","title":"Username","text":"<p>When you click the Modify Username button, the following window will pop up:</p> <p></p> <p>Enter the modified username and current password, and click the OK button to complete the modification.</p> <p>Danger</p> <p>It should be noted that after changing the user name, you need to log in again. The system will log out of the current account by default.</p>"},{"location":"reference/admin/profile/home.html#password","title":"Password","text":"<p>When you click the Change Password button, the following window will pop up:</p> <p></p> <p>Enter the original password and the new password, and click the OK button to complete the modification.</p> <p>Danger</p> <p>It should be noted that after changing the password, you need to log in again. The system will log out of the current account by default.</p>"},{"location":"reference/admin/profile/home.html#chatgpt","title":"ChatGPT","text":"<p>When you click the ChatGPT button, the following window will pop up:</p> <p></p> <p>This page mainly shows some of the configuration features that ChatGPT can do.</p>"},{"location":"reference/admin/profile/home.html#editor","title":"Editor","text":"<p>When you click the editor button, the following window will pop up:</p> <p></p> <p>When you modify the editor, the modified configuration is synchronized to all locations in the system that use the editor.</p> <p>The editor's changes are WYSIWYG and show the current configuration scheme in real time.</p>"},{"location":"reference/admin/snippet/home.html","title":"Snippet","text":"<p>Note</p> <p>The snippet feature allows you to add support for various custom snippets, perform subsequent snippet operations, and more. The added code snippet is then added to the editor.</p> <p>Move your mouse over the <code>Admin</code> icon in the top menu to pop up the drop-down box, click the <code>Snippet</code> submenu in the drop-down box. A window similar to the following pops up, the default list is empty, you need to add it yourself.</p> <p></p> <p>If you added a fragment, a page similar to the following appears</p> <p></p>"},{"location":"reference/admin/snippet/home.html#add-snippet","title":"Add Snippet","text":"<p>Click the Add button on the right side of the list display area (it is a <code>+</code> icon), and after clicking it, the Add Data Source window will pop up as follows</p> <p></p> <p>In the window, we need to enter the following</p> Attribute Description <code>Name</code> Marks the name of the current snippet <code>Description</code> A description of the current code snippet <code>Snippet</code> The specific SQL content of the current code snippet <p>After filling in the above, click the <code>Submit</code> button at the bottom to save the code snippet.</p> <p>Note</p> <p>After the data is saved, the list of data sources is automatically refreshed.</p>"},{"location":"reference/admin/snippet/home.html#review-the-snippet-content","title":"Review the snippet content","text":"<p>Click the first button in <code>Action</code> in a data in the list to view the specific code snippet content, and a dialog box will pop up, which is roughly as follows</p> <p></p> <p>Click <code>OK</code> or <code>Cancel</code> to close the dialog box</p>"},{"location":"reference/admin/snippet/home.html#modify-the-code-snippet","title":"Modify the code snippet","text":"<p>Click the second button in <code>Action</code> in one of the data in the list to modify the snippet, similar to the <code>Add Snippet</code> action.</p>"},{"location":"reference/admin/snippet/home.html#quote-snippet","title":"Quote Snippet","text":"<p>Click the third button in <code>Action</code> of a piece of data in the list, reference the current code snippet, and you will be taken to the query page, and the fragment content will be entered directly into the editor.</p>"},{"location":"reference/admin/snippet/home.html#delete-the-snippet","title":"Delete the snippet","text":"<p>Click the fourth button in <code>Action</code> of a piece of data in the list to delete the snippet, and the following will pop up after clicking</p> <p></p> <p>Click the small pop-up window and click <code>OK</code> to remove the snippet.</p>"},{"location":"reference/admin/template/sql/home.html","title":"Sql","text":"<p>Note</p> <p>The system supports the SQL template function, through which the realization of some monitoring and other functions can be supported.</p>"},{"location":"reference/admin/template/sql/home.html#default-template","title":"Default template","text":"<p>The system supports some default templates, currently supports:</p> <ul> <li><code>getAllDatabaseAndTable</code></li> <li><code>getAllDatabase</code></li> <li><code>getAllTablesFromDatabase</code></li> </ul> <p>Of course, each template can support one or more plug-ins, and they will be used in subsequent operations of the system.</p>"},{"location":"reference/admin/template/sql/home.html#add-template","title":"Add template","text":"<p>After entering the system, click the corresponding <code>Sql</code> submenu under the top <code>Settings</code> menu to go to the function configuration function</p> <p></p> <p>Click the Add button on the top right to add a new function, and the following window will pop up after clicking:</p> <p></p> <p>The following is a detailed parameter description:</p> <ul> <li><code>Name</code>: The name used to mark the function prompt, the suggestion is English</li> <li><code>Plugin</code>: The plugin this function applies to, multiple options can be selected</li> <li><code>Description</code>: Description of the function</li> <li><code>Template</code>: The SQL statement executed by the template</li> </ul> <p>When the above content is written, click the <code>Submit</code> button at the bottom to save the operation, and you can use it in the editor later.</p> <p>Warning</p> <p>The default template does not carry any parameters and we can execute it directly.</p>"},{"location":"reference/admin/template/sql/home.html#dynamic-parameter-template","title":"Dynamic parameter template","text":"<p>We can realize the template dynamic parameter passing function by defining variables. Let's take an example, we need to display all the data tables under the <code>default</code> database, the normal SQL is</p> <pre><code>SHOW TABLES FROM default\n</code></pre> <p>When we use the template, the SQL changes to</p> <pre><code>SHOW TABLES FROM ${database:String}\n</code></pre> <p>The system parses the parameter into <code>database=String</code> by collecting <code>{database:String}</code> expression, where <code>database</code> is the parameter name, and <code>String</code> is the type of parameter passing.</p> <p>When we use the expression time, we only need to pass the <code>Map</code> type parameter, where key=parameter name, value=data value passed according to the type.</p>"},{"location":"reference/clients/cli.html","title":"Command line interface","text":"<p>The DataCap CLI provides a terminal-based, interactive shell for running queries. The CLI is a self-executing JAR file, which means it acts like a normal UNIX executable.</p>"},{"location":"reference/clients/cli.html#requirements","title":"Requirements","text":"<p>The CLI requires a Java virtual machine available on the path. It can be used with Java version 8 and higher.</p> <p>The CLI uses the DataCap client REST API over HTTP/HTTPS to communicate with the system.</p> <p>The CLI version should be identical to the version of system, or newer.</p>"},{"location":"reference/clients/cli.html#installation","title":"Installation","text":"<p>Download datacap-client-cli-1.6.0.jar, rename it to datacap, make it executable with <code>chmod +x</code>.</p>"},{"location":"reference/clients/cli.html#running-the-cli","title":"Running the CLI","text":"<pre><code>./datacap\n\nconnect -h 127.0.0.1 -p 9096 -u username -P password\n</code></pre> <p>If successful, you will get a prompt to execute commands. Use the <code>help</code> command to see a list of supported commands.</p> Command Description <code>source info</code> Get data source details <code>source list</code> Get a list of remote server data sources <code>source use &lt;SourceID&gt;</code> Set the data source flag for subsequent operations on the data source <code>source execute \"&lt;QuerySQL&gt;\"</code> Execute remote SQL"},{"location":"reference/connectors/index.html","title":"Connectors","text":"<p>This chapter describes the connectors available in DataCap to access data from different data sources.</p>"},{"location":"reference/connectors/index.html#jdbc","title":"JDBC","text":"<p>DuckDB Yandex Database Snowflake MySQL ClickHouse </p>"},{"location":"reference/connectors/index.html#native","title":"Native","text":"<p>H2 Database Apache Kafka Aliyun OSS Apache Zookeeper Redis </p>"},{"location":"reference/connectors/index.html#http","title":"Http","text":"<p>ClickHouse </p>"},{"location":"reference/connectors/cassandra.html","title":"Apache Cassandra","text":""},{"location":"reference/connectors/cassandra.html#what-is-cassandra","title":"What is Cassandra ?","text":"<p>Apache Cassandra\u00ae powers mission-critical deployments with improved performance and unparalleled levels of scale in the cloud.</p>"},{"location":"reference/connectors/cassandra.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.11.x</code></p> <p>Support Time: <code>2023-06-07</code></p>"},{"location":"reference/connectors/cassandra.html#configure","title":"Configure","text":"<p>Note</p> <p>If your plugin service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9042</code> Field Required Default Value <code>Database</code> <code>datacenter</code>"},{"location":"reference/connectors/cassandra.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>0.4.x</code></li> </ul>"},{"location":"reference/connectors/http/ceresdb.html","title":"CeresDB","text":""},{"location":"reference/connectors/http/ceresdb.html#what-is-ceresdb","title":"What is CeresDB ?","text":"<p>CeresDB is a high-performance, distributed, cloud native time-series database.</p>"},{"location":"reference/connectors/http/ceresdb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-12</code></p>"},{"location":"reference/connectors/http/ceresdb.html#configure","title":"Configure","text":"<p>Note</p> <p>If your CeresDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>5440</code>"},{"location":"reference/connectors/http/ceresdb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 1.x</li> </ul>"},{"location":"reference/connectors/http/clickhouse.html","title":"ClickHouse","text":""},{"location":"reference/connectors/http/clickhouse.html#what-is-clickhouse","title":"What is ClickHouse ?","text":"<p>ClickHouse\u00ae is a column-oriented database management system (DBMS) for online analytical processing of queries (OLAP). ClickHouse\u2019s performance exceeds all other column-oriented database management systems. It processes billions of rows and tens of gigabytes of data per server per second.</p>"},{"location":"reference/connectors/http/clickhouse.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.3.x</code></p> <p>Support Time: <code>2022-11-09</code></p>"},{"location":"reference/connectors/http/clickhouse.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default clickhouse.json</p> <p>Note</p> <p>If your ClickHouse service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>8123</code>"},{"location":"reference/connectors/http/clickhouse.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 19.x</li> <li> 20.x</li> <li> 21.x</li> </ul>"},{"location":"reference/connectors/http/greptimedb.html","title":"GreptimeDB","text":""},{"location":"reference/connectors/http/greptimedb.html#what-is-greptimedb","title":"What is GreptimeDB ?","text":"<p>An open-source, cloud-native, distributed time-series database with PromQL/SQL/Python supported.</p>"},{"location":"reference/connectors/http/greptimedb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-14</code></p>"},{"location":"reference/connectors/http/greptimedb.html#configure","title":"Configure","text":"<p>Note</p> <p>If your GreptimeDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>4000</code>"},{"location":"reference/connectors/http/greptimedb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 0.x</li> </ul>"},{"location":"reference/connectors/http/questdb.html","title":"QuestDB","text":""},{"location":"reference/connectors/http/questdb.html#what-is-questdb","title":"What is QuestDB ?","text":"<p>QuestDB is an open-source time-series database for high throughput ingestion and fast SQL queries with operational simplicity. It supports schema-agnostic ingestion using the InfluxDB line protocol, PostgreSQL wire protocol, and a REST API for bulk imports and exports.</p>"},{"location":"reference/connectors/http/questdb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-17</code></p>"},{"location":"reference/connectors/http/questdb.html#configure","title":"Configure","text":"<p>Note</p> <p>If your QuestDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code>"},{"location":"reference/connectors/http/questdb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 7.x</li> </ul>"},{"location":"reference/connectors/jdbc/clickhouse.html","title":"ClickHouse","text":""},{"location":"reference/connectors/jdbc/clickhouse.html#what-is-clickhouse","title":"What is ClickHouse ?","text":"<p>ClickHouse\u00ae is a column-oriented database management system (DBMS) for online analytical processing of queries (OLAP). ClickHouse\u2019s performance exceeds all other column-oriented database management systems. It processes billions of rows and tens of gigabytes of data per server per second.</p>"},{"location":"reference/connectors/jdbc/clickhouse.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.0.x</code></p> <p>Support Time: <code>2022-09-22</code></p>"},{"location":"reference/connectors/jdbc/clickhouse.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default clickhouse.json</p> <p>Note</p> <p>If your ClickHouse service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> - <p>Note</p> <p>You can add the already supported ClickHouse parameters by adding Key Value, the parameters can be reference document</p>"},{"location":"reference/connectors/jdbc/clickhouse.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 19.x</li> <li> 20.x</li> <li> 21.x</li> </ul>"},{"location":"reference/connectors/jdbc/doris.html","title":"Apache Doris","text":""},{"location":"reference/connectors/jdbc/doris.html#what-is-doris","title":"What is Doris ?","text":"<p>An easy-to-use, high-performance and unified analytical database</p>"},{"location":"reference/connectors/jdbc/doris.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-19</code></p>"},{"location":"reference/connectors/jdbc/doris.html#configure","title":"Configure","text":"<p>Note</p> <p>If your Doris service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9093</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"reference/connectors/jdbc/doris.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p>"},{"location":"reference/connectors/jdbc/duckdb.html","title":"DuckDB","text":""},{"location":"reference/connectors/jdbc/duckdb.html#what-is-duckdb","title":"What is DuckDB ?","text":"<p>DuckDB is an in-process SQL OLAP database management system.</p>"},{"location":"reference/connectors/jdbc/duckdb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.6.x</code></p> <p>Support Time: <code>2023-02-20</code></p>"},{"location":"reference/connectors/jdbc/duckdb.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default duckdb.json</p> <p>Note</p> <p>If your DuckDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>/root</code> <code>Port</code> <code>0</code> Field Required Default Value <code>Database</code> <code>local</code>"},{"location":"reference/connectors/jdbc/duckdb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 0.7.0</li> </ul>"},{"location":"reference/connectors/jdbc/hologres.html","title":"Hologres","text":""},{"location":"reference/connectors/jdbc/hologres.html#what-is-hologres","title":"What is Hologres ?","text":"<p>Hologres is an all-in-one real-time data warehouse engine that is compatible with PostgreSQL. It supports online analytical processing (OLAP) and ad hoc analysis of PB-scale data. Hologres supports online data serving at high concurrency and low latency. It is deeply integrated with MaxCompute, Flink and DataWorks, provides a full-stack data warehouse solution that integrates online and offline processing.</p>"},{"location":"reference/connectors/jdbc/hologres.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-25</code></p>"},{"location":"reference/connectors/jdbc/hologres.html#configure","title":"Configure","text":"<p>Note</p> <p>If your Hologres service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>hologres-cn-regison.aliyuncs.com</code> <code>Port</code> <code>80</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"reference/connectors/jdbc/hologres.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> all</li> </ul>"},{"location":"reference/connectors/jdbc/mysql.html","title":"MySQL","text":""},{"location":"reference/connectors/jdbc/mysql.html#what-is-mysql","title":"What is MySQL ?","text":"<p>MySQL is one of the most recognizable technologies in the modern big data ecosystem. Often called the most popular database and currently enjoying widespread, effective use regardless of industry, it\u2019s clear that anyone involved with enterprise data or general IT should at least aim for a basic familiarity of MySQL.</p>"},{"location":"reference/connectors/jdbc/mysql.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.0.x</code></p> <p>Support Time: <code>2022-09-19</code></p>"},{"location":"reference/connectors/jdbc/mysql.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default mysql.json</p> <p>Note</p> <p>If your MySQL service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>3306</code> Field Required Default Value <code>Username</code> - <code>Password</code> - <code>SSL</code> <code>false</code> Field Required Default Value <code>Database</code> <code>default</code> <p>Note</p> <p>You can add the already supported MySQL parameters by adding Key Value, the parameters can be reference document</p> <p>Default:</p> Key value <code>useOldAliasMetadataBehavior</code> <code>true</code>"},{"location":"reference/connectors/jdbc/mysql.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 5.x</li> <li> 6.x</li> <li> 7.x</li> </ul>"},{"location":"reference/connectors/jdbc/pinot.html","title":"Apache Pinot","text":""},{"location":"reference/connectors/jdbc/pinot.html#what-is-pinot","title":"What is Pinot ?","text":"<p>Apache Pinot is a real-time distributed OLAP datastore purpose-built for low-latency, high-throughput analytics, and perfect for user-facing analytical workloads.</p>"},{"location":"reference/connectors/jdbc/pinot.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.10.x</code></p> <p>Support Time: <code>2023-05-06</code></p>"},{"location":"reference/connectors/jdbc/pinot.html#configure","title":"Configure","text":"<p>Note</p> <p>If your Pinot service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorization Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code> Field Required Default Value <code>Username</code> - <code>Password</code> -"},{"location":"reference/connectors/jdbc/pinot.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>0.8.x</code></li> </ul>"},{"location":"reference/connectors/jdbc/snowflake.html","title":"Snowflake","text":""},{"location":"reference/connectors/jdbc/snowflake.html#what-is-snowflake","title":"What is Snowflake ?","text":"<p>Execute your most critical workloads on top of Snowflake's multi-cluster shared data architecture in a fully managed platform that capitalizes on the near-infinite resources of the cloud.</p>"},{"location":"reference/connectors/jdbc/snowflake.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.4.x</code></p> <p>Support Time: <code>2023-01-29</code></p>"},{"location":"reference/connectors/jdbc/snowflake.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default snowflake.json</p> <p>Note</p> <p>If your Snowflake service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>80</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> - <p>Note</p> <p>You can add the already supported Snowflake parameters by adding Key Value, the parameters can be reference document</p>"},{"location":"reference/connectors/jdbc/snowflake.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p>"},{"location":"reference/connectors/jdbc/starrocks.html","title":"StarRocks","text":""},{"location":"reference/connectors/jdbc/starrocks.html#what-is-starrocks","title":"What is StarRocks ?","text":"<p>An Open-Source, High-Performance Analytical Database</p>"},{"location":"reference/connectors/jdbc/starrocks.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-20</code></p>"},{"location":"reference/connectors/jdbc/starrocks.html#configure","title":"Configure","text":"<p>Note</p> <p>If your StarRocks service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9030</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"reference/connectors/jdbc/starrocks.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 2.2.x</li> </ul>"},{"location":"reference/connectors/jdbc/ydb.html","title":"Yandex Database","text":""},{"location":"reference/connectors/jdbc/ydb.html#what-is-ydb","title":"What is YDB ?","text":"<p>YDB is a fault-tolerant distributed SQL DBMS. YDB provides high availability, horizontal scalability, strict consistency, and ACID transaction support. Queries are made using an SQL dialect (YQL).</p>"},{"location":"reference/connectors/jdbc/ydb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.4.x</code></p> <p>Support Time: <code>2023-01-30</code></p>"},{"location":"reference/connectors/jdbc/ydb.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default ydb.json</p> <p>Note</p> <p>If your YDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>2136</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> <code>local</code>"},{"location":"reference/connectors/jdbc/ydb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 2.1.x</li> </ul>"},{"location":"reference/connectors/native/alioss.html","title":"AliYun OSS","text":""},{"location":"reference/connectors/native/alioss.html#what-is-aliyun-oss","title":"What is Aliyun OSS ?","text":"<p>Fully managed object storage service to store and access any amount of data from anywhere</p>"},{"location":"reference/connectors/native/alioss.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.6.x</code></p> <p>Support Time: <code>2023-02-23</code></p>"},{"location":"reference/connectors/native/alioss.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in Aliyun OSS on DataCap.</p>"},{"location":"reference/connectors/native/alioss.html#select","title":"SELECT","text":"<p>Synopsis</p> <pre><code>SELECT [ * | &lt;Columns&gt; ] select_expression [, ...]\nFROM from_item [. ...]\n</code></pre> <p>where <code>from_item</code> is one of</p> <pre><code>table_name [ `a.b` | a.b | `a`.`b`]\n</code></pre> <p>Danger</p> <p>When <code>table_name</code> is set to <code>all</code> the root directory is searched.</p> <p>Select expressions</p> <p>Each <code>select_expression</code> must be in one of the following forms:</p> <pre><code>expression [ column_alias ]\n</code></pre> <pre><code>*\n</code></pre> <p>In the case of <code>expression [ column_alias ]</code>, a single output column is defined.</p> <p>In the case of <code>*</code>, all columns of the relation defined by the query are included in the result set.</p> <pre><code>    *\n--------\n   data\n</code></pre> <p>Danger</p> <p>If it is a multi-level directory, such as <code>/oss/id/2</code>, it will be written `oss`.`id`.`2`, and use <code>.</code> to split between directories.</p>"},{"location":"reference/connectors/native/alioss.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default alioss.json</p> <p>Note</p> <p>If your Aliyun OSS service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>https://oss-cn-regison.aliyuncs.com</code> Field Required Description Default Value <code>Username</code> access Id - <code>Password</code> access Secret - Field Required Description Default Value <code>Database</code> bucket name <code>default</code>"},{"location":"reference/connectors/native/alioss.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>all version</code></li> </ul>"},{"location":"reference/connectors/native/h2.html","title":"H2 Database","text":""},{"location":"reference/connectors/native/h2.html#what-is-h2","title":"What is h2 ?","text":"<p>H2 is an embedded database developed in Java that is itself just a class library. </p>"},{"location":"reference/connectors/native/h2.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.8.x</code></p> <p>Support Time: <code>2023-04-05</code></p>"},{"location":"reference/connectors/native/h2.html#configure","title":"Configure","text":"<p>Note</p> <p>If your h2 service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code>"},{"location":"reference/connectors/native/h2.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>all</code></li> </ul>"},{"location":"reference/connectors/native/redis.html","title":"Redis","text":""},{"location":"reference/connectors/native/redis.html#what-is-redis","title":"What is Redis ?","text":"<p>The open source, in-memory data store used by millions of developers as a database, cache, streaming engine, and message broker.</p>"},{"location":"reference/connectors/native/redis.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.3.x</code></p> <p>Support Time: <code>2022-12-01</code></p>"},{"location":"reference/connectors/native/redis.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default redis.json</p> <p>Note</p> <p>If your Redis service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorization Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>6379</code> Field Required Default Value <code>Password</code> -"},{"location":"reference/connectors/native/redis.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 6.x</li> <li> 7.x</li> </ul>"},{"location":"reference/connectors/native/zookeeper.html","title":"Apache Zookeeper","text":""},{"location":"reference/connectors/native/zookeeper.html#what-is-zookeeper","title":"What is Zookeeper ?","text":"<p>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. </p>"},{"location":"reference/connectors/native/zookeeper.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.5.x</code></p> <p>Support Time: <code>2023-02-07</code></p>"},{"location":"reference/connectors/native/zookeeper.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in Zookeeper on DataCap.</p>"},{"location":"reference/connectors/native/zookeeper.html#select","title":"SELECT","text":"<p>Synopsis</p> <pre><code>SELECT [ * | &lt;Columns&gt; ] select_expression [, ...]\nFROM from_item [. ...]\n</code></pre> <p>where <code>from_item</code> is one of</p> <pre><code>table_name [ `a.b` | a.b | `a`.`b`]\n</code></pre> <p>Danger</p> <p>When <code>table_name</code> is set to <code>all</code> the root directory is searched.</p> <p>Select expressions</p> <p>Each <code>select_expression</code> must be in one of the following forms:</p> <pre><code>expression [ column_alias ]\n</code></pre> <pre><code>*\n</code></pre> <p>In the case of <code>expression [ column_alias ]</code>, a single output column is defined.</p> <p>In the case of <code>*</code>, all columns of the relation defined by the query are included in the result set.</p> <pre><code>    *\n--------\n   data\n</code></pre> <p>Danger</p> <p>If it is a multi-level directory, such as <code>/zookeeper/id/2</code>, it will be written `zookeeper`.`id`.`2`, and use <code>.</code> to split between directories.</p>"},{"location":"reference/connectors/native/zookeeper.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default zookeeper.json</p> <p>Note</p> <p>If your Zookeeper service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1:2181</code> <code>Port</code> <code>1</code>"},{"location":"reference/connectors/native/zookeeper.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>3.1.x</code> - <code>3.7.x</code></li> </ul>"},{"location":"reference/connectors/native/hadoop/hdfs.html","title":"Apache Hadoop HDFS","text":""},{"location":"reference/connectors/native/hadoop/hdfs.html#what-is-hdfs","title":"What is HDFS ?","text":"<p>The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. It has many similarities with existing distributed file systems.</p>"},{"location":"reference/connectors/native/hadoop/hdfs.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-27</code></p>"},{"location":"reference/connectors/native/hadoop/hdfs.html#configure","title":"Configure","text":"<p>Note</p> <p>If your HDFS service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAdvanced Field Required Default Value <code>Name</code> - Field Required Description Default Value <code>file</code> <code>core-site.xml</code> <code>hdfs-site.xml</code> <code>[]</code>"},{"location":"reference/connectors/native/hadoop/hdfs.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>3.x</code></li> </ul>"},{"location":"reference/connectors/native/kafka/index.html","title":"Apache Kafka","text":""},{"location":"reference/connectors/native/kafka/index.html#what-is-apache-kafka","title":"What is Apache Kafka ?","text":"<p>Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.</p>"},{"location":"reference/connectors/native/kafka/index.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.7.x</code></p> <p>Support Time: <code>2023-03-06</code></p>"},{"location":"reference/connectors/native/kafka/index.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in DataCap Kafka plugin.</p> <p>SHOW TOPICS SHOW CONSUMERS</p>"},{"location":"reference/connectors/native/kafka/index.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default kafka.json</p> <p>Note</p> <p>If your Apache Kafka service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>localhost:9092</code>"},{"location":"reference/connectors/native/kafka/index.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>1.0.0</code></li> <li> <code>1.1.0</code></li> <li> <code>1.2.0</code></li> </ul>"},{"location":"reference/get_started/install.html","title":"Deploying in Self Host","text":"<p>DataCap is a software for data transformation, integration and visualization.</p>"},{"location":"reference/get_started/install.html#system-requirements","title":"System Requirements","text":"<p>Warning</p> <p>The binary package of the software is compiled and tested based on the following systems. It has not been tested on other versions, and it is theoretically supported.</p> <p>If there is an unsupported system, use the source code compilation method to actively compile the binary file.</p> System Version JDK <code>&gt;=11</code> MySQL <code>&gt;=5.6.x</code>"},{"location":"reference/get_started/install.html#binary-install","title":"Binary install","text":"<p>Note</p> <p>Download the binary software package of the corresponding system from the following address for installation.</p> <ul> <li>Download Release</li> </ul>"},{"location":"reference/get_started/install.html#download-package","title":"Download package","text":"<p>Run the following command after downloading the binary to your local</p> <pre><code>tar -xvzf datacap-release.tar.gz\n</code></pre>"},{"location":"reference/get_started/install.html#configuration-software","title":"Configuration software","text":"<p>For the first installation of the software, you need to import the sql scripts in the <code>schema/datacap.sql</code> file to the MySQL server. Note that the scripts that need to be imported are matched according to the downloaded software package</p> <p>After importing the <code>SQL</code> script, modify the <code>configure/application.properties</code> configuration file to modify the configuration information of the MySQL server</p> <p>Add configuration</p> <pre><code>spring.datasource.url=jdbc:mysql://localhost:3306/datacap?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;useSSL=false&amp;useOldAliasMetadataBehavior=true&amp;jdbcCompliantTruncation=false&amp;sessionVariables=sql_mode='STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,PIPES_AS_CONCAT'\nspring.datasource.username=root\nspring.datasource.password=12345678\n</code></pre> <p>Warning</p> <p>If you need to modify the log configuration, just modify the <code>configure/logback.xml</code> configuration file</p>"},{"location":"reference/get_started/install.html#start-service","title":"Start service","text":"<p>DataCap service startup is very simple, execute the following script</p> <pre><code>./bin/startup.sh\n</code></pre>"},{"location":"reference/get_started/install.html#stop-service","title":"Stop service","text":"<p>Stop the service and execute the following script</p> <pre><code>./bin/shutdown.sh\n</code></pre> <p>Note</p> <p>If you want to debug the system, you can use <code>./bin/debug.sh</code> to start the service, but it will stop when you close the window</p>"},{"location":"reference/get_started/install.html#source-installation","title":"Source installation","text":"<p>Warning</p> <p>To manually compile and install DataCap, you need to perform the following steps.</p> <p>The system needs to install <code>JDK</code></p> <ul> <li>Clone the source code to this machine</li> </ul> <pre><code>git clone https://github.com/devlive-community/datacap.git\n</code></pre> <ul> <li>Compile and build the application</li> </ul> <pre><code>./mvnw clean install package -DskipTests -Dgpg.skip\n</code></pre> <p>Warning</p> <p>After compiling, the <code>datacap-release.tar.gz</code> package will be generated in the <code>dist</code> directory.</p> <p>Use the relevant packages to install it.</p> <p>Note</p> <p>If you do not want to install to the local software directory, you can use the following documents to start the development mode for software use.</p> <p>Developer</p>"},{"location":"reference/get_started/install_containers.html","title":"Deploying in a Docker container","text":"<p>The DataCap project provides the qianmoq/datacap Docker image that includes the DataCap server and a default configuration. The Docker image is published to Docker Hub and can be used with the Docker runtime, among several others.</p>"},{"location":"reference/get_started/install_containers.html#running-the-container","title":"Running the container","text":"<p>To run DataCap in Docker, you must have the Docker engine installed on your machine. You can download Docker from the Docker website, or use the packaging system of your operating systems.</p> <p>Use the docker command to create a container from the qianmoq/datacap image. Assign it the datacap name, to make it easier to reference it later. Run it in the background, and map the default DataCap port, which is <code>9096</code>, from inside the container to port <code>9096</code> on your workstation.</p> <pre><code>docker run -d -p 9909:9096 --name datacap qianmoq/datacap\n</code></pre> <p>Without specifying the container image tag, it defaults to <code>latest</code>, but a number of any released DataCap version can be used, for example <code>qianmoq/datacap:1.8.0</code>.</p> <p>Run <code>docker ps</code> to see all the containers running in the background.</p> <pre><code>-&gt; % docker ps\nCONTAINER ID   IMAGE                    COMMAND               CREATED      STATUS          PORTS                    NAMES\n2096fba19e2a   datacap:latest           \"sh ./bin/debug.sh\"   5 days ago   Up 14 seconds   0.0.0.0:9909-&gt;9096/tcp   datacap\n</code></pre>"},{"location":"reference/get_started/install_containers.html#cleaning-up","title":"Cleaning up","text":"<p>You can stop and start the container, using the <code>docker stop datacap</code> and <code>docker start datacap</code> commands. To fully remove the stopped container, run <code>docker rm datacap</code>.</p>"},{"location":"reference/get_started/install_rainbond.html","title":"Deploying in Rainbond","text":"<p>If you are unfamiliar with Kubernetes, and want to install DataCap in Kubernetes, you can use Rainbond to deploy. Rainbond is a cloud-native application management platform built on Kubernetes and simplifies the application deployment to Kubernetes.</p>"},{"location":"reference/get_started/install_rainbond.html#prerequisite","title":"Prerequisite","text":"<p>To install Rainbond, please refer to Rainbond Quick Install.</p>"},{"location":"reference/get_started/install_rainbond.html#deploy-datacap","title":"Deploy DataCap","text":"<p>DataCap has been released to the Rainbond Open Source App Store, DataCap can be deployed with one click through the Rainbond Open Source App Store.</p> <p>Go to the Rainbond Console's <code>Platform Management -&gt; App Marketplace -&gt; Open Source App Store</code> and search for <code>datacap</code> and install it.</p> <p></p> <p>Fill in the following information, and click <code>Confirm</code> button to install.</p> <ul> <li>Team: select a team or create a new team</li> <li>Cluster: select a cluster</li> <li>Application: select an application or create a new application</li> <li>Version: select a version</li> </ul> <p>After installation, DataCap can be accessed through the default domain name provided by Rainbond, Default user password <code>admin/12345678</code></p> <p></p>"},{"location":"reference/get_started/query.html","title":"Query","text":"<p>After entering the software UI interface, click the <code>Query</code> menu option at the top, and you will enter a page similar to the following:</p> <p></p>"},{"location":"reference/get_started/query.html#description","title":"Description","text":"<p>The query page is divided into two parts: the upper part is the SQL editor, and the lower part is the query result</p> <p></p> <p>There are 4 function boxes at the top of the editor, they are:</p> <ul> <li>The first one: <code>selection box</code> is used to select the data source we have created</li> <li>The second: <code>button</code> is to perform the operation</li> <li>The third: <code>button</code> is to format the SQL content we entered</li> <li>The fourth: <code>button</code> is used to cancel the query that takes too long to execute</li> </ul> <p>Danger</p> <p>The cancel function does not mean that the actual query is over, and the query will continue to run in the background.</p>"},{"location":"reference/get_started/query.html#example","title":"Example","text":"<p>We use the following SQL for testing</p> <pre><code>show databases\n</code></pre> <p>After we write the SQL into the editor, click the second function button at the top of the editor to run it. After running, a window similar to the following will be displayed:</p> <p></p> <p>The result window is divided into: the top menu is the data export function, which currently supports <code>CSV</code> export, and the lower part is the data result display.</p> <p>Note</p> <p>The specific result display content is returned according to the SQL query by the user</p>"},{"location":"reference/get_started/query.html#data-output","title":"Data output","text":"<p>Move the mouse to the top menu of the result display area, and a drop-down box will appear. Click the type to be exported, and a download dialog box will pop up, and the data can be downloaded to the local.</p>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html","title":"SHOW CONSUMERS","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW CONSUMERS\nSHOW CONSUMERS FROM topic\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html#description","title":"Description","text":"<p>Returns a list of all defined consumers in the current cluster (if a topic is specified, a list of consumers for the specified topic will be returned). Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html","title":"SHOW DATABASES","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW DATABASES\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html#description","title":"Description","text":"<p>Returns a list of all defined topics in the current cluster. Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html","title":"SHOW TABLES","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW TABLES\nSHOW TABLES FROM `database`\n</code></pre> <p><code>database</code> kafka topic name</p>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html#description","title":"Description","text":"<p>Returns a list of all defined consumers in the current cluster (if a topic is specified, a list of consumers for the specified topic will be returned). Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html","title":"SHOW TOPICS","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW TOPICS\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html#description","title":"Description","text":"<p>Returns a list of all defined topics in the current cluster. Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"release/1.0.0.20221015.html","title":"1.0.0.20221015","text":"<p>Note</p> <p>This is the first new version we've released.</p> <p> DataCap is released </p> Release Version Release Time <code>1.0.0.20221015</code> <code>2022-10-15</code>"},{"location":"release/1.0.0.20221015.html#general","title":"General","text":"<ul> <li>Building SPI supports multiple data sources</li> <li>Supports web visualization based on Vue architecture</li> <li>Support Data source usage history</li> <li>Data statistics for data sources and history</li> </ul>"},{"location":"release/1.0.0.20221015.html#plugins","title":"Plugins","text":"<ul> <li> Support ClickHouse</li> <li> Support MySQL</li> <li> Support Presto</li> <li> Support Redis</li> <li> Support PostgreSQL</li> <li> Support Trino</li> <li> Support ElasticSearch</li> <li> Support Apache Druid</li> <li> Support Apache Kyuubi</li> <li> Support Apache Hive</li> <li> Support Apache Kylin</li> <li> Support Apache Ignite</li> <li> Support IBM DB2</li> </ul>"},{"location":"release/1.0.0.20221015.html#thank-you","title":"Thank you","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @mlboy @qianmoQ"},{"location":"release/1.1.0.20221115.html","title":"1.1.0.20221115","text":"<p>Note</p> <p>The current release involves several major updates. The following link is Roadmap</p> <p> DataCap is released </p> Release Version Release Time <code>1.1.0.20221115</code> <code>2022-11-15</code>"},{"location":"release/1.1.0.20221115.html#general","title":"General","text":"<ul> <li>Replace plugin name to id</li> <li>Support for internationalization issues-82</li> <li>Reduce size of docker image</li> <li>Switch bash docker image to eclipse-temurin:8-jdk-focal</li> <li>Support ssl issues-75</li> <li>Extract the plug-in to get the global tool</li> <li>Support database write operation issues-70</li> <li>Supports user rights management</li> <li>Support code snippet issues-74</li> <li>Support editor auto completion</li> <li>Support to provide data source schema tree bar issues-106</li> <li>Support multiple editor issues-110</li> <li>Add profile for user</li> <li>Support change user password</li> <li>Add data source radar map within 7 days</li> <li>Add about page</li> <li>Add feedback issues-126</li> </ul>"},{"location":"release/1.1.0.20221115.html#spi","title":"SPI","text":"<ul> <li>Add custom validator</li> </ul>"},{"location":"release/1.1.0.20221115.html#plugins","title":"Plugins","text":"<ul> <li>Support MongoDB</li> <li>Support Dremio</li> <li>Support HBase jdbc for Phoenix issues-103</li> <li>Support H2</li> <li>Support SqlServer</li> <li>Support Oracle</li> </ul>"},{"location":"release/1.1.0.20221115.html#redis","title":"Redis","text":"<ul> <li>Fix cannot init RedisConnection issues-71</li> </ul>"},{"location":"release/1.1.0.20221115.html#elasticsearch","title":"ElasticSearch","text":"<ul> <li>Update version to <code>7.10.0</code></li> </ul>"},{"location":"release/1.1.0.20221115.html#kyuubi","title":"Kyuubi","text":"<ul> <li>Bump Kyuubi <code>1.6.0-incubating</code></li> </ul>"},{"location":"release/1.1.0.20221115.html#thank-you","title":"Thank you","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @pan3793 @javalover123 @shuangzishuai @GtoCm @why198852 @qianmoQ"},{"location":"release/1.10.0.html","title":"1.10.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.10.0</code> <code>2023-05-30</code>"},{"location":"release/1.10.0.html#general","title":"General","text":"<ul> <li>Fix service start default connection mongo</li> <li>Fixed h2 db update_time and create_time for sql template</li> <li>Improve the H2 metadata management to obtain type</li> <li>Improve the mysql metadata management to obtain type</li> <li>Fixed metadata management data page default to 1</li> <li>Reconstruct the data render table</li> <li>Support column type</li> <li>Add time consuming and view executing SQL</li> <li>Support for selectable totals per page</li> <li>Supports header hint data types</li> <li>Supports replication of selected data results</li> <li>Support for selecting specified column queries</li> <li>Support filter</li> <li>Fixed the default user creation time being null</li> <li>Support Permission</li> <li>Fixed user createTime is null</li> </ul>"},{"location":"release/1.10.0.html#web","title":"Web","text":"<ul> <li>None Network authorization information is not cleared</li> <li>Optimize data management to obtain data</li> <li>Disable warnings output to console</li> <li>Increased editor buffering prompt limit</li> <li>Removes the default collation rule</li> <li>Rename user dashboard path</li> <li>Add dashboard chat style</li> <li>Fix navigation style</li> <li>Add data source load state</li> </ul>"},{"location":"release/1.10.0.html#plugins","title":"Plugins","text":"<ul> <li>Support apache pinot</li> <li>Support mongo community</li> </ul>"},{"location":"release/1.10.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump clickhouse-jdbc from <code>0.3.2-patch9</code> to <code>0.4.6</code></li> <li>Bump oracle-xe from <code>1.17.6</code> to <code>1.18.1</code></li> <li>Bump kyuubi-hive-jdbc-shaded from <code>1.6.0-incubating</code> to <code>1.7.1</code></li> </ul>"},{"location":"release/1.11.0.html","title":"1.11.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.11.0</code> <code>2023-06-13</code>"},{"location":"release/1.11.0.html#general","title":"General","text":"<ul> <li>The number of rows returned by the query history is added</li> <li>Fixed a 404 error on the home page</li> <li>Strip plugins into separate folders</li> </ul>"},{"location":"release/1.11.0.html#web","title":"Web","text":"<ul> <li>Refactor the folder</li> <li>Add menu breadcrumbs</li> <li>Synchronous server routing</li> <li>Add not login page</li> <li>Add source manager route</li> <li>Fixed the callback exception of route construction failure</li> <li>Fix data source type marker exception</li> </ul>"},{"location":"release/1.11.0.html#plugins","title":"Plugins","text":"<ul> <li>Support apache cassandra</li> </ul>"},{"location":"release/1.12.0.html","title":"1.12.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.12.0</code> <code>2023-07-11</code>"},{"location":"release/1.12.0.html#general","title":"General","text":"<ul> <li>Remove log default debug level</li> <li>Split module</li> <li>Fixed depend</li> <li>Support redirect for menu</li> <li>Fixed sql schema</li> <li>Support whether to function menu</li> <li>Replace openai sdk to <code>openai-java-sdk</code></li> <li>Refactor chat</li> </ul>"},{"location":"release/1.12.0.html#web","title":"Web","text":"<ul> <li>Fixed cache not clear, need to click again</li> <li>Fixed an error with invalid token</li> <li>Adds buffer tag name</li> <li>Fixed abnormal profile page using h2 database</li> <li>404 caused by repair service restart</li> </ul>"},{"location":"release/1.13.0.html","title":"1.13.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.13.0</code> <code>2023-08-09</code>"},{"location":"release/1.13.0.html#general","title":"General","text":"<ul> <li>Fixed <code>openai-java-sdk</code> version</li> <li>Add version for source</li> <li>Add a data source scan task</li> <li>Optimized status icon</li> <li>Remove support for built-in H2 database</li> </ul>"},{"location":"release/1.13.0.html#web","title":"Web","text":"<ul> <li>Support text</li> <li>Fix div white-space</li> <li>Added calendar heatmap chinease</li> <li>Fixed data contribution graph error</li> <li>When the data source is not available list disables selection</li> </ul>"},{"location":"release/1.13.0.html#kyuubi","title":"Kyuubi","text":"<ul> <li>Fix unable to execute set syntax sql</li> <li>Fix connection not closed</li> </ul>"},{"location":"release/1.13.0.html#oracle","title":"Oracle","text":"<ul> <li>Support get DBName and TableName</li> </ul>"},{"location":"release/1.13.0.html#clickhouse","title":"Clickhouse","text":"<ul> <li>Fixed no query errors in the <code>default</code> database</li> </ul>"},{"location":"release/1.14.0.html","title":"1.14.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.14.0</code> <code>2023-09-14</code>"},{"location":"release/1.14.0.html#general","title":"General","text":"<ul> <li>Fix the issue where the data source check task returns an empty</li> <li>Add captcha</li> <li>Support login verification code</li> <li>Automatic refresh of verification code failure is supported</li> <li>Support signup verification code</li> <li>Support signup enable</li> <li>Move etc to configure</li> </ul>"},{"location":"release/1.14.0.html#web","title":"Web","text":"<ul> <li>Fixed empty editor destruction exception</li> <li>Global public page adds layout</li> <li>Fixed the profile page error</li> <li>Fixed the abnormal login page style</li> </ul>"},{"location":"release/1.14.0.html#pipeline-apache-seatunnel","title":"Pipeline (Apache Seatunnel)","text":"<ul> <li>Support kafka source and sink</li> <li>Support delete</li> <li>Build pipeline page</li> <li>Support submit</li> <li>Support SWITCH field type</li> <li>Add executor logo</li> <li>Supports traffic limiting queuing</li> <li>Support stop</li> <li>Reset the pipeline when the service restarts</li> <li>Add logging interface and optimize UI</li> <li>Support field description</li> <li>Support field select type</li> <li>Support field checker</li> <li>Support field array</li> <li>Support redis sink</li> <li>Supports specifying the runtime mechanism</li> </ul>"},{"location":"release/1.14.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump com.google.guava:guava from 31.1-jre to 32.1.2-jre</li> <li>Bump org.devlive.sdk:openai-java-sdk from 1.5.0 to 1.9.0</li> <li>Bump com.h2database:h2 from 2.1.214 to 2.2.220</li> <li>Bump org.projectlombok:lombok from 1.18.24 to 1.18.28</li> <li>Bump org.apache.kafka:kafka-clients from 2.8.0 to 2.8.1</li> <li>Bump org.duckdb:duckdb_jdbc from 0.7.0 to 0.8.1</li> <li>Bump com.github.eirslett:frontend-maven-plugin from 1.12.1 to 1.13.4</li> <li>Bump kotlin.version from 1.8.20 to 1.9.10</li> <li>Bump org.sonatype.plugins:nexus-staging-maven-plugin from 1.6 to 1.6.13</li> </ul>"},{"location":"release/1.15.0.html","title":"1.15.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.15.0</code> <code>2023-10-18</code>"},{"location":"release/1.15.0.html#general","title":"General","text":"<ul> <li>Support database synchronization</li> <li>Support table synchronization</li> <li>Support column synchronization</li> <li>Add scheduler history</li> <li>Refactor metadata module</li> <li>Improve SQL files</li> </ul>"},{"location":"release/1.15.0.html#editor","title":"Editor","text":"<ul> <li>Replace <code>monaco</code> to <code>ace</code></li> </ul>"},{"location":"release/1.15.0.html#docs","title":"Docs","text":"<ul> <li>Add deployment documents in Chinese</li> <li>Refine the fragment and data source Chinese documentation</li> </ul>"},{"location":"release/1.2.0.html","title":"1.2.0","text":"<p>Note</p> <p>The current release involves several major updates. The following link is Roadmap</p> <p> DataCap is released </p> Release Version Release Time <code>1.2.0</code> <code>2022-11-30</code>"},{"location":"release/1.2.0.html#general","title":"General","text":"<ul> <li>Support http protocol</li> </ul>"},{"location":"release/1.2.0.html#web","title":"Web","text":"<ul> <li>Support for data result column header hiding (#139)</li> <li>Support data result filtering (#132 #140)</li> <li>Replace <code>@antv/g2</code> to <code>echarts</code></li> <li>Replace <code>ant-design-vue</code> to <code>iview</code></li> <li>Replace <code>@antv/s2</code> to <code>ag-grid</code></li> <li>Optimize about page</li> <li>Optimize not found page</li> <li>Add not authorized page</li> <li>Add version badge</li> <li>Add not network page</li> <li>Support result visual line chart</li> </ul>"},{"location":"release/1.2.0.html#plugins","title":"Plugins","text":"<ul> <li>Support cratedb</li> <li>Support cratedb for http</li> <li>Support dameng</li> <li>Support clickhouse for http</li> <li>Support tdengine for jdbc</li> <li>Support impala for jdbc</li> </ul>"},{"location":"release/1.2.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.3.0.html","title":"1.3.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.3.0</code> <code>2022-12-16</code>"},{"location":"release/1.3.0.html#general","title":"General","text":"<ul> <li>Support change username</li> <li>Support custom sql template</li> <li>Support plugin function</li> <li>Add restart script</li> </ul>"},{"location":"release/1.3.0.html#web","title":"Web","text":"<ul> <li>Optimize the presentation of the data source list</li> <li>Add data source description and prompt</li> <li>Support query history id order</li> <li>Support quote query history</li> </ul>"},{"location":"release/1.3.0.html#plugins","title":"Plugins","text":"<ul> <li>Support oceanbase for jdbc</li> <li>Support redis for native</li> <li>Support neo4j for jdbc</li> <li>Support iotdb for jdbc</li> </ul>"},{"location":"release/1.3.0.html#redis","title":"Redis","text":"<ul> <li>Support auth for native</li> </ul>"},{"location":"release/1.3.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.4.0.html","title":"1.4.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.4.0</code> <code>2023-01-31</code>"},{"location":"release/1.4.0.html#general","title":"General","text":"<ul> <li>Fixed restart script</li> <li>Supports monitor process</li> <li>Do not modify the default system SQL template</li> <li>Fixed plugin template by name</li> <li>Support user login log</li> <li>Refactoring plug-in configuration extraction mode</li> </ul>"},{"location":"release/1.4.0.html#experimental","title":"Experimental","text":"<ul> <li>Support data source manager</li> <li>Add client cli</li> </ul>"},{"location":"release/1.4.0.html#web","title":"Web","text":"<ul> <li>Plug-in ICONS are displayed based on the plug-in type</li> <li>Optimize editor auto prompt</li> <li>Support watermark</li> <li>Templates are not supported for adding data sources</li> <li>Fixed footer link</li> </ul>"},{"location":"release/1.4.0.html#plugins","title":"Plugins","text":"<ul> <li>Support snowflake for jdbc</li> <li>Support ydb for jdbc</li> </ul>"},{"location":"release/1.4.0.html#docs","title":"Docs","text":"<ul> <li>Refactor some docs</li> </ul>"},{"location":"release/1.4.0.html#redis-native","title":"Redis (Native)","text":"<ul> <li>Fixed command multiple parameters</li> </ul>"},{"location":"release/1.4.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ @hometownglory"},{"location":"release/1.5.0.html","title":"1.5.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.5.0</code> <code>2023-02-16</code>"},{"location":"release/1.5.0.html#general","title":"General","text":"<ul> <li>Support dsl query</li> <li>Remove incubator</li> <li>Add sql parser</li> <li>Refactor the module directories</li> <li>Set port default value is 0</li> </ul>"},{"location":"release/1.5.0.html#spi","title":"SPI","text":"<ul> <li>Fixed jdbc no password exception is configured</li> </ul>"},{"location":"release/1.5.0.html#web","title":"Web","text":"<ul> <li>Support multi column sort</li> </ul>"},{"location":"release/1.5.0.html#plugins","title":"Plugins","text":"<ul> <li>Support zookeeper for native</li> </ul>"},{"location":"release/1.5.0.html#docs","title":"Docs","text":"<ul> <li>Add powered by page</li> </ul>"},{"location":"release/1.5.0.html#redis-native","title":"Redis (Native)","text":"<ul> <li>Fixed mget,hget value is displayed as null #219</li> </ul>"},{"location":"release/1.5.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump maven-javadoc-plugin from 2.10.4 to 3.4.1</li> <li>Bump ojdbc8 from 21.1.0.0 to 21.9.0.0</li> <li>Bump mongodb-jdbc from 2.0.0 to 2.0.2</li> </ul>"},{"location":"release/1.5.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.6.0.html","title":"1.6.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.6.0</code> <code>2023-03-02</code>"},{"location":"release/1.6.0.html#general","title":"General","text":"<ul> <li>Add logo</li> <li>Support <code>SHOW PATHS xxx</code></li> <li>Fixed function time field</li> <li>Refactor all module</li> <li>Add http lib</li> <li>Add logger lib</li> </ul>"},{"location":"release/1.6.0.html#spi","title":"SPI","text":"<ul> <li>JDBC: Repair Connection failure Do not close the connection</li> </ul>"},{"location":"release/1.6.0.html#web","title":"Web","text":"<ul> <li>Add default watermark</li> <li>Remove about page</li> <li>Add routing permission control</li> <li>Optimize lazy loading of the tree menu of the query page</li> </ul>"},{"location":"release/1.6.0.html#plugins","title":"Plugins","text":"<ul> <li>Support duckdb for jdbc close #249</li> <li>Support alioss for native #250</li> </ul>"},{"location":"release/1.6.0.html#zookeeper-native","title":"Zookeeper (Native)","text":"<ul> <li>Support <code>SHOW PATHS</code></li> </ul>"},{"location":"release/1.6.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump maven-javadoc-plugin from <code>3.4.1</code> to <code>3.5.1</code></li> <li>Bump oceanbas-client from <code>2.4.0</code> to <code>2.4.2</code></li> </ul>"},{"location":"release/1.6.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @why198852 @mlboy @qianmoQ"},{"location":"release/1.7.0.html","title":"1.7.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.7.0</code> <code>2023-03-20</code>"},{"location":"release/1.7.0.html#general","title":"General","text":"<ul> <li>Add other issues template</li> <li>Add role</li> <li>Upgrade JDK <code>8</code> to <code>11</code></li> <li>Support chatgpt</li> <li>Add submit pipeline api</li> </ul>"},{"location":"release/1.7.0.html#experimental","title":"Experimental","text":"<ul> <li>Add seatunnel executor</li> </ul>"},{"location":"release/1.7.0.html#client","title":"Client","text":"<ul> <li>Support execute sql on source</li> <li>Fixed code bugs</li> </ul>"},{"location":"release/1.7.0.html#docs","title":"Docs","text":"<ul> <li>Add icon to connectors</li> </ul>"},{"location":"release/1.7.0.html#spi","title":"SPI","text":"<ul> <li>Add executor spi</li> </ul>"},{"location":"release/1.7.0.html#web","title":"Web","text":"<ul> <li>Fixed duplicate tree menu data</li> <li>Optimized type display icon</li> <li>Optimize data source testing\uff5csave interaction</li> <li>Support query history display plug-in type</li> <li>Add system announcement display</li> <li>Fixed the 'keyword' is repeated with tab page addition bug #208</li> <li>Replace markdown preview component</li> </ul>"},{"location":"release/1.7.0.html#plugins","title":"Plugins","text":"<ul> <li>Support kafka</li> </ul>"},{"location":"release/1.7.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Upgrade redis version from <code>3.6.3</code> to <code>4.3.1</code></li> <li>Bump maven-assembly-plugin from <code>3.1.1</code> to <code>3.5.0</code> #272</li> <li>Bump antlr4.version from <code>4.9.3</code> to <code>4.12.0</code> #262</li> <li>Bump jedis from <code>3.6.3</code> to <code>4.3.1</code> #254</li> <li>Bump DmJdbcDriver18 from <code>8.1.2.141</code> to <code>8.1.2.192</code> #234</li> </ul>"},{"location":"release/1.7.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @why198852 @Stacey1018 @qianmoQ"},{"location":"release/1.8.0.html","title":"1.8.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.8.0</code> <code>2023-04-10</code>"},{"location":"release/1.8.0.html#general","title":"General","text":"<ul> <li>Rename executor directory</li> <li>Optimize document release timing</li> <li>Fixed format connect url close #304</li> <li>Support proxy for chatgpt close #299</li> <li>ChatGPT is currently unable to associate context close #298</li> <li>Support returning parsing error results</li> <li>Add schedule lib</li> <li>Support the code editor supports automatic prompts for data source library tables and columns close #301</li> <li>Fix initialization sql script</li> <li>Support h2 database</li> <li>Remove some invalid jars</li> <li>Add docker publish ci</li> </ul>"},{"location":"release/1.8.0.html#docs","title":"Docs","text":"<ul> <li>Refactor install docs</li> </ul>"},{"location":"release/1.8.0.html#web","title":"Web","text":"<ul> <li>The code editor supports code fragments close #300</li> </ul>"},{"location":"release/1.8.0.html#plugins","title":"Plugins","text":"<ul> <li>Support h2 for native (memory)</li> </ul>"},{"location":"release/1.8.0.html#kafka","title":"Kafka","text":"<ul> <li>Perfect test case</li> <li>Support <code>SHOW DATABASES</code> and <code>SHOW TABLES</code> ...</li> </ul>"},{"location":"release/1.8.0.html#oracle","title":"Oracle","text":"<ul> <li>Fixed validation sql content</li> </ul>"},{"location":"release/1.8.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump jackson.version from <code>2.13.4</code> to <code>2.14.2</code></li> <li>Bump postgresql from <code>42.5.0</code> to <code>42.6.0</code></li> </ul>"},{"location":"release/1.8.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.9.0.html","title":"1.9.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.9.0</code> <code>2023-05-04</code>"},{"location":"release/1.9.0.html#general","title":"General","text":"<ul> <li>Support github publish packages</li> <li>Optimized the docker image publishing process</li> <li>Support format date</li> <li>Add a connection to the database to specify the time zone</li> <li>Fixed default h2 database uninitialized scheduled task</li> <li>Add admin user to README.md</li> <li>Add docker image label</li> <li>Add wechat qr to README.md</li> <li>Add docker badge</li> <li>Fixed source create time is null</li> </ul>"},{"location":"release/1.9.0.html#docs","title":"Docs","text":"<ul> <li>Add chinese index</li> <li>Add the Rainbond deployment document</li> <li>Add plugin docs</li> <li>Top scrolling notifications are supported</li> </ul>"},{"location":"release/1.9.0.html#web","title":"Web","text":"<ul> <li>Fix invalid paging of data table</li> <li>Fixed not rendering properly</li> <li>Fix missing translation results for rendering containing translational data</li> <li>Support copy multiple selection rows</li> <li>Fix data source test status issues</li> <li>Support close message</li> <li>Add schedule link</li> </ul>"},{"location":"release/1.9.0.html#plugins","title":"Plugins","text":"<ul> <li>Support ceresdb</li> <li>Support greptimedb</li> <li>Support questdb</li> <li>Support apache doris</li> <li>Support starrocks</li> <li>Support hologres</li> <li>Support apache hadoop hdfs</li> </ul>"},{"location":"release/1.9.0.html#spi","title":"SPI","text":"<ul> <li>Remove http retry logic</li> </ul>"},{"location":"release/1.9.0.html#yandex-database","title":"Yandex Database","text":"<ul> <li>Fixed ydb dependency conflicts</li> </ul>"},{"location":"release/1.9.0.html#trino","title":"Trino","text":"<ul> <li>Add configure</li> </ul>"},{"location":"release/1.9.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump trino-jdbc from <code>397</code> to <code>414</code> (#331)</li> <li>Bump iotdb-jdbc from <code>0.13.0</code> to <code>1.1.0</code> (#309)</li> </ul>"},{"location":"release/1.9.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/latest.html","title":"1.16.0 (latest)","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p>DataCap is released!</p> Release Version Release Time <code>1.16.0</code> <code>2023-11-01</code>"},{"location":"release/latest.html#general","title":"General","text":"<ul> <li>Support column order </li> <li>Support delete rows</li> <li>Support delete multiple rows </li> <li>Supports data update without primary key </li> <li>Supports data update with primary key </li> <li>Support preview pending changes</li> </ul>"},{"location":"release/latest.html#editor","title":"Editor","text":"<ul> <li>Support selection query </li> <li>Support custom configure </li> </ul>"},{"location":"release/latest.html#docs","title":"Docs","text":"<ul> <li>Add user profile doc</li> </ul>"},{"location":"release/latest.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump org.apache.maven.plugins:maven-javadoc-plugin from <code>3.5.0</code> to <code>3.6.0</code></li> <li>Bump com.oceanbase:oceanbase-client from <code>2.4.2</code> to <code>2.4.5</code></li> <li>Bump org.apache.maven.plugins:maven-javadoc-plugin from <code>3.5.0</code> to <code>3.6.0</code></li> </ul>"},{"location":"resources/functions/home.html","title":"Functions","text":"<ul> <li> <p>ClickHouse</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>MySQL</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>Hive</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>Trino &amp; Presto</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> </ul>"},{"location":"zh/index.html","title":"DataCap","text":"DataCap \u662f\u7528\u4e8e\u6570\u636e\u8f6c\u6362\u3001\u96c6\u6210\u548c\u53ef\u89c6\u5316\u7684\u96c6\u6210\u8f6f\u4ef6\u3002\u652f\u6301\u591a\u79cd\u6570\u636e\u6e90\u3001\u6587\u4ef6\u7c7b\u578b\u3001\u5927\u6570\u636e\u76f8\u5173\u6570\u636e\u5e93\u3001\u5173\u7cfb\u6570\u636e\u5e93\u3001NoSQL\u6570\u636e\u5e93\u7b49\u3002\u901a\u8fc7\u8f6f\u4ef6\u53ef\u4ee5\u5b9e\u73b0\u591a\u6570\u636e\u6e90\u7684\u7ba1\u7406\uff0c\u5bf9\u6e90\u4e0b\u7684\u6570\u636e\u8fdb\u884c\u5404\u79cd\u64cd\u4f5c\u8f6c\u6362\u3001\u5236\u4f5c\u6570\u636e\u56fe\u8868\u3001\u76d1\u63a7\u6570\u636e\u6e90\u548c\u5176\u4ed6\u529f\u80fd\u3002               \u9a6c\u4e0a\u5f00\u59cb             \u4e0b\u8f7d             \u5728 GitHub \u4e0a\u52a0\u5165\u6211\u4eec             \u67e5\u770b\u5728\u7ebf Demo"},{"location":"zh/index.html#_1","title":"\u6982\u8ff0","text":"<p> Datacap \u662f\u5feb\u901f\u3001\u8f7b\u91cf\u7ea7\u3001\u76f4\u89c2\u7684\u7cfb\u7edf\u3002 </p> <ul> <li> <p>\u529f\u80fd\u5f3a\u5927\u4f46\u6613\u4e8e\u4f7f\u7528 </p> <p>\u4f7f\u7528\u7b80\u5355\u7684 SQL IDE \u5feb\u901f\u8f7b\u677e\u5730\u96c6\u6210\u548c\u63a2\u7d22\u60a8\u7684\u6570\u636e\u3002</p> </li> <li> <p>\u4e0e\u73b0\u4ee3\u6570\u636e\u5e93\u96c6\u6210</p> <p>DataCap \u53ef\u4ee5\u901a\u8fc7 JDBC, Native, Http \u8fde\u63a5\u5230\u4efb\u4f55\u57fa\u4e8e SQL \u7684\u6570\u636e\u6e90\u3002</p> </li> <li> <p>\u9ad8\u5ea6\u5b9a\u5236\u5316</p> <p>DataCap \u53ef\u4ee5\u901a\u8fc7\u5b9e\u73b0 SPI \u63d0\u4f9b\u7684\u65b9\u5f0f\u53ef\u4ee5\u5b9e\u73b0\u5feb\u901f\u5bf9\u63a5\u65b0\u7684\u6570\u636e\u6e90\u3002</p> </li> <li> <p>\u52a0\u5165 (\u9489\u9489 \uff5c \u5fae\u4fe1)</p> <p> </p> </li> </ul>"},{"location":"zh/index.html#_2","title":"\u652f\u6301\u7684\u8fde\u63a5\u5668","text":""},{"location":"zh/powered_by.html","title":"\u4f7f\u7528\u6848\u4f8b","text":"\u6dfb\u52a0\u60a8\u7684\u6216\u516c\u53f8 <p>Note</p> <p>\u6709\u8bb8\u591a\u516c\u53f8\uff0c\u4e2a\u4eba\u548c\u5f00\u6e90\u7ec4\u7ec7\u4f7f\u7528\u6b64\u7a0b\u5e8f\u3002\u4e0b\u9762\u5217\u51fa\u4e86\u5176\u4e2d\u4e00\u4e9b\u3002</p>"},{"location":"zh/powered_by.html#_1","title":"\u5f00\u6e90\u9879\u76ee","text":"<ul> <li> <p> DataCap developer</p> <p>DataCap \u662f\u7528\u4e8e\u6570\u636e\u8f6c\u6362\u3001\u96c6\u6210\u548c\u53ef\u89c6\u5316\u7684\u96c6\u6210\u8f6f\u4ef6\u3002   \u5f00\u59cb\u4f7f\u7528</p> </li> </ul>"},{"location":"zh/powered_by.html#_2","title":"\u4e2a\u4eba\u7528\u6237","text":"<ul> <li> <p> qianmoQ</p> <p>\u70ed\u7231\u5f00\u6e90\u9879\u76ee\u7684\u6e90\u4ee3\u7801\u8d21\u732e\u8005\u3002  \u8bbf\u95ee qianmoQ</p> </li> <li> <p> Stacey1018</p> <p>\u6211\u53ef\u4ee5\u5728\u96e8\u4e2d\u5ea6\u8fc7\u3002\u6211\u53ef\u4ee5\u81ea\u5df1\u518d\u6b21\u7ad9\u8d77\u6765\u3002  \u8bbf\u95ee Stacey1018</p> </li> </ul>"},{"location":"zh/developer_guide/plugin-java.html","title":"Java \u5b9e\u73b0","text":"<p>DataCap \u652f\u6301\u81ea\u5b9a\u4e49\u63d2\u4ef6\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u7f16\u5199\u81ea\u5df1\u7684\u63d2\u4ef6\u96c6\u6210\u5230\u7cfb\u7edf\u4e2d\u3002\u8be5\u6587\u6863\u4e3b\u8981\u8bb2\u89e3\u5982\u4f55\u5feb\u901f\u96c6\u6210\u4e00\u4e2a\u63d2\u4ef6\u5230 DataCap \u7cfb\u7edf\u4e2d\u3002</p> <p>Note</p> <p>\u672c\u6587\u4f7f\u7528\u96c6\u6210\u57fa\u4e8e HTTP \u534f\u8bae\u7684 QuestDB \u6570\u636e\u5b58\u50a8\u7cfb\u7edf\u6765\u6f14\u793a\u3002</p>"},{"location":"zh/developer_guide/plugin-java.html#pomxml","title":"<code>pom.xml</code> \u4f9d\u8d56","text":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-spi&lt;/artifactId&gt;\n    &lt;scope&gt;provided&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-common&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;commons-beanutils&lt;/groupId&gt;\n    &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.testcontainers&lt;/groupId&gt;\n    &lt;artifactId&gt;testcontainers&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>\u4ee5\u4e0a\u914d\u7f6e\u6dfb\u52a0\u4e86 <code>datacap-spi</code> \u548c <code>datacap-common</code> \u6a21\u5757\uff0c\u5176\u4ed6\u7684\u662f\u4e00\u4e9b\u8f85\u52a9\u4f9d\u8d56\u3002</p> <p>Warning</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\u5982\u679c\u60a8\u662f\u5355\u72ec\u5f00\u542f\u7684\u9879\u76ee\u9700\u8981\u6307\u5b9a\u5404\u4e2a\u4f9d\u8d56\u7684\u7248\u672c\u53f7\u3002</p>"},{"location":"zh/developer_guide/plugin-java.html#_1","title":"\u63d2\u4ef6\u52a0\u8f7d\u5668","text":"<pre><code>public class QuestDBPluginModule\n        extends AbstractPluginModule\n        implements PluginModule\n{\n    @Override\n    public String getName()\n    {\n        return \"QuestDB\";\n    }\n\n    @Override\n    public PluginType getType()\n    {\n        return PluginType.HTTP;\n    }\n\n    @Override\n    public AbstractPluginModule get()\n    {\n        return this;\n    }\n\n    protected void configure()\n    {\n        Multibinder&lt;Plugin&gt; plugin = Multibinder.newSetBinder(this.binder(), Plugin.class);\n        plugin.addBinding().to(QuestDBPlugin.class);\n    }\n}\n</code></pre> <p>\u52a0\u8f7d\u5668\u9700\u8981\u7ee7\u627f <code>AbstractPluginModule</code> \u7c7b\uff0c\u5e76\u5b9e\u73b0 <code>PluginModule</code> \u63a5\u53e3\uff0c\u8fd9\u6837\u7cfb\u7edf\u4f1a\u5728\u542f\u52a8\u65f6\u81ea\u52a8\u5c06\u63d2\u4ef6\u52a0\u8f7d\u5230\u7cfb\u7edf\u4e2d\u3002</p> <p>Note</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u9700\u8981\u8986\u76d6\u7236\u7c7b\u4e2d\u7684 <code>configure()</code> \u65b9\u6cd5\uff0c\u5e76\u5c06\u63d2\u4ef6\u7ed1\u5b9a\u5230\u7cfb\u7edf\u4e2d\u3002</p>"},{"location":"zh/developer_guide/plugin-java.html#_2","title":"\u63d2\u4ef6\u6267\u884c\u5668","text":"<pre><code>@Slf4j\npublic class QuestDBPlugin\n        implements Plugin\n{\n    private HttpConfigure configure;\n    private HttpConnection connection;\n    private Response response;\n\n    @Override\n    public String name()\n    {\n        return \"QuestDB\";\n    }\n\n    @Override\n    public String description()\n    {\n        return \"Integrate QuestDB data sources\";\n    }\n\n    @Override\n    public PluginType type()\n    {\n        return PluginType.HTTP;\n    }\n\n    @Override\n    public void connect(Configure configure)\n    {\n        try {\n            this.response = new Response();\n            this.configure = new HttpConfigure();\n            BeanUtils.copyProperties(this.configure, configure);\n            this.connection = new HttpConnection(this.configure, this.response);\n        }\n        catch (Exception ex) {\n            this.response.setIsConnected(Boolean.FALSE);\n            this.response.setMessage(ex.getMessage());\n        }\n    }\n\n    @Override\n    public Response execute(String content)\n    {\n        if (ObjectUtils.isNotEmpty(this.connection)) {\n            log.info(\"Execute questdb plugin logic started\");\n            this.response = this.connection.getResponse();\n            QuestDBAdapter processor = new QuestDBAdapter(this.connection);\n            this.response = processor.handlerExecute(content);\n            log.info(\"Execute questdb plugin logic end\");\n        }\n        this.destroy();\n        return this.response;\n    }\n\n    @Override\n    public void destroy()\n    {\n        if (ObjectUtils.isNotEmpty(this.connection)) {\n            this.connection.destroy();\n        }\n    }\n}\n</code></pre> <p>\u6267\u884c\u5668\u9700\u8981\u5b9e\u73b0 <code>Plugin</code> \u63a5\u53e3\uff0c\u8be5\u63a5\u53e3\u4e2d\u63d0\u4f9b\u4e86\u4ee5\u4e0b\u65b9\u6cd5</p> <ul> <li><code>name()</code>: \u63d2\u4ef6\u6709\u552f\u4e00\u540d\u79f0\uff0c\u540c\u540d\u63d2\u4ef6\u53ea\u4f1a\u5728\u7b2c\u4e00\u6b21\u52a0\u8f7d\u65f6\u751f\u6548</li> <li><code>description()</code>: \u5bf9\u4e8e\u8be5\u63d2\u4ef6\u7684\u63cf\u8ff0</li> <li><code>type()</code>: \u63d2\u4ef6\u7c7b\u578b</li> <li><code>connect(Configure configure)</code>: \u63d2\u4ef6\u9700\u8981\u63d0\u524d\u8fde\u63a5\u4fe1\u606f\uff0c\u6bd4\u5982\u5f53\u524d\u63d2\u4ef6\u63d2\u4ef6\uff0c\u5c31\u662f\u63d2\u4ef6\u7684\u8fde\u63a5\u9636\u6bb5\uff08\u7cfb\u7edf\u9884\u8bbe HTTP \u8fde\u63a5\u65b9\u5f0f\u76f4\u63a5\u4f7f\u7528\uff09\u3002</li> <li><code>execute(String content)</code>: \u5177\u4f53\u6267\u884c\u64cd\u4f5c\u903b\u8f91</li> <li><code>destroy()</code>:  \u63d2\u4ef6\u6700\u540e\u7684\u9500\u6bc1\uff0c\u6ce8\u610f\u9500\u6bc1\u9700\u8981\u5305\u542b\u8fde\u63a5\u4e2d\u7684\u4fe1\u606f</li> </ul>"},{"location":"zh/developer_guide/plugin-java.html#_3","title":"\u63d2\u4ef6\u8f6c\u6362\u5668","text":"<pre><code>@Slf4j\npublic class QuestDBAdapter\n        extends HttpAdapter\n{\n    public QuestDBAdapter(HttpConnection connection)\n    {\n        super(connection);\n    }\n\n    @Override\n    public Response handlerExecute(String content)\n    {\n        Time processorTime = new Time();\n        processorTime.setStart(new Date().getTime());\n        Response response = this.httpConnection.getResponse();\n        HttpConfigure configure = new HttpConfigure();\n        if (response.getIsConnected()) {\n            List&lt;String&gt; headers = new ArrayList&lt;&gt;();\n            List&lt;String&gt; types = new ArrayList&lt;&gt;();\n            List&lt;Object&gt; columns = new ArrayList&lt;&gt;();\n            try {\n                BeanUtils.copyProperties(configure, this.httpConnection.getConfigure());\n                configure.setAutoConnected(Boolean.FALSE);\n                configure.setRetry(0);\n                configure.setMethod(HttpMethod.GET);\n                configure.setPath(\"exec\");\n                Map&lt;String, String&gt; parameters = Maps.newHashMap();\n                parameters.put(\"query\", content);\n                configure.setParams(parameters);\n                configure.setDecoded(true);\n                HttpConnection httpConnection = new HttpConnection(configure, new Response());\n                HttpClient httpClient = HttpClient.getInstance(configure, httpConnection);\n                String body = httpClient.execute();\n                QuestDBResponse requestResponse = JSON.objectmapper.readValue(body, QuestDBResponse.class);\n                if (ObjectUtils.isNotEmpty(requestResponse.getQuery())) {\n                    response.setIsSuccessful(true);\n                    if (ObjectUtils.isNotEmpty(requestResponse.getColumns())) {\n                        requestResponse.getColumns()\n                                .forEach(schema -&gt; {\n                                    headers.add(schema.getName());\n                                    types.add(schema.getType());\n                                });\n                    }\n                    requestResponse.getDataset()\n                            .forEach(record -&gt; columns.add(handlerFormatter(configure.getFormat(), headers, record)));\n                }\n                else {\n                    response.setIsSuccessful(Boolean.FALSE);\n                    response.setMessage(requestResponse.getError());\n                }\n            }\n            catch (Exception ex) {\n                log.error(\"Execute content failed content {} exception \", content, ex);\n                response.setIsSuccessful(Boolean.FALSE);\n                response.setMessage(ex.getMessage());\n            }\n            finally {\n                response.setHeaders(headers);\n                response.setTypes(types);\n                response.setColumns(columns);\n            }\n        }\n        processorTime.setEnd(new Date().getTime());\n        response.setProcessor(processorTime);\n        return response;\n    }\n}\n</code></pre> <p>\u63d2\u4ef6\u8f6c\u6362\u5668\u7528\u4e8e\u5bf9\u5f53\u524d\u63d2\u4ef6\u6267\u884c\u540e\u7684\u7ed3\u679c\u7684\u8f6c\u5316\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a DataCap \u4e2d\u53ef\u4ee5\u4f7f\u7528\u7684\u903b\u8f91\u3002\u4e3b\u8981\u662f\u7528\u4e8e\u5c01\u88c5 <code>Response</code> \u8fd4\u56de\u7ed3\u679c\u3002</p> <p>\u672c\u6587\u662f\u57fa\u4e8e JDBC \u7684\u63d2\u4ef6\u6240\u4ee5\u76f4\u63a5\u7ee7\u627f <code>HttpAdapter</code> \u7236\u7c7b\u5373\u53ef\u5b9e\u73b0\u90e8\u5206\u529f\u80fd\u3002</p>"},{"location":"zh/developer_guide/plugin-java.html#spi","title":"SPI \u52a0\u8f7d\u5668","text":"<p>\u5728 <code>resources</code> \u6e90\u76ee\u5f55\u4e0b\u6dfb\u52a0 <code>META-INF</code> \u548c <code>services</code> \u76ee\u5f55</p> <p>Warning</p> <p><code>services</code> \u5728 <code>resources</code> \u76ee\u5f55\u4e2d\u9700\u8981</p> <p>\u521b\u5efa <code>io.edurt.datacap.spi.PluginModule</code> \u6587\u4ef6\uff0c\u5185\u5bb9\u5982\u4e0b</p> <pre><code>io.edurt.datacap.plugin.http.questdb.QuestDBPluginModule\n</code></pre> <p>\u8be5\u6587\u4ef6\u7684\u5185\u5bb9\u662f\u6211\u4eec\u5b9a\u4e49\u597d\u7684\u63d2\u4ef6\u52a0\u8f7d\u6a21\u5757\u3002</p> <p>Warning</p> <p>\u63d2\u4ef6\u7684\u5355\u5143\u6d4b\u8bd5\u53ef\u4ee5\u53c2\u8003\u5df2\u7ecf\u53d1\u5e03\u7684\u63d2\u4ef6\u8fdb\u884c\u6d4b\u8bd5</p>"},{"location":"zh/developer_guide/plugin-kotlin.html","title":"Kotlin \u5b9e\u73b0","text":"<p>DataCap \u652f\u6301\u81ea\u5b9a\u4e49\u63d2\u4ef6\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u7f16\u5199\u81ea\u5df1\u7684\u63d2\u4ef6\u96c6\u6210\u5230\u7cfb\u7edf\u4e2d\u3002\u8be5\u6587\u6863\u4e3b\u8981\u8bb2\u89e3\u5982\u4f55\u5feb\u901f\u96c6\u6210\u4e00\u4e2a\u63d2\u4ef6\u5230 DataCap \u7cfb\u7edf\u4e2d\u3002</p> <p>Note</p> <p>\u672c\u6587\u4f7f\u7528\u96c6\u6210\u57fa\u4e8e JDBC \u534f\u8bae\u7684 StarRocks \u6570\u636e\u5b58\u50a8\u7cfb\u7edf\u6765\u6f14\u793a\u3002</p>"},{"location":"zh/developer_guide/plugin-kotlin.html#pomxml","title":"<code>pom.xml</code> \u4f9d\u8d56","text":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-spi&lt;/artifactId&gt;\n    &lt;scope&gt;provided&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-common&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;commons-beanutils&lt;/groupId&gt;\n    &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.testcontainers&lt;/groupId&gt;\n    &lt;artifactId&gt;testcontainers&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>\u4ee5\u4e0a\u914d\u7f6e\u6dfb\u52a0\u4e86 <code>datacap-spi</code> \u548c <code>datacap-common</code> \u6a21\u5757\uff0c\u5176\u4ed6\u7684\u662f\u4e00\u4e9b\u8f85\u52a9\u4f9d\u8d56\u3002</p> <p>Warning</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\u5982\u679c\u60a8\u662f\u5355\u72ec\u5f00\u542f\u7684\u9879\u76ee\u9700\u8981\u6307\u5b9a\u5404\u4e2a\u4f9d\u8d56\u7684\u7248\u672c\u53f7\u3002</p>"},{"location":"zh/developer_guide/plugin-kotlin.html#_1","title":"\u63d2\u4ef6\u52a0\u8f7d\u5668","text":"<pre><code>class StarRocksPluginModule : AbstractPluginModule(), PluginModule {\n    override fun getName(): String {\n        return \"StarRocks\"\n    }\n\n    override fun getType(): PluginType {\n        return PluginType.JDBC\n    }\n\n    override fun get(): AbstractPluginModule {\n        return this\n    }\n\n    override fun configure() {\n        val module = Multibinder.newSetBinder(binder(), String::class.java)\n        module.addBinding().toInstance(this.javaClass.simpleName)\n        val plugin: Multibinder&lt;Plugin&gt; = Multibinder.newSetBinder(binder(), Plugin::class.java)\n        plugin.addBinding().to(StarRocksPlugin::class.java)\n    }\n}\n</code></pre> <p>\u52a0\u8f7d\u5668\u9700\u8981\u7ee7\u627f <code>AbstractPluginModule</code> \u7c7b\uff0c\u5e76\u5b9e\u73b0 <code>PluginModule</code> \u63a5\u53e3\uff0c\u8fd9\u6837\u7cfb\u7edf\u4f1a\u5728\u542f\u52a8\u65f6\u81ea\u52a8\u5c06\u63d2\u4ef6\u52a0\u8f7d\u5230\u7cfb\u7edf\u4e2d\u3002</p> <p>Note</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u9700\u8981\u8986\u76d6\u7236\u7c7b\u4e2d\u7684 <code>configure()</code> \u65b9\u6cd5\uff0c\u5e76\u5c06\u63d2\u4ef6\u7ed1\u5b9a\u5230\u7cfb\u7edf\u4e2d\u3002</p>"},{"location":"zh/developer_guide/plugin-kotlin.html#_2","title":"\u63d2\u4ef6\u6267\u884c\u5668","text":"<pre><code>class StarRocksPlugin : Plugin {\n    private val log = getLogger(StarRocksPlugin::class.java)\n\n    private var jdbcConfigure: JdbcConfigure? = null\n    private var jdbcConnection: JdbcConnection? = null\n    private var jdbcResponse: Response? = null\n\n    override fun name(): String {\n        return \"StarRocks\"\n    }\n\n    override fun description(): String {\n        return \"Integrate StarRocks data sources\"\n    }\n\n    override fun type(): PluginType {\n        return PluginType.JDBC\n    }\n\n    override fun connect(configure: Configure?) {\n        try {\n            log.info(\"Connecting to StarRocks\")\n            jdbcResponse = Response()\n            jdbcConfigure = JdbcConfigure()\n            BeanUtils.copyProperties(jdbcConfigure, configure)\n            jdbcConfigure!!.jdbcDriver = \"com.mysql.cj.jdbc.Driver\"\n            jdbcConfigure!!.jdbcType = \"mysql\"\n            jdbcConnection = object : JdbcConnection(jdbcConfigure, jdbcResponse) {}\n        } catch (ex: Exception) {\n            jdbcResponse!!.isConnected = false\n            jdbcResponse!!.message = ex.message\n        }\n    }\n\n    override fun execute(content: String?): Response {\n        if (ObjectUtils.isNotEmpty(jdbcConnection)) {\n            log.info(\"Execute starrocks plugin logic started\")\n            jdbcResponse = jdbcConnection?.response\n            val processor = JdbcAdapter(jdbcConnection)\n            jdbcResponse = processor.handlerExecute(content)\n            log.info(\"Execute starrocks plugin logic end\")\n        }\n        destroy()\n        return jdbcResponse!!\n    }\n\n    override fun destroy() {\n        if (ObjectUtils.isNotEmpty(jdbcConnection)) {\n            jdbcConnection?.destroy()\n            jdbcConnection = null\n        }\n    }\n}\n</code></pre> <p>\u6267\u884c\u5668\u9700\u8981\u5b9e\u73b0 <code>Plugin</code> \u63a5\u53e3\uff0c\u8be5\u63a5\u53e3\u4e2d\u63d0\u4f9b\u4e86\u4ee5\u4e0b\u65b9\u6cd5</p> <ul> <li><code>name()</code>: \u63d2\u4ef6\u6709\u552f\u4e00\u540d\u79f0\uff0c\u540c\u540d\u63d2\u4ef6\u53ea\u4f1a\u5728\u7b2c\u4e00\u6b21\u52a0\u8f7d\u65f6\u751f\u6548</li> <li><code>description()</code>: \u5bf9\u4e8e\u8be5\u63d2\u4ef6\u7684\u63cf\u8ff0</li> <li><code>type()</code>: \u63d2\u4ef6\u7c7b\u578b</li> <li><code>connect(Configure configure)</code>: \u63d2\u4ef6\u9700\u8981\u63d0\u524d\u8fde\u63a5\u4fe1\u606f\uff0c\u6bd4\u5982\u5f53\u524d\u63d2\u4ef6\u63d2\u4ef6\uff0c\u5c31\u662f\u63d2\u4ef6\u7684\u8fde\u63a5\u9636\u6bb5\uff08\u7cfb\u7edf\u9884\u8bbe HTTP \u8fde\u63a5\u65b9\u5f0f\u76f4\u63a5\u4f7f\u7528\uff09\u3002</li> <li><code>execute(String content)</code>: \u5177\u4f53\u6267\u884c\u64cd\u4f5c\u903b\u8f91</li> <li><code>destroy()</code>:  \u63d2\u4ef6\u6700\u540e\u7684\u9500\u6bc1\uff0c\u6ce8\u610f\u9500\u6bc1\u9700\u8981\u5305\u542b\u8fde\u63a5\u4e2d\u7684\u4fe1\u606f</li> </ul>"},{"location":"zh/developer_guide/plugin-kotlin.html#_3","title":"\u63d2\u4ef6\u8f6c\u6362\u5668","text":"<p>\u63d2\u4ef6\u8f6c\u6362\u5668\u7528\u4e8e\u5bf9\u5f53\u524d\u63d2\u4ef6\u6267\u884c\u540e\u7684\u7ed3\u679c\u7684\u8f6c\u5316\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a DataCap \u4e2d\u53ef\u4ee5\u4f7f\u7528\u7684\u903b\u8f91\u3002\u4e3b\u8981\u662f\u7528\u4e8e\u5c01\u88c5 <code>Response</code> \u8fd4\u56de\u7ed3\u679c\u3002</p> <p>\u672c\u6587\u662f\u57fa\u4e8e JDBC \u7684\u63d2\u4ef6\u6240\u4ee5\u76f4\u63a5\u7ee7\u627f <code>JdbcAdapter</code> \u7236\u7c7b\u5373\u53ef\u5b9e\u73b0\u90e8\u5206\u529f\u80fd\u3002</p>"},{"location":"zh/developer_guide/plugin-kotlin.html#spi","title":"SPI \u52a0\u8f7d\u5668","text":"<p>\u5728 <code>resources</code> \u6e90\u76ee\u5f55\u4e0b\u6dfb\u52a0 <code>META-INF</code> \u548c <code>services</code> \u76ee\u5f55</p> <p>Warning</p> <p><code>services</code> \u5728 <code>resources</code> \u76ee\u5f55\u4e2d\u9700\u8981</p> <p>\u521b\u5efa <code>io.edurt.datacap.spi.PluginModule</code> \u6587\u4ef6\uff0c\u5185\u5bb9\u5982\u4e0b</p> <pre><code>io.edurt.datacap.plugin.jdbc.starrocks.StarRocksPluginModule\n</code></pre> <p>\u8be5\u6587\u4ef6\u7684\u5185\u5bb9\u662f\u6211\u4eec\u5b9a\u4e49\u597d\u7684\u63d2\u4ef6\u52a0\u8f7d\u6a21\u5757\u3002</p> <p>Warning</p> <p>\u63d2\u4ef6\u7684\u5355\u5143\u6d4b\u8bd5\u53ef\u4ee5\u53c2\u8003\u5df2\u7ecf\u53d1\u5e03\u7684\u63d2\u4ef6\u8fdb\u884c\u6d4b\u8bd5</p>"},{"location":"zh/developer_guide/pipeline/home.html","title":"\u6d41\u6c34\u7ebf","text":"<p>\u5728 DataCap \u7cfb\u7edf\u4e2d\uff0c\u6d41\u6c34\u7ebf\u529f\u80fd\u7528\u6237\u53ef\u4ee5\u968f\u610f\u914d\u7f6e\uff0c\u6839\u636e\u4f4e\u5c42\u6267\u884c\u5668\u7684\u7248\u672c\u53ef\u4ee5\u4efb\u610f\u8c03\u6574\uff0c\u7cfb\u7edf\u4f1a\u6839\u636e\u914d\u7f6e\u81ea\u52a8\u8bc6\u522b\u5e76\u7f16\u8bd1\u6700\u7ec8\u7684\u914d\u7f6e\u5e76\u53d1\u9001\u5230\u6267\u884c\u5668\u4e2d\u3002</p> <p>\u6211\u4eec\u53ef\u63d0\u4f9b\u7684\u914d\u7f6e\u6709:</p> \u5b57\u6bb5 \u7c7b\u578b \u63cf\u8ff0 <code>field</code> <code>String</code> \u5b57\u6bb5\u540d <code>origin</code> <code>String</code> \u9ed8\u8ba4\u7b49\u4e8e\u5b57\u6bb5\u503c\uff0c\u81ea\u5b9a\u4e49\u5217\u540d\u4f7f\u7528, \u5982\u679c\u662f <code>host|port</code> \u683c\u5f0f\uff0c\u7cfb\u7edf\u5c06\u4f1a\u5c06\u5b57\u6bb5\u901a\u8fc7 <code>:</code> \u8fdb\u884c\u62fc\u63a5 <code>required</code> <code>Boolean</code> \u5f53\u503c\u4e3a <code>true</code> \u65f6\uff0c\u8868\u793a\u8be5\u5b57\u6bb5\u4e3a\u5fc5\u586b\u9879 <code>override</code> <code>Boolean</code> \u5982\u679c\u8be5\u6807\u5fd7\u4e3a <code>true</code>\uff0c\u5219\u8868\u793a\u901a\u8fc7\u7528\u6237\u914d\u7f6e\u63d0\u53d6\u8be5\u5b57\u6bb5\uff0c\u9ed8\u8ba4\u6570\u636e\u5c06\u88ab\u4e22\u5f03 <code>input</code> <code>Boolean</code> \u662f\u5426\u4e3a\u8f93\u5165\u53c2\u6570 <code>width</code> <code>Integer</code> \u7ec4\u4ef6\u5bbd\u5ea6, \u9ed8\u8ba4 <code>300</code> <code>type</code> <code>FieldType</code> \u5b57\u6bb5\u7c7b\u578b, \u9ed8\u8ba4 <code>INPUT</code> <code>tooltip</code> <code>String</code> \u63d0\u793a\u4fe1\u606f <code>description</code> <code>String</code> \u63cf\u8ff0\u4fe1\u606f <code>value</code> <code>Object</code> \u5f53\u524d\u914d\u7f6e\u8f93\u5165\u7684\u7ed3\u679c <code>hidden</code> <code>Boolean</code> \u5982\u679c\u8be5\u914d\u7f6e\u9879\u4e3a <code>true</code>\uff0c\u5219\u524d\u7aef\u4e0d\u4f1a\u663e\u793a\uff0c\u542f\u7528\u540e\u624d\u4f1a\u663e\u793a\u3002 <code>defaultValues</code> <code>Array</code> \u5982\u679c\u7c7b\u578b\u4e3a SELECT \uff0c\u5219\u9700\u8981\u4f20\u5165\u9ed8\u8ba4\u6570\u636e <p>Danger</p> <p>\u6211\u4eec\u4e0d\u5efa\u8bae\u7528\u6237\u81ea\u884c\u4fee\u6539\u4ee5\u4e0a\u914d\u7f6e\uff0c\u5982\u6709\u51fa\u73b0\u914d\u7f6e\u5f02\u5e38\u5c06\u4f1a\u5bfc\u81f4\u63d2\u4ef6\u65e0\u6cd5\u4f7f\u7528\u8be5\u529f\u80fd</p>"},{"location":"zh/reference/admin/datasource/home.html","title":"\u6570\u636e\u6e90","text":"<p>Note</p> <p>\u901a\u8fc7\u6570\u636e\u6e90\u529f\u80fd\uff0c\u53ef\u4ee5\u6dfb\u52a0\u5bf9\u5404\u79cd\u81ea\u5b9a\u4e49\u6570\u636e\u6e90\u7684\u652f\u6301\uff0c\u5e76\u6267\u884c\u540e\u7eed\u7684\u6570\u636e\u6e90\u64cd\u4f5c\u7b49\u3002</p> <p>\u9f20\u6807\u79fb\u5411\u9876\u90e8\u83dc\u5355\u7684 <code>Admin</code> \u6807\u8bc6\u4e0b\uff0c\u4f1a\u5f39\u51fa\u4e0b\u62c9\u6846\uff0c\u70b9\u51fb\u4e0b\u62c9\u6846\u4e2d\u7684\u7b2c\u4e00\u4e2a\u5b50\u83dc\u5355\u3002\u5f39\u51fa\u7c7b\u4f3c\u5982\u4e0b\u7a97\u53e3\uff0c\u9ed8\u8ba4\u5217\u8868\u4e3a\u7a7a\uff0c\u9700\u8981\u81ea\u884c\u6dfb\u52a0\u3002</p> <p></p> <p>\u5982\u679c\u60a8\u6dfb\u52a0\u4e86\u6570\u636e\u6e90\u4f1a\u663e\u793a\u7c7b\u4f3c\u5982\u4e0b\u9875\u9762</p> <p></p>"},{"location":"zh/reference/admin/datasource/home.html#_1","title":"\u6dfb\u52a0\u6570\u636e\u6e90","text":"<p>\u70b9\u51fb\u5217\u8868\u5c55\u793a\u533a\u57df\u7684\u53f3\u4fa7\u6dfb\u52a0\u6309\u94ae\uff08\u5b83\u662f\u4e00\u4e2a <code>+</code> \u56fe\u6807\uff09\uff0c\u70b9\u51fb\u540e\u5c06\u5f39\u51fa\u5982\u4e0b\u6dfb\u52a0\u6570\u636e\u6e90\u7a97\u53e3</p> <p></p> <p>\u5f53\u6211\u4eec\u9009\u62e9\u67d0\u79cd\u7c7b\u578b\u7684\u6570\u636e\u6e90\u65f6\uff0c\u6570\u636e\u6e90\u914d\u7f6e\u4fe1\u606f\u5c06\u663e\u793a\u5728\u9876\u90e8\u6807\u7b7e\u680f\u4e2d\uff0c\u4e0d\u540c\u7684\u6570\u636e\u6e90\u6709\u4e0d\u540c\u7684\u914d\u7f6e\u9879\uff0c\u5b83\u7684\u914d\u7f6e\u5355\u5728\u670d\u52a1\u542f\u52a8\u662f\u7684\u6307\u5b9a\u76ee\u5f55\u4e2d\u3002</p> <p>\u5f53\u6211\u4eec\u9009\u62e9\u7c7b\u578b\u4e3a <code>MySQL</code> \u7684\u6e90\u65f6\uff0c\u5f39\u51fa\u7c7b\u4f3c\u4ee5\u4e0b\u7a97\u53e3</p> <p></p> <p>\u5728\u914d\u7f6e\u9875\u9762\u4e2d\u51fa\u73b0\u4e864\u4e2a\u9009\u9879\u5361\uff0c\u70b9\u51fb\u4e0d\u540c\u7684\u9009\u9879\u5361\u586b\u5145\u76f8\u5173\u4fe1\u606f\uff0c\u7136\u540e\u70b9\u51fb\u5e95\u90e8\u7684 <code>Test</code> \u6309\u94ae\uff0c\u4f1a\u5f39\u51fa\u5982\u4e0b\u9875\u9762\uff1a</p> <p></p> <p>\u5f53\u6570\u636e\u6e90\u6d4b\u8bd5\u6210\u529f\u540e\u9876\u90e8\u4f1a\u5c55\u793a\u5f53\u524d\u670d\u52a1\u6d4b\u8bd5\u540e\u7684\u7248\u672c\u53f7\uff0c\u6b64\u65f6\u70b9\u51fb\u5730\u6b65\u7684 <code>Save</code> \u6309\u94ae\u5373\u53ef\u4fdd\u5b58\u6570\u636e\u3002</p> <p>Note</p> <p>\u6570\u636e\u6e90\u4fdd\u5b58\u540e\uff0c\u6570\u636e\u6e90\u5217\u8868\u4f1a\u81ea\u52a8\u5237\u65b0\u3002</p>"},{"location":"zh/reference/admin/datasource/home.html#_2","title":"\u4fee\u6539\u6570\u636e\u6e90","text":"<p>\u70b9\u51fb\u5217\u8868\u4e2d\u67d0\u4e2a\u6570\u636e\u6e90\u4e2d <code>Action</code> \u4e2d\u7684\u7b2c\u4e00\u4e2a\u6309\u94ae\u5373\u53ef\u4fee\u6539\u6570\u636e\u6e90\uff0c\u64cd\u4f5c\u7c7b\u4f3c\u4e8e <code>\u6dfb\u52a0\u6570\u636e\u6e90</code> \u64cd\u4f5c</p>"},{"location":"zh/reference/admin/datasource/home.html#_3","title":"\u5220\u9664\u6570\u636e\u6e90","text":"<p>\u70b9\u51fb\u5217\u8868\u4e2d\u67d0\u4e2a\u6570\u636e\u6e90\u7684 <code>Action</code> \u4e2d\u7684\u7b2c\u4e8c\u4e2a\u6309\u94ae\uff0c\u5220\u9664\u8be5\u6570\u636e\u6e90\uff0c\u70b9\u51fb\u540e\u4f1a\u5f39\u51fa\u4ee5\u4e0b\u5185\u5bb9</p> <p></p> <p>\u5355\u51fb\u5f39\u51fa\u7684\u5c0f\u7a97\u53e3\uff0c\u7136\u540e\u5355\u51fb <code>OK</code> \u4ee5\u5220\u9664\u9009\u4e2d\u7684\u6570\u636e\u6e90\u3002</p> <p>Danger</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u5220\u9664\u6570\u636e\u6e90\u540e\uff0c\u4e0e\u6570\u636e\u6e90\u76f8\u5173\u7684\u67e5\u8be2\u5386\u53f2\u8bb0\u5f55\u5c06\u88ab\u5220\u9664\u3002</p>"},{"location":"zh/reference/admin/datasource/home.html#_4","title":"\u6570\u636e\u6e90\u7ba1\u7406","text":"<p>\u5355\u51fb\u5217\u8868\u4e2d\u6570\u636e\u6e90\u7684 <code>Action</code> \u4e2d\u7684\u7b2c\u4e09\u4e2a\u6216\u8005\u7b2c\u56db\u4e2a\u6309\u94ae\uff0c\u8df3\u8f6c\u5230\u6570\u636e\u6e90\u7ba1\u7406\u9875\u9762\u3002</p> <p></p> <p>\u9875\u9762\u5206\u4e3a\u5de6\u53f3\u4e24\u90e8\u5206\u3002\u5de6\u4fa7\u4e3b\u8981\u5c55\u793a\u6570\u636e\u6e90\u7684\u57fa\u672c\u4fe1\u606f\uff0c\u5305\u62ec\uff1a</p> <ul> <li>\u9009\u4e2d\u6570\u636e\u6e90\u7684\u76f8\u5173\u5143\u6570\u636e</li> </ul>"},{"location":"zh/reference/admin/datasource/home.html#_5","title":"\u4fe1\u606f\u6a21\u5757","text":"<p>\u5f53\u6211\u4eec\u5728\u5de6\u4fa7\u9009\u62e9\u6570\u636e\u5e93\u548c\u6570\u636e\u8868\u65f6\uff0c\u53f3\u4fa7\u7684\u5185\u5bb9\u663e\u793a\u5982\u4e0b</p> <p></p> <p>\u5728\u53f3\u4fa7\u5185\u5bb9\u4e2d\u51fa\u73b0\u4e24\u4e2a\u9009\u9879\u5361:</p> <ul> <li><code>Info</code>\uff08\u9ed8\u8ba4\u9009\u9879\uff09</li> <li><code>Data</code></li> </ul> <p>Note</p> <p>\u9ed8\u8ba4\u5f53\u524d\u9009\u9879\u5361\u4e0b\u663e\u793a\u5173\u4e8e\u5f53\u524d\u8868\u7684\u76f8\u5173\u4fe1\u606f\u3002</p>"},{"location":"zh/reference/admin/datasource/home.html#_6","title":"\u6570\u636e\u6a21\u5757","text":"<p>\u70b9\u51fb <code>Data</code> \u9009\u9879\u5361\uff0c\u4f1a\u51fa\u73b0\u7c7b\u4f3c\u5982\u4e0b\u9875\u9762\uff0c\u5b83\u5c55\u793a\u4e86\u5f53\u524d\u9009\u4e2d\u8868\u7684\u76f8\u5173\u6570\u636e\u3002</p> <p></p> <p>\u5728\u9876\u90e8\u7684\u56db\u4e2a\u6309\u94ae\u5206\u522b\u662f\uff1a</p> <ul> <li><code>First Page</code></li> <li><code>Previous Page</code></li> <li><code>Next Page</code></li> <li><code>Last Page</code></li> </ul> <p>\u63a5\u4e0b\u6765\u540e\u9762\u7684\u6309\u94ae\u662f\u7528\u4e8e\u8bbe\u7f6e\u6570\u636e\u67e5\u8be2\u7684\u914d\u7f6e\uff1a</p> <p></p> <ul> <li><code>Jump to Page</code></li> <li><code>Show Page Size</code></li> </ul> <p>\u586b\u5145\u914d\u7f6e\u540e\uff0c\u70b9\u51fb <code>Apply</code> \u6309\u94ae\u5373\u53ef\u5e94\u7528\u5f53\u524d\u914d\u7f6e\u4fe1\u606f\u3002</p> <p>\u5728\u53f3\u4fa7\u8fd8\u6709\u4e00\u4e2a\u6309\u94ae\uff0c\u70b9\u51fb\u540e\u4f1a\u5c55\u793a\u5f53\u524d\u67e5\u8be2\u4f7f\u7528\u5230\u7684\u8be6\u7ec6 <code>SQL</code> \u5185\u5bb9</p> <p></p> <p>Note</p> <p>\u5f53\u524d SQL \u751f\u6210\u662f\u6839\u636e\u540c\u6b65\u5230\u5143\u6570\u636e\u7684\u987a\u5e8f\u800c\u5b9a\u3002</p> <p>Danger</p> <p>\u76ee\u524d\u5e76\u4e0d\u662f\u6240\u6709\u7684\u6570\u636e\u6e90\u90fd\u652f\u6301\u7ba1\u7406\uff0c\u5982\u679c\u9700\u8981\u53ef\u81ea\u884c\u6dfb\u52a0\u6a21\u7248\u3002\u5982\u679c\u6709\u5174\u8da3\u53ef\u5c06\u6e90\u7801\u8d21\u732e\u7ed9\u6211\u4eec\u3002</p>"},{"location":"zh/reference/admin/history/query/home.html","title":"\u67e5\u8be2\u5386\u53f2","text":"<p>\u9f20\u6807\u79fb\u5411\u9876\u90e8\u83dc\u5355\u7684 <code>Admin</code> \u6807\u8bc6\u4e0b\uff0c\u4f1a\u5f39\u51fa\u4e0b\u62c9\u6846\uff0c\u70b9\u51fb\u4e0b\u62c9\u6846\u4e2d\u7684 <code>History</code> \u5b50\u83dc\u5355\u3002\u5f39\u51fa\u7c7b\u4f3c\u5982\u4e0b\u7a97\u53e3\uff0c\u9ed8\u8ba4\u5217\u8868\u4e3a\u7a7a\uff0c\u901a\u8fc7\u67e5\u8be2\u9875\u9762\u8fdb\u884c\u67e5\u8be2\u5373\u53ef\u81ea\u52a8\u6dfb\u52a0\u8bb0\u5f55\u3002</p> <p></p>"},{"location":"zh/reference/admin/history/query/home.html#sql","title":"\u67e5\u770b\u6267\u884c SQL","text":"<p>\u70b9\u51fb\u5217\u8868\u4e2d\u67d0\u4e2a\u6570\u636e\u4e2d <code>Action</code> \u4e2d\u7684\u7b2c\u4e00\u4e2a\u6309\u94ae\uff0c\u67e5\u770b\u5177\u4f53\u7684\u4ee3\u7801\u7247\u6bb5\u5185\u5bb9\uff0c\u4f1a\u5f39\u51fa\u4e00\u4e2a\u5bf9\u8bdd\u6846\uff0c\u5927\u81f4\u5982\u4e0b</p> <p></p> <p>\u6b64\u67e5\u8be2\u4e2d\u67e5\u8be2\u7684\u7279\u5b9a SQL \u8bed\u53e5\u5c06\u663e\u793a\u5728\u7a97\u53e3\u4e2d\u3002</p>"},{"location":"zh/reference/admin/history/query/home.html#_1","title":"\u67e5\u770b\u6267\u884c\u9519\u8bef","text":"<p>Danger</p> <p>\u53ea\u6709\u67e5\u8be2\u51fa\u73b0\u5f02\u5e38\u60c5\u51b5\u4e0b\uff0c\u624d\u53ef\u4ee5\u67e5\u770b\u9519\u8bef\u4fe1\u606f\u3002</p> <p>\u70b9\u51fb\u5217\u8868\u4e2d\u67d0\u4e2a\u6570\u636e\u4e2d <code>Action</code> \u4e2d\u7684\u7b2c\u4e8c\u4e2a\u6309\u94ae\u5373\u53ef\u67e5\u770b\u9519\u8bef\u4fe1\u606f</p> <p></p>"},{"location":"zh/reference/admin/pipeline/home.html","title":"\u6d41\u6c34\u7ebf","text":"<p>\u5728 DataCap \u8f6f\u4ef6\u4e2d\u6d41\u6c34\u7ebf\u7528\u4e8e\u7528\u6237\u9488\u5bf9\u6570\u636e\u8fdb\u884c\u8fc1\u79fb\u7b49\u4e00\u4e9b\u6570\u636e\u64cd\u4f5c\u7684\u5de5\u5177\u3002</p>"},{"location":"zh/reference/admin/pipeline/home.html#_1","title":"\u6784\u5efa\u6d41\u6c34\u7ebf","text":"<p>\u8fdb\u5165\u7cfb\u7edf\u540e\uff0c\u70b9\u51fb\u9876\u90e8 <code>Admin</code> \u83dc\u5355\u4e0b\u5bf9\u5e94\u7684 <code>Pipeline</code> \u5b50\u83dc\u5355\uff0c\u9ed8\u8ba4\u8fdb\u5165\u6d41\u6c34\u7ebf\u5217\u8868\u3002\u7c7b\u4f3c\u4e0b\u56fe\uff1a</p> <p></p> <p>\u70b9\u51fb\u5217\u8868\u53f3\u4fa7\u7684 <code>+ Create</code> \u6309\u94ae\uff0c\u7cfb\u7edf\u4f1a\u5f39\u51fa\u914d\u7f6e\u9875\u9762\uff1a</p> <p></p> <p>\u914d\u7f6e\u9875\u9762\u5206\u4e3a\u4e09\u4e2a\u914d\u7f6e\u6a21\u5757\uff0c\u5206\u522b\u662f\uff1a</p> <ul> <li><code>Description</code> \u4e3b\u8981\u914d\u7f6e\u7528\u6237\u6267\u884c\u7684 SQL</li> <li><code>From</code> \u914d\u7f6e\u6570\u636e\u63a5\u5165\u6e90</li> <li><code>To</code> \u914d\u7f6e\u6570\u636e\u8f93\u51fa\u6e90</li> </ul> <p>\u6bcf\u4e2a\u6570\u636e\u6e90\u5177\u6709\u4e0d\u540c\u7684\u914d\u7f6e\u5c5e\u6027\uff0c\u5f53\u9009\u62e9\u6570\u636e\u6e90\u540e\u6309\u7167\u63d0\u793a\u914d\u7f6e\u76f8\u5173\u5c5e\u6027\u5373\u53ef\u3002</p> <p>\u5f53\u4efb\u52a1\u53d1\u5e03\u6210\u529f\u540e\u9ed8\u8ba4\u4f1a\u5237\u65b0\u4efb\u52a1\u5217\u8868\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p>"},{"location":"zh/reference/admin/pipeline/home.html#_2","title":"\u6d41\u6c34\u7ebf\u7ba1\u7406","text":"<p>\u4efb\u52a1\u53d1\u5e03\u540e\u9ed8\u8ba4\u5c06\u4f1a\u542f\u52a8\uff0c\u5728\u4efb\u52a1\u7684\u53f3\u4fa7 <code>Action</code> \u64cd\u4f5c\u4e2d\u5305\u542b\u4ee5\u4e0b\u529f\u80fd\uff1a</p>"},{"location":"zh/reference/admin/pipeline/home.html#_3","title":"\u67e5\u770b\u9519\u8bef","text":"<p>\u5f53\u6211\u4eec\u70b9\u51fb <code>Action</code> \u4e2d\u7684\u7b2c\u4e00\u4e2a\u6309\u94ae\u65f6\uff0c\u7cfb\u7edf\u4f1a\u5f39\u51fa\u9519\u8bef\u4fe1\u606f\u9875\u9762\u3002</p> <p>\u53ea\u6709\u4efb\u52a1\u8fd0\u884c\u5931\u8d25\u540e\u8be5\u529f\u80fd\u624d\u4f1a\u88ab\u542f\u7528</p> <p></p>"},{"location":"zh/reference/admin/pipeline/home.html#_4","title":"\u67e5\u770b\u65e5\u5fd7","text":"<p>\u5f53\u6211\u4eec\u70b9\u51fb <code>Action</code> \u4e2d\u7684\u7b2c\u4e8c\u4e2a\u6309\u94ae\u65f6\uff0c\u7cfb\u7edf\u4f1a\u5f39\u51fa\u65e5\u5fd7\u9875\u9762\u3002</p> <p></p>"},{"location":"zh/reference/admin/pipeline/home.html#_5","title":"\u4efb\u52a1\u505c\u6b62","text":"<p>\u5f53\u6211\u4eec\u70b9\u51fb <code>Action</code> \u4e2d\u7684\u7b2c\u4e09\u4e2a\u6309\u94ae\u65f6\uff0c\u7cfb\u7edf\u4f1a\u5f39\u51fa\u505c\u6b62\u4efb\u52a1\u9875\u9762\u3002</p> <p>\u53ea\u6709\u4efb\u52a1\u8fd0\u884c\u4e2d\u8be5\u529f\u80fd\u624d\u4f1a\u88ab\u542f\u7528</p> <p></p> <p>\u6211\u4eec\u6309\u7167\u7a97\u53e3\u63d0\u793a\u7684\u4fe1\u606f\u8f93\u5165\u4efb\u52a1\u540d\u5b57\u540e\u70b9\u51fb <code>Stop</code> \u6309\u94ae\u5373\u53ef\u3002</p>"},{"location":"zh/reference/admin/pipeline/home.html#_6","title":"\u4efb\u52a1\u5220\u9664","text":"<p>\u5f53\u6211\u4eec\u70b9\u51fb <code>Action</code> \u4e2d\u7684\u7b2c\u56db\u4e2a\u6309\u94ae\u65f6\uff0c\u7cfb\u7edf\u4f1a\u5f39\u51fa\u5220\u9664\u4efb\u52a1\u9875\u9762\u3002</p> <p></p> <p>\u6211\u4eec\u6309\u7167\u7a97\u53e3\u63d0\u793a\u7684\u4fe1\u606f\u8f93\u5165\u4efb\u52a1\u540d\u5b57\u540e\u70b9\u51fb <code>Delete</code> \u6309\u94ae\u5373\u53ef\u3002</p>"},{"location":"zh/reference/admin/profile/home.html","title":"\u4e2a\u4eba\u8d44\u6599","text":"<p>Note</p> <p>\u901a\u8fc7\u4e2a\u4eba\u8d44\u6599\u529f\u80fd\uff0c\u53ef\u4ee5\u5bf9\u4e2a\u4eba\u7528\u6237\u7684\u4e00\u4e9b\u67e5\u8be2\u5386\u53f2\u548c\u6570\u636e\u6e90\u7684\u4f7f\u7528\u8fdb\u884c\u4e00\u4e9b\u6982\u89c8\u67e5\u770b\u3002</p> <p>\u9f20\u6807\u79fb\u5411\u9876\u90e8\u83dc\u5355\u7684\u6700\u53f3\u4fa7\u7684\u5934\u50cf\u83dc\u5355\uff0c\u4f1a\u5f39\u51fa\u4e0b\u62c9\u6846\uff0c\u70b9\u51fb\u4e0b\u62c9\u6846\u4e2d\u7684\u7b2c\u4e00\u4e2a\u5b50\u83dc\u5355\u3002\u5f39\u51fa\u7c7b\u4f3c\u5982\u4e0b\u7a97\u53e3\uff1a</p> <p></p> <p>\u9996\u5148\u6211\u4eec\u770b\u5230\u7684\u6700\u4e0a\u9762\u7684\u4e00\u4e2a\u56fe\u8868\u662f\u8fd1\u4e00\u5e74\u7684\u67e5\u8be2\u65e5\u5386\u56fe\u3002\u5b83\u6839\u636e\u6bcf\u5929\u7684\u67e5\u8be2\u603b\u6570\u6c47\u603b\u6765\u8ba1\u7b97\u3002</p> <p>\u7b2c\u4e8c\u4e2a\u56fe\u8868\u662f\u8fd17\u65e5\u7684\u6570\u636e\u6e90\u4f7f\u7528\u60c5\u51b5\u3002\u5b83\u6839\u636e\u6bcf\u5929\u7684\u6570\u636e\u6e90\u4f7f\u7528\u60c5\u51b5\u6c47\u603b\u6765\u8ba1\u7b97\u3002</p>"},{"location":"zh/reference/admin/profile/home.html#_1","title":"\u4e2a\u4eba\u8d44\u6599","text":"<p>\u5f53\u70b9\u51fb\u4e2a\u4eba\u8d44\u6599\u6309\u94ae\u540e\uff08\u4e5f\u5c31\u662f\u5de6\u4fa7\u83dc\u5355\u7684\u7b2c\u4e00\u4e2a\u6309\u94ae\uff09\uff0c\u4f1a\u5f39\u51fa\u5982\u4e0b\u7a97\u53e3\uff1a</p> <p></p> <p>\u8be5\u9875\u9762\u4e3b\u8981\u5c55\u793a\u4e86\u4e2a\u4eba\u8d44\u6599\u7684\u57fa\u672c\u4fe1\u606f\u3002</p>"},{"location":"zh/reference/admin/profile/home.html#_2","title":"\u767b\u5f55\u65e5\u5fd7","text":"<p>\u5f53\u70b9\u51fb\u767b\u5f55\u65e5\u5fd7\u6309\u94ae\u540e\uff08\u4e5f\u5c31\u662f\u5de6\u4fa7\u83dc\u5355\u7684\u7b2c\u4e8c\u4e2a\u6309\u94ae\uff09\uff0c\u4f1a\u5f39\u51fa\u5982\u4e0b\u7a97\u53e3\uff1a</p> <p></p> <p>\u8be5\u9875\u9762\u4e3b\u8981\u5c55\u793a\u4e86\u5f53\u524d\u7528\u6237\u7684\u8be6\u7ec6\u767b\u5f55\u65e5\u5fd7\uff0c\u5305\u62ec\u4e86\u767b\u5f55\u65f6\u95f4\u3001\u767b\u5f55\u5730\u70b9\u3001\u767b\u5f55\u65b9\u5f0f\u7b49\u3002</p>"},{"location":"zh/reference/admin/profile/home.html#_3","title":"\u8d26\u53f7\u8bbe\u7f6e","text":"<p>\u5f53\u70b9\u51fb\u8d26\u53f7\u8bbe\u7f6e\u6309\u94ae\u540e\uff08\u4e5f\u5c31\u662f\u5de6\u4fa7\u83dc\u5355\u7684\u7b2c\u4e09\u4e2a\u6309\u94ae\uff09\uff0c\u4f1a\u5f39\u51fa\u5982\u4e0b\u7a97\u53e3\uff1a</p> <p></p> <p>\u8be5\u9875\u9762\u4e3b\u8981\u5c55\u793a\u4e86\u4e00\u4e9b\u7528\u6237\u53ef\u4ee5\u8fdb\u884c\u7684\u914d\u7f6e\u529f\u80fd\u3002</p>"},{"location":"zh/reference/admin/profile/home.html#_4","title":"\u7528\u6237\u540d","text":"<p>\u5f53\u70b9\u51fb\u4fee\u6539\u7528\u6237\u540d\u6309\u94ae\u540e\uff0c\u4f1a\u5f39\u51fa\u5982\u4e0b\u7a97\u53e3\uff1a</p> <p></p> <p>\u8f93\u5165\u4fee\u6539\u540e\u7684\u7528\u6237\u540d\u548c\u5f53\u524d\u5bc6\u7801\uff0c\u70b9\u51fb\u786e\u5b9a\u6309\u94ae\u5373\u53ef\u5b8c\u6210\u4fee\u6539\u3002</p> <p>Danger</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff1a\u4fee\u6539\u7528\u6237\u540d\u540e\uff0c\u9700\u8981\u91cd\u65b0\u767b\u5f55\u3002\u7cfb\u7edf\u4f1a\u9ed8\u8ba4\u9000\u51fa\u5f53\u524d\u8d26\u53f7\u3002</p>"},{"location":"zh/reference/admin/profile/home.html#_5","title":"\u5bc6\u7801","text":"<p>\u5f53\u70b9\u51fb\u4fee\u6539\u5bc6\u7801\u6309\u94ae\u540e\uff0c\u4f1a\u5f39\u51fa\u5982\u4e0b\u7a97\u53e3\uff1a</p> <p></p> <p>\u8f93\u5165\u539f\u5bc6\u7801\u548c\u65b0\u5bc6\u7801\uff0c\u70b9\u51fb\u786e\u5b9a\u6309\u94ae\u5373\u53ef\u5b8c\u6210\u4fee\u6539\u3002</p> <p>Danger</p> <p>\u9700\u8981\u6ce8\u610f\u7684\u662f\uff1a\u4fee\u6539\u5bc6\u7801\u540e\uff0c\u9700\u8981\u91cd\u65b0\u767b\u5f55\u3002\u7cfb\u7edf\u4f1a\u9ed8\u8ba4\u9000\u51fa\u5f53\u524d\u8d26\u53f7\u3002</p>"},{"location":"zh/reference/admin/profile/home.html#chatgpt","title":"ChatGPT","text":"<p>\u5f53\u70b9\u51fb ChatGPT \u6309\u94ae\u540e\uff0c\u4f1a\u5f39\u51fa\u5982\u4e0b\u7a97\u53e3\uff1a</p> <p></p> <p>\u8be5\u9875\u9762\u4e3b\u8981\u5c55\u793a\u4e86\u4e00\u4e9b ChatGPT \u53ef\u4ee5\u8fdb\u884c\u7684\u914d\u7f6e\u529f\u80fd\u3002</p>"},{"location":"zh/reference/admin/profile/home.html#_6","title":"\u7f16\u8f91\u5668","text":"<p>\u5f53\u70b9\u51fb\u7f16\u8f91\u5668\u6309\u94ae\u540e\uff0c\u4f1a\u5f39\u51fa\u5982\u4e0b\u7a97\u53e3\uff1a</p> <p></p> <p>\u5728\u4fee\u6539\u7f16\u8f91\u5668\u65f6\uff0c\u4fee\u6539\u7684\u914d\u7f6e\u4f1a\u540c\u6b65\u5230\u7cfb\u7edf\u4e2d\u7684\u6240\u6709\u7528\u5230\u7f16\u8f91\u5668\u7684\u4f4d\u7f6e\u3002</p> <p>\u7f16\u8f91\u5668\u7684\u4fee\u6539\u662f\u6240\u89c1\u5373\u6240\u5f97\u7684\u72b6\u6001\uff0c\u53ef\u4ee5\u5b9e\u65f6\u663e\u793a\u51fa\u6765\u5f53\u524d\u7684\u914d\u7f6e\u65b9\u6848\u3002</p>"},{"location":"zh/reference/admin/snippet/home.html","title":"\u4ee3\u7801\u7247\u6bb5","text":"<p>Note</p> <p>\u901a\u8fc7\u4ee3\u7801\u6bb5\u529f\u80fd\uff0c\u53ef\u4ee5\u6dfb\u52a0\u5bf9\u5404\u79cd\u81ea\u5b9a\u4e49\u4ee3\u7801\u6bb5\u7684\u652f\u6301\uff0c\u5e76\u6267\u884c\u540e\u7eed\u7684\u4ee3\u7801\u6bb5\u64cd\u4f5c\u7b49\u3002\u6dfb\u52a0\u7684\u4ee3\u7801\u7247\u6bb5\u540e\u7eed\u4f1a\u6dfb\u52a0\u5230\u7f16\u8f91\u5668\u4e2d\u3002</p> <p>\u9f20\u6807\u79fb\u5411\u9876\u90e8\u83dc\u5355\u7684 <code>Admin</code> \u6807\u8bc6\u4e0b\uff0c\u4f1a\u5f39\u51fa\u4e0b\u62c9\u6846\uff0c\u70b9\u51fb\u4e0b\u62c9\u6846\u4e2d\u7684 <code>Snippet</code> \u5b50\u83dc\u5355\u3002\u5f39\u51fa\u7c7b\u4f3c\u5982\u4e0b\u7a97\u53e3\uff0c\u9ed8\u8ba4\u5217\u8868\u4e3a\u7a7a\uff0c\u9700\u8981\u81ea\u884c\u6dfb\u52a0\u3002</p> <p></p> <p>\u5982\u679c\u60a8\u6dfb\u52a0\u4e86\u7247\u6bb5\u4f1a\u663e\u793a\u7c7b\u4f3c\u5982\u4e0b\u9875\u9762</p> <p></p>"},{"location":"zh/reference/admin/snippet/home.html#_1","title":"\u6dfb\u52a0\u7247\u6bb5","text":"<p>\u70b9\u51fb\u5217\u8868\u5c55\u793a\u533a\u57df\u7684\u53f3\u4fa7\u6dfb\u52a0\u6309\u94ae\uff08\u5b83\u662f\u4e00\u4e2a <code>+</code> \u56fe\u6807\uff09\uff0c\u70b9\u51fb\u540e\u5c06\u5f39\u51fa\u5982\u4e0b\u6dfb\u52a0\u6570\u636e\u6e90\u7a97\u53e3</p> <p></p> <p>\u5728\u7a97\u53e3\u4e2d\uff0c\u6211\u4eec\u9700\u8981\u8f93\u5165\u4ee5\u4e0b\u5185\u5bb9</p> \u5c5e\u6027 \u63cf\u8ff0 <code>Name</code> \u6807\u8bb0\u5f53\u524d\u4ee3\u7801\u6bb5\u7684\u540d\u79f0 <code>Description</code> \u5f53\u524d\u4ee3\u7801\u7247\u6bb5\u7684\u8bf4\u660e <code>Snippet</code> \u5f53\u524d\u4ee3\u7801\u7247\u6bb5\u7684\u7279\u5b9a SQL \u5185\u5bb9 <p>\u586b\u5199\u5b8c\u4ee5\u4e0a\u5185\u5bb9\u540e\uff0c\u70b9\u51fb\u5e95\u90e8\u7684 <code>Submit</code> \u6309\u94ae\u4fdd\u5b58\u4ee3\u7801\u7247\u6bb5\u3002</p> <p>Note</p> <p>\u6570\u636e\u4fdd\u5b58\u540e\uff0c\u6570\u636e\u6e90\u5217\u8868\u4f1a\u81ea\u52a8\u5237\u65b0\u3002</p>"},{"location":"zh/reference/admin/snippet/home.html#_2","title":"\u67e5\u770b\u4ee3\u7801\u6bb5\u5185\u5bb9","text":"<p>\u70b9\u51fb\u5217\u8868\u4e2d\u67d0\u4e2a\u6570\u636e\u4e2d <code>Action</code> \u4e2d\u7684\u7b2c\u4e00\u4e2a\u6309\u94ae\uff0c\u67e5\u770b\u5177\u4f53\u7684\u4ee3\u7801\u7247\u6bb5\u5185\u5bb9\uff0c\u4f1a\u5f39\u51fa\u4e00\u4e2a\u5bf9\u8bdd\u6846\uff0c\u5927\u81f4\u5982\u4e0b</p> <p></p> <p>\u5355\u51fb <code>OK</code> \u6216 <code>Cancel</code> \u5173\u95ed\u5bf9\u8bdd\u6846</p>"},{"location":"zh/reference/admin/snippet/home.html#_3","title":"\u4fee\u6539\u4ee3\u7801\u6bb5","text":"<p>\u70b9\u51fb\u5217\u8868\u4e2d\u67d0\u4e2a\u6570\u636e\u4e2d <code>Action</code> \u4e2d\u7684\u7b2c\u4e8c\u4e2a\u6309\u94ae\u5373\u53ef\u4fee\u6539\u4ee3\u7801\u6bb5\uff0c\u8be5\u64cd\u4f5c\u7c7b\u4f3c\u4e8e <code>\u6dfb\u52a0\u7247\u6bb5</code> \u64cd\u4f5c\u3002</p>"},{"location":"zh/reference/admin/snippet/home.html#_4","title":"\u5f15\u7528\u7247\u6bb5","text":"<p>\u70b9\u51fb\u5217\u8868\u4e2d\u67d0\u4e2a\u6570\u636e\u7684 <code>Action</code> \u4e2d\u7684\u7b2c\u4e09\u4e2a\u6309\u94ae\uff0c\u5f15\u7528\u5f53\u524d\u4ee3\u7801\u7247\u6bb5\uff0c\u4f1a\u8df3\u8f6c\u5230\u67e5\u8be2\u9875\u9762\uff0c\u7247\u6bb5\u5185\u5bb9\u4f1a\u76f4\u63a5\u8f93\u5165\u5230\u7f16\u8f91\u5668\u4e2d\u3002</p>"},{"location":"zh/reference/admin/snippet/home.html#_5","title":"\u5220\u9664\u4ee3\u7801\u6bb5","text":"<p>\u70b9\u51fb\u5217\u8868\u4e2d\u67d0\u4e2a\u6570\u636e\u7684 <code>Action</code> \u4e2d\u7684\u7b2c\u56db\u4e2a\u6309\u94ae\uff0c\u5220\u9664\u4ee3\u7801\u6bb5\uff0c\u70b9\u51fb\u540e\u4f1a\u5f39\u51fa\u4ee5\u4e0b\u5185\u5bb9</p> <p></p> <p>\u5355\u51fb\u5f39\u51fa\u7684\u5c0f\u7a97\u53e3\uff0c\u7136\u540e\u5355\u51fb <code>OK</code> \u4ee5\u5220\u9664\u4ee3\u7801\u6bb5\u3002</p>"},{"location":"zh/reference/clients/cli.html","title":"\u547d\u4ee4\u884c\u754c\u9762","text":"<p>DataCap CLI \u63d0\u4f9b\u57fa\u4e8e\u7ec8\u7aef\u7684\u4ea4\u4e92\u5f0f shell \u6765\u8fd0\u884c\u67e5\u8be2\u3002 CLI \u662f\u4e00\u4e2a\u81ea\u52a8\u6267\u884c\u7684 JAR \u6587\u4ef6\uff0c\u8fd9\u610f\u5473\u7740\u5b83\u7684\u884c\u4e3a\u5c31\u50cf\u666e\u901a\u7684 UNIX \u53ef\u6267\u884c\u6587\u4ef6\u4e00\u6837\u3002</p>"},{"location":"zh/reference/clients/cli.html#_1","title":"\u8981\u6c42","text":"<p>CLI \u9700\u8981\u8def\u5f84\u4e0a\u6709\u53ef\u7528\u7684 Java \u865a\u62df\u673a\u3002\u5b83\u53ef\u4ee5\u4e0e Java \u7248\u672c 8 \u53ca\u66f4\u9ad8\u7248\u672c\u4e00\u8d77\u4f7f\u7528\u3002</p> <p>CLI \u4f7f\u7528\u57fa\u4e8e HTTP/HTTPS \u7684 DataCap \u5ba2\u6237\u7aef REST API \u4e0e\u7cfb\u7edf\u8fdb\u884c\u901a\u4fe1\u3002</p> <p>CLI \u7248\u672c\u5e94\u4e0e\u7cfb\u7edf\u7248\u672c\u76f8\u540c\u6216\u66f4\u9ad8\u3002</p>"},{"location":"zh/reference/clients/cli.html#_2","title":"\u5b89\u88c5","text":"<p>\u4e0b\u8f7d datacap-client-cli-1.6.0.jar, \u5c06\u5176\u91cd\u547d\u540d\u4e3a datacap\uff0c\u4f7f\u7528 <code>chmod +x</code> \u547d\u4ee4\u5c06\u5176\u8bbe\u7f6e\u4e3a\u53ef\u6267\u884c\u3002</p>"},{"location":"zh/reference/clients/cli.html#cli","title":"\u8fd0\u884c CLI","text":"<pre><code>./datacap\n\nconnect -h 127.0.0.1 -p 9096 -u username -P password\n</code></pre> <p>\u5982\u679c\u6210\u529f\uff0c\u60a8\u5c06\u6536\u5230\u6267\u884c\u547d\u4ee4\u7684\u63d0\u793a\u3002\u4f7f\u7528 <code>help</code> \u547d\u4ee4\u67e5\u770b\u652f\u6301\u7684\u547d\u4ee4\u5217\u8868\u3002</p> \u547d\u4ee4 \u63cf\u8ff0 <code>source info</code> \u83b7\u53d6\u6570\u636e\u6e90\u8be6\u7ec6\u4fe1\u606f <code>source list</code> \u83b7\u53d6\u8fdc\u7a0b\u670d\u52a1\u5668\u6570\u636e\u6e90\u5217\u8868 <code>source use &lt;SourceID&gt;</code> \u8bbe\u7f6e\u6570\u636e\u6e90\u6807\u5fd7\uff0c\u4ee5\u4fbf\u540e\u7eed\u5bf9\u6570\u636e\u6e90\u7684\u64cd\u4f5c <code>source execute \"&lt;QuerySQL&gt;\"</code> \u6267\u884c\u8fdc\u7a0bSQL"},{"location":"zh/reference/connectors/http/ceresdb.html#ceresdb","title":"\u4ec0\u4e48\u662f CeresDB ?","text":"<p>CeresDB \u662f\u4e00\u6b3e\u9ad8\u6027\u80fd\u3001\u5206\u5e03\u5f0f\u7684\u4e91\u539f\u751f\u65f6\u5e8f\u6570\u636e\u5e93\u3002</p>"},{"location":"zh/reference/connectors/http/ceresdb.html#_1","title":"\u73af\u5883","text":"<p>Note</p> <p>\u5982\u679c\u4f60\u9700\u8981\u4f7f\u7528\u8fd9\u4e2a\u6570\u636e\u6e90, \u60a8\u9700\u8981\u5c06 DataCap \u670d\u52a1\u5347\u7ea7\u5230 &gt;= <code>1.9.x</code></p> <p>\u652f\u6301\u65f6\u95f4: <code>2023-04-12</code></p>"},{"location":"zh/reference/connectors/http/ceresdb.html#_2","title":"\u914d\u7f6e","text":"<p>Note</p> <p>\u5982\u679c\u60a8\u7684CeresDB\u670d\u52a1\u7248\u672c\u9700\u8981\u5176\u4ed6\u7279\u6b8a\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542f DataCap \u670d\u52a1\u3002</p> \u914d\u7f6e Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>5440</code>"},{"location":"zh/reference/connectors/http/ceresdb.html#_3","title":"\u7248\u672c\uff08\u9a8c\u8bc1\uff09","text":"<p>Warning</p> <p>\u670d\u52a1\u7248\u672c\u5c1a\u672a\u6d4b\u8bd5\uff0c\u5982\u679c\u60a8\u6709\u8be6\u7ec6\u7684\u6d4b\u8bd5\u5e76\u53d1\u73b0\u9519\u8bef\uff0c\u8bf7\u63d0\u4ea4 issues</p> <ul> <li> 1.x</li> </ul>"},{"location":"zh/reference/connectors/http/greptimedb.html#greptimedb","title":"\u4ec0\u4e48\u662f GreptimeDB ?","text":"<p>\u4e00\u4e2a\u5f00\u6e90\u3001\u4e91\u539f\u751f\u3001\u5206\u5e03\u5f0f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5e93\uff0c\u652f\u6301PromQL/SQL/Python\u3002</p>"},{"location":"zh/reference/connectors/http/greptimedb.html#_1","title":"\u73af\u5883","text":"<p>Note</p> <p>\u5982\u679c\u4f60\u9700\u8981\u4f7f\u7528\u8fd9\u4e2a\u6570\u636e\u6e90, \u60a8\u9700\u8981\u5c06 DataCap \u670d\u52a1\u5347\u7ea7\u5230 &gt;= <code>1.9.x</code></p> <p>\u652f\u6301\u65f6\u95f4: <code>2023-04-14</code></p>"},{"location":"zh/reference/connectors/http/greptimedb.html#_2","title":"\u914d\u7f6e","text":"<p>Note</p> <p>\u5982\u679c\u60a8\u7684 GreptimeDB \u670d\u52a1\u7248\u672c\u9700\u8981\u5176\u4ed6\u7279\u6b8a\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542f DataCap \u670d\u52a1\u3002</p> \u914d\u7f6e Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>5440</code>"},{"location":"zh/reference/connectors/http/greptimedb.html#_3","title":"\u7248\u672c\uff08\u9a8c\u8bc1\uff09","text":"<p>Warning</p> <p>\u670d\u52a1\u7248\u672c\u5c1a\u672a\u6d4b\u8bd5\uff0c\u5982\u679c\u60a8\u6709\u8be6\u7ec6\u7684\u6d4b\u8bd5\u5e76\u53d1\u73b0\u9519\u8bef\uff0c\u8bf7\u63d0\u4ea4 issues</p> <ul> <li> 0.x</li> </ul>"},{"location":"zh/reference/connectors/http/questdb.html#questdb","title":"\u4ec0\u4e48\u662f QuestDB ?","text":"<p>QuestDB \u662f\u4e00\u4e2a\u5f00\u6e90\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5e93\uff0c\u7528\u4e8e\u9ad8\u541e\u5410\u91cf\u6444\u53d6\u548c\u5feb\u901f SQL \u67e5\u8be2\uff0c\u64cd\u4f5c\u7b80\u5355\u3002\u5b83\u652f\u6301\u4f7f\u7528 InfluxDB \u884c\u534f\u8bae\u3001PostgreSQL \u6709\u7ebf\u534f\u8bae\u548c\u7528\u4e8e\u6279\u91cf\u5bfc\u5165\u548c\u5bfc\u51fa\u7684 REST API \u8fdb\u884c\u4e0e\u6a21\u5f0f\u65e0\u5173\u7684\u6444\u53d6\u3002</p>"},{"location":"zh/reference/connectors/http/questdb.html#_1","title":"\u73af\u5883","text":"<p>Note</p> <p>\u5982\u679c\u4f60\u9700\u8981\u4f7f\u7528\u8fd9\u4e2a\u6570\u636e\u6e90, \u60a8\u9700\u8981\u5c06 DataCap \u670d\u52a1\u5347\u7ea7\u5230 &gt;= <code>1.9.x</code></p> <p>\u652f\u6301\u65f6\u95f4: <code>2023-04-17</code></p>"},{"location":"zh/reference/connectors/http/questdb.html#_2","title":"\u914d\u7f6e","text":"<p>Note</p> <p>\u5982\u679c\u60a8\u7684 QuestDB \u670d\u52a1\u7248\u672c\u9700\u8981\u5176\u4ed6\u7279\u6b8a\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542f DataCap \u670d\u52a1\u3002</p> \u914d\u7f6e Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code>"},{"location":"zh/reference/connectors/http/questdb.html#_3","title":"\u7248\u672c\uff08\u9a8c\u8bc1\uff09","text":"<p>Warning</p> <p>\u670d\u52a1\u7248\u672c\u5c1a\u672a\u6d4b\u8bd5\uff0c\u5982\u679c\u60a8\u6709\u8be6\u7ec6\u7684\u6d4b\u8bd5\u5e76\u53d1\u73b0\u9519\u8bef\uff0c\u8bf7\u63d0\u4ea4 issues</p> <ul> <li> 7.x</li> </ul>"},{"location":"zh/reference/connectors/jdbc/doris.html#doris","title":"\u4ec0\u4e48\u662f Doris ?","text":"<p>\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u3001\u9ad8\u6027\u80fd\u548c\u7edf\u4e00\u7684\u5206\u6790\u6570\u636e\u5e93</p>"},{"location":"zh/reference/connectors/jdbc/doris.html#_1","title":"\u73af\u5883","text":"<p>Note</p> <p>\u5982\u679c\u4f60\u9700\u8981\u4f7f\u7528\u8fd9\u4e2a\u6570\u636e\u6e90, \u60a8\u9700\u8981\u5c06 DataCap \u670d\u52a1\u5347\u7ea7\u5230 &gt;= <code>1.9.x</code></p> <p>\u652f\u6301\u65f6\u95f4: <code>2023-04-19</code></p>"},{"location":"zh/reference/connectors/jdbc/doris.html#_2","title":"\u914d\u7f6e","text":"<p>Note</p> <p>\u5982\u679c\u60a8\u7684 Doris \u670d\u52a1\u7248\u672c\u9700\u8981\u5176\u4ed6\u7279\u6b8a\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542f DataCap \u670d\u52a1\u3002</p> \u914d\u7f6e\u6388\u6743\u9ad8\u7ea7 Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9093</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"zh/reference/connectors/jdbc/doris.html#_3","title":"\u7248\u672c\uff08\u9a8c\u8bc1\uff09","text":"<p>Warning</p> <p>\u670d\u52a1\u7248\u672c\u5c1a\u672a\u6d4b\u8bd5\uff0c\u5982\u679c\u60a8\u6709\u8be6\u7ec6\u7684\u6d4b\u8bd5\u5e76\u53d1\u73b0\u9519\u8bef\uff0c\u8bf7\u63d0\u4ea4 issues</p>"},{"location":"zh/reference/connectors/jdbc/hologres.html#hologres","title":"\u4ec0\u4e48\u662f Hologres ?","text":"<p>Hologres\u662f\u517c\u5bb9PostgreSQL\u7684\u4e00\u7ad9\u5f0f\u5b9e\u65f6\u6570\u636e\u4ed3\u5e93\u5f15\u64ce\uff0c\u652f\u6301PB\u7ea7\u6570\u636e\u591a\u7ef4\u5206\u6790\uff08OLAP\uff09\u4e0e\u5373\u5e2d\u5206\u6790\uff08Ad Hoc\uff09\uff0c\u652f\u6301\u9ad8\u5e76\u53d1\u4f4e\u5ef6\u8fdf\u7684\u5728\u7ebf\u6570\u636e\u670d\u52a1\uff08Serving\uff09\u3002\u4e0eMaxCompute\u3001Flink\u3001DataWorks\u6df1\u5ea6\u878d\u5408\uff0c\u63d0\u4f9b\u79bb\u5728\u7ebf\u4e00\u4f53\u5316\u5168\u6808\u6570\u4ed3\u89e3\u51b3\u65b9\u6848\u3002</p>"},{"location":"zh/reference/connectors/jdbc/hologres.html#_1","title":"\u73af\u5883","text":"<p>Note</p> <p>\u5982\u679c\u4f60\u9700\u8981\u4f7f\u7528\u8fd9\u4e2a\u6570\u636e\u6e90, \u60a8\u9700\u8981\u5c06 DataCap \u670d\u52a1\u5347\u7ea7\u5230 &gt;= <code>1.9.x</code></p> <p>\u652f\u6301\u65f6\u95f4: <code>2023-04-25</code></p>"},{"location":"zh/reference/connectors/jdbc/hologres.html#_2","title":"\u914d\u7f6e","text":"<p>Note</p> <p>\u5982\u679c\u60a8\u7684 Hologres \u670d\u52a1\u7248\u672c\u9700\u8981\u5176\u4ed6\u7279\u6b8a\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542f DataCap \u670d\u52a1\u3002</p> \u914d\u7f6e\u6388\u6743\u9ad8\u7ea7 Field Required Default Value <code>Name</code> - <code>Host</code> <code>hologres-cn-regison.aliyuncs.com</code> <code>Port</code> <code>80</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"zh/reference/connectors/jdbc/hologres.html#_3","title":"\u7248\u672c\uff08\u9a8c\u8bc1\uff09","text":"<p>Warning</p> <p>\u670d\u52a1\u7248\u672c\u5c1a\u672a\u6d4b\u8bd5\uff0c\u5982\u679c\u60a8\u6709\u8be6\u7ec6\u7684\u6d4b\u8bd5\u5e76\u53d1\u73b0\u9519\u8bef\uff0c\u8bf7\u63d0\u4ea4 issues</p> <ul> <li> all</li> </ul>"},{"location":"zh/reference/connectors/jdbc/pinot.html#pinot","title":"\u4ec0\u4e48\u662f Pinot ?","text":"<p>Apache Pinot \u662f\u4e00\u4e2a\u5b9e\u65f6\u5206\u5e03\u5f0f OLAP \u6570\u636e\u5b58\u50a8\uff0c\u4e13\u4e3a\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u541e\u5410\u91cf\u5206\u6790\u800c\u6784\u5efa\uff0c\u975e\u5e38\u9002\u5408\u9762\u5411\u7528\u6237\u7684\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\u3002</p>"},{"location":"zh/reference/connectors/jdbc/pinot.html#_1","title":"\u73af\u5883","text":"<p>Note</p> <p>\u5982\u679c\u9700\u8981\u4f7f\u7528\u8be5\u6570\u636e\u6e90\uff0c\u9700\u8981\u5c06DataCap\u670d\u52a1\u5347\u7ea7\u5230 &gt;= <code>1.10.x</code></p> <p>\u652f\u6301\u65f6\u95f4: <code>2023-05-06</code></p>"},{"location":"zh/reference/connectors/jdbc/pinot.html#_2","title":"\u914d\u7f6e","text":"<p>Note</p> <p>\u5982\u679c\u60a8\u7684\u670d\u52a1\u7248\u672c\u9700\u8981\u5176\u4ed6\u7279\u6b8a\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542fDataCap\u670d\u52a1\u3002</p> \u914d\u7f6e\u6388\u6743 Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code> Field Required Default Value <code>Username</code> - <code>Password</code> -"},{"location":"zh/reference/connectors/jdbc/pinot.html#_3","title":"\u7248\u672c (\u9a8c\u8bc1)","text":"<p>Warning</p> <p>\u670d\u52a1\u7248\u672c\u5c1a\u672a\u6d4b\u8bd5\uff0c\u5982\u679c\u60a8\u6709\u8be6\u7ec6\u7684\u6d4b\u8bd5\u5e76\u53d1\u73b0\u9519\u8bef\uff0c\u8bf7\u63d0\u4ea4 issues</p> <ul> <li> <code>0.8.x</code></li> </ul>"},{"location":"zh/reference/connectors/jdbc/starrocks.html#starrocks","title":"\u4ec0\u4e48\u662f StarRocks ?","text":"<p>\u5f00\u6e90\u3001\u9ad8\u6027\u80fd\u7684\u5206\u6790\u6570\u636e\u5e93</p>"},{"location":"zh/reference/connectors/jdbc/starrocks.html#_1","title":"\u73af\u5883","text":"<p>Note</p> <p>\u5982\u679c\u4f60\u9700\u8981\u4f7f\u7528\u8fd9\u4e2a\u6570\u636e\u6e90, \u60a8\u9700\u8981\u5c06 DataCap \u670d\u52a1\u5347\u7ea7\u5230 &gt;= <code>1.9.x</code></p> <p>\u652f\u6301\u65f6\u95f4: <code>2023-04-20</code></p>"},{"location":"zh/reference/connectors/jdbc/starrocks.html#_2","title":"\u914d\u7f6e","text":"<p>Note</p> <p>\u5982\u679c\u60a8\u7684 StarRocks \u670d\u52a1\u7248\u672c\u9700\u8981\u5176\u4ed6\u7279\u6b8a\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u5e76\u91cd\u542f DataCap \u670d\u52a1\u3002</p> \u914d\u7f6e\u6388\u6743\u9ad8\u7ea7 Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9030</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"zh/reference/connectors/jdbc/starrocks.html#_3","title":"\u7248\u672c\uff08\u9a8c\u8bc1\uff09","text":"<p>Warning</p> <p>\u670d\u52a1\u7248\u672c\u5c1a\u672a\u6d4b\u8bd5\uff0c\u5982\u679c\u60a8\u6709\u8be6\u7ec6\u7684\u6d4b\u8bd5\u5e76\u53d1\u73b0\u9519\u8bef\uff0c\u8bf7\u63d0\u4ea4 issues</p> <ul> <li> 2.2.x</li> </ul>"},{"location":"zh/reference/get_started/install.html","title":"\u5728\u81ea\u4e3b\u673a\u4e2d\u90e8\u7f72","text":"<p>DataCap\u662f\u4e00\u6b3e\u7528\u4e8e\u6570\u636e\u8f6c\u6362\uff0c\u96c6\u6210\u548c\u53ef\u89c6\u5316\u7684\u8f6f\u4ef6\u3002</p>"},{"location":"zh/reference/get_started/install.html#_1","title":"\u7cfb\u7edf\u8981\u6c42","text":"<p>Warning</p> <p>\u8be5\u8f6f\u4ef6\u7684\u4e8c\u8fdb\u5236\u5305\u57fa\u4e8e\u4ee5\u4e0b\u7cfb\u7edf\u8fdb\u884c\u7f16\u8bd1\u548c\u6d4b\u8bd5\u3002\u5b83\u5c1a\u672a\u5728\u5176\u4ed6\u7248\u672c\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7406\u8bba\u4e0a\u53d7\u652f\u6301\u3002</p> <p>\u5982\u679c\u6709\u4e0d\u652f\u6301\u7684\u7cfb\u7edf\uff0c\u8bf7\u4f7f\u7528\u6e90\u7801\u7f16\u8bd1\u65b9\u6cd5\u4e3b\u52a8\u7f16\u8bd1\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002</p> \u7cfb\u7edf \u7248\u672c JDK <code>&gt;=11</code> MySQL <code>&gt;=5.6.x</code>"},{"location":"zh/reference/get_started/install.html#_2","title":"\u4e8c\u8fdb\u5236\u5b89\u88c5","text":"<p>Note</p> <p>\u4ece\u4ee5\u4e0b\u5730\u5740\u4e0b\u8f7d\u76f8\u5e94\u7cfb\u7edf\u7684\u4e8c\u8fdb\u5236\u8f6f\u4ef6\u5305\u8fdb\u884c\u5b89\u88c5\u3002</p> <ul> <li>\u4e0b\u8f7d\u6700\u65b0\u53d1\u5e03\u7248\u672c</li> </ul>"},{"location":"zh/reference/get_started/install.html#_3","title":"\u4e0b\u8f7d\u5305","text":"<p>\u5c06\u4e8c\u8fdb\u5236\u6587\u4ef6\u4e0b\u8f7d\u5230\u672c\u5730\u540e\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4</p> <pre><code>tar -xvzf datacap-release.tar.gz\n</code></pre>"},{"location":"zh/reference/get_started/install.html#_4","title":"\u8f6f\u4ef6\u914d\u7f6e","text":"<p>\u5bf9\u4e8e\u8f6f\u4ef6\u7684\u9996\u6b21\u5b89\u88c5\uff0c\u60a8\u9700\u8981\u5c06 <code>schema/datacap.sql</code> \u6587\u4ef6\u4e2d\u7684sql\u811a\u672c\u5bfc\u5165MySQL\u670d\u52a1\u5668\u3002\u6ce8\u610f\u9700\u8981\u5bfc\u5165\u7684\u811a\u672c\u6839\u636e\u4e0b\u8f7d\u7684\u8f6f\u4ef6\u5305\u8fdb\u884c\u5339\u914d</p> <p>\u5bfc\u5165 <code>SQL</code> \u811a\u672c\u540e\uff0c\u4fee\u6539 <code>configure/application.properties</code> \u914d\u7f6e\u6587\u4ef6\u4ee5\u4fee\u6539MySQL\u670d\u52a1\u5668\u7684\u914d\u7f6e\u4fe1\u606f</p> <p>\u6dfb\u52a0\u914d\u7f6e</p> <pre><code>spring.datasource.url=jdbc:mysql://localhost:3306/datacap?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;useSSL=false&amp;useOldAliasMetadataBehavior=true&amp;jdbcCompliantTruncation=false&amp;sessionVariables=sql_mode='STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,PIPES_AS_CONCAT'\nspring.datasource.username=root\nspring.datasource.password=12345678\n</code></pre> <p>Warning</p> <p>\u5982\u679c\u9700\u8981\u4fee\u6539\u65e5\u5fd7\u914d\u7f6e\uff0c\u53ea\u9700\u4fee\u6539 <code>configure/logback.xml</code> \u914d\u7f6e\u6587\u4ef6\u5373\u53ef</p>"},{"location":"zh/reference/get_started/install.html#_5","title":"\u542f\u52a8\u670d\u52a1","text":"<p>DataCap\u670d\u52a1\u542f\u52a8\u975e\u5e38\u7b80\u5355\uff0c\u6267\u884c\u4ee5\u4e0b\u811a\u672c</p> <pre><code>./bin/startup.sh\n</code></pre>"},{"location":"zh/reference/get_started/install.html#_6","title":"\u505c\u6b62\u670d\u52a1","text":"<p>\u505c\u6b62\u670d\u52a1\u5e76\u6267\u884c\u4ee5\u4e0b\u811a\u672c</p> <pre><code>./bin/shutdown.sh\n</code></pre> <p>Note</p> <p>\u5982\u679c\u8981\u8c03\u8bd5\u7cfb\u7edf\uff0c\u53ef\u4ee5\u4f7f\u7528 <code>./bin/debug.sh</code> \u542f\u52a8\u670d\u52a1\uff0c\u4f46\u5173\u95ed\u7a97\u53e3\u65f6\u5b83\u5c06\u505c\u6b62</p>"},{"location":"zh/reference/get_started/install.html#_7","title":"\u6e90\u5b89\u88c5","text":"<p>Warning</p> <p>\u8981\u624b\u52a8\u7f16\u8bd1\u5e76\u5b89\u88c5 DataCap\uff0c\u60a8\u9700\u8981\u6267\u884c\u4ee5\u4e0b\u6b65\u9aa4\u3002</p> <p>\u7cfb\u7edf\u9700\u8981\u5b89\u88c5 <code>JDK</code></p> <ul> <li>\u5c06\u6e90\u4ee3\u7801\u514b\u9686\u5230\u6b64\u8ba1\u7b97\u673a</li> </ul> <pre><code>git clone https://github.com/devlive-community/datacap.git\n</code></pre> <ul> <li>\u7f16\u8bd1\u548c\u6784\u5efa\u5e94\u7528\u7a0b\u5e8f</li> </ul> <pre><code>./mvnw clean install package -DskipTests -Dgpg.skip\n</code></pre> <p>Warning</p> <p>\u7f16\u8bd1\u5b8c\u6210\u540e\uff0c<code>datacap-release.tar.gz</code> \u5305\u4f1a\u5728 <code>dist</code> \u76ee\u5f55\u4e2d\u751f\u6210\u3002</p> <p>\u4f7f\u7528\u76f8\u5173\u8f6f\u4ef6\u5305\u8fdb\u884c\u5b89\u88c5\u3002</p> <p>Note</p> <p>\u5982\u679c\u4e0d\u60f3\u5b89\u88c5\u5230\u672c\u5730\u8f6f\u4ef6\u76ee\u5f55\uff0c\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u6587\u6863\u542f\u52a8\u5f00\u53d1\u6a21\u5f0f\u8fdb\u884c\u8f6f\u4ef6\u4f7f\u7528\u3002</p> <p>\u5f00\u53d1\u8005</p>"},{"location":"zh/reference/get_started/install_containers.html","title":"\u5728 Docker \u4e2d\u90e8\u7f72","text":"<p>DataCap \u9879\u76ee\u63d0\u4f9b qianmoq/datacap \u5305\u542b DataCap \u670d\u52a1\u5668\u548c\u9ed8\u8ba4\u914d\u7f6e\u7684 Docker \u6620\u50cf\u3002Docker \u6620\u50cf\u53d1\u5e03\u5230 Docker Hub\uff0c\u53ef\u4ee5\u4e0e Docker \u8fd0\u884c\u65f6\u7b49\u4e00\u8d77\u4f7f\u7528\u3002</p>"},{"location":"zh/reference/get_started/install_containers.html#_1","title":"\u8fd0\u884c\u5bb9\u5668","text":"<p>\u8981\u5728 Docker \u4e2d\u8fd0\u884c DataCap\uff0c\u60a8\u5fc5\u987b\u5728\u8ba1\u7b97\u673a\u4e0a\u5b89\u88c5 Docker \u5f15\u64ce\u3002\u60a8\u53ef\u4ee5\u4ece Docker website, \u6216\u4f7f\u7528\u64cd\u4f5c\u7cfb\u7edf\u7684\u6253\u5305\u7cfb\u7edf\u3002</p> <p>\u4f7f\u7528 docker \u547d\u4ee4\u4ece qianmoq/datacap \u56fe\u50cf\u3002\u4e3a\u5176\u5206\u914d\u6570\u636e\u5e3d\u540d\u79f0\uff0c\u4ee5\u4fbf\u4ee5\u540e\u66f4\u5bb9\u6613\u5f15\u7528\u5b83\u3002\u5728\u540e\u53f0\u8fd0\u884c\u5b83\uff0c\u5e76\u5c06\u9ed8\u8ba4 DataCap \u7aef\u53e3\uff08\u5373 <code>9096</code>\uff09\u4ece\u5bb9\u5668\u5185\u90e8\u6620\u5c04\u5230\u5de5\u4f5c\u7ad9\u4e0a\u7684\u7aef\u53e3 <code>9096</code>\u3002</p> <pre><code>docker run -d -p 9909:9096 --name datacap qianmoq/datacap\n</code></pre> <p>\u5982\u679c\u4e0d\u6307\u5b9a\u5bb9\u5668\u6620\u50cf\u6807\u8bb0\uff0c\u5219\u9ed8\u8ba4\u4e3a <code>latest</code> \uff0c\u4f46\u53ef\u4ee5\u4f7f\u7528\u8bb8\u591a\u5df2\u53d1\u5e03\u7684 DataCap \u7248\u672c\uff0c\u4f8b\u5982 <code>qianmoq/datacap:1.8.0</code>\u3002</p> <p>\u8fd0\u884c <code>docker ps</code> \u4ee5\u67e5\u770b\u5728\u540e\u53f0\u8fd0\u884c\u7684\u6240\u6709\u5bb9\u5668\u3002</p> <pre><code>-&gt; % docker ps\nCONTAINER ID   IMAGE                    COMMAND               CREATED      STATUS          PORTS                    NAMES\n2096fba19e2a   datacap:latest           \"sh ./bin/debug.sh\"   5 days ago   Up 14 seconds   0.0.0.0:9909-&gt;9096/tcp   datacap\n</code></pre>"},{"location":"zh/reference/get_started/install_containers.html#_2","title":"\u6e05\u7406","text":"<p>\u60a8\u53ef\u4ee5\u4f7f\u7528 <code>docker stop datacap</code> \u548c <code>docker start datacap</code> \u547d\u4ee4\u505c\u6b62\u548c\u542f\u52a8\u5bb9\u5668\u3002\u8981\u5b8c\u5168\u5220\u9664\u5df2\u505c\u6b62\u7684\u5bb9\u5668\uff0c\u8bf7\u8fd0\u884c <code>docker rm datacap</code>\u3002</p>"},{"location":"zh/reference/get_started/install_rainbond.html","title":"\u5728 Rainbond \u4e2d\u90e8\u7f72","text":"<p>\u5982\u679c\u60a8\u4e0d\u719f\u6089 Kubernetes\uff0c\u60f3\u5728 Kubernetes \u4e2d\u5b89\u88c5 DataCap\uff0c\u53ef\u4ee5\u4f7f\u7528 Rainbond \u6765\u90e8\u7f72\u3002Rainbond \u662f\u4e00\u4e2a\u57fa\u4e8e Kubernetes \u6784\u5efa\u7684\u4e91\u539f\u751f\u5e94\u7528\u7ba1\u7406\u5e73\u53f0\uff0c\u53ef\u4ee5\u5f88\u7b80\u5355\u7684\u5c06\u4f60\u7684\u5e94\u7528\u90e8\u7f72\u5230 Kubernetes \u4e2d\u3002</p>"},{"location":"zh/reference/get_started/install_rainbond.html#_1","title":"\u524d\u63d0","text":"<p>\u5b89\u88c5 Rainbond, \u8bf7\u53c2\u9605 Rainbond \u5feb\u901f\u5b89\u88c5.</p>"},{"location":"zh/reference/get_started/install_rainbond.html#datacap","title":"\u90e8\u7f72 DataCap","text":"<p>DataCap \u5df2\u53d1\u5e03\u5230 Rainbond \u5f00\u6e90\u5e94\u7528\u5546\u5e97\uff0c\u53ef\u901a\u8fc7 Rainbond \u5f00\u6e90\u5e94\u7528\u5546\u5e97\u4e00\u952e\u90e8\u7f72 DataCap\u3002</p> <p>\u8fdb\u5165 Rainbond \u63a7\u5236\u53f0\u7684 <code>\u5e73\u53f0\u7ba1\u7406 -&gt; \u5e94\u7528\u5e02\u573a -&gt; \u5f00\u6e90\u5e94\u7528\u5546\u5e97</code> \u4e2d\u641c\u7d22 <code>DataCap</code> \u5e76\u5b89\u88c5\u3002</p> <p></p> <p>\u586b\u5199\u4ee5\u4e0b\u4fe1\u606f\uff0c\u7136\u540e\u70b9\u51fb\u786e\u8ba4\u6309\u94ae\u8fdb\u884c\u5b89\u88c5\u3002</p> <ul> <li>\u56e2\u961f\uff1a\u9009\u62e9\u73b0\u6709\u56e2\u961f\u6216\u521b\u5efa\u65b0\u7684\u56e2\u961f</li> <li>\u96c6\u7fa4\uff1a\u9009\u62e9\u5bf9\u5e94\u7684\u96c6\u7fa4</li> <li>\u5e94\u7528\uff1a\u9009\u62e9\u73b0\u6709\u5e94\u7528\u6216\u521b\u5efa\u65b0\u7684\u5e94\u7528</li> <li>\u7248\u672c\uff1a\u9009\u62e9\u8981\u5b89\u88c5\u7684\u7248\u672c</li> </ul> <p>\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u53ef\u901a\u8fc7 Rainbond \u63d0\u4f9b\u7684\u9ed8\u8ba4\u57df\u540d\u8bbf\u95ee DataCap\uff0c\u9ed8\u8ba4\u7528\u6237\u5bc6\u7801 <code>admin/12345678</code></p> <p></p>"},{"location":"zh/release/1.10.0.html","title":"1.10.0","text":"<p>Note</p> <p>\u5f53\u524d\u7248\u672c\u6d89\u53ca\u51e0\u4e2a\u4e3b\u8981\u66f4\u65b0\u3002</p> <p> DataCap \u5df2\u53d1\u5e03 </p> \u53d1\u5e03\u7248\u672c \u53d1\u5e03\u65f6\u95f4 <code>1.10.0</code> <code>2023-05-30</code>"},{"location":"zh/release/1.10.0.html#general","title":"General","text":"<ul> <li>\u4fee\u590d\u670d\u52a1\u542f\u52a8\u9ed8\u8ba4\u8fde\u63a5 mongo</li> <li>\u4fee\u590d\u4e86 sql \u6a21\u677f\u7684 h2 db update_time \u548c create_time</li> <li>\u6539\u8fdb H2 \u5143\u6570\u636e\u7ba1\u7406\u83b7\u53d6\u7c7b\u578b</li> <li>\u6539\u8fdb mysql \u5143\u6570\u636e\u7ba1\u7406\u83b7\u53d6\u7c7b\u578b</li> <li>\u56fa\u5b9a\u5143\u6570\u636e\u7ba1\u7406\u6570\u636e\u9875\u9ed8\u8ba4\u4e3a 1</li> <li>\u91cd\u6784\u6570\u636e\u6e32\u67d3\u8868</li> <li>\u652f\u6301\u680f\u76ee\u7c7b\u578b</li> <li>\u6dfb\u52a0\u8017\u65f6\u548c\u67e5\u770b\u6267\u884c SQL</li> <li>\u652f\u6301\u53ef\u9009\u62e9\u7684\u6bcf\u9875\u603b\u8ba1</li> <li>\u652f\u6301\u6807\u9898\u63d0\u793a\u6570\u636e\u7c7b\u578b</li> <li>\u652f\u6301\u590d\u5236\u9009\u5b9a\u7684\u6570\u636e\u7ed3\u679c</li> <li>\u652f\u6301\u9009\u62e9\u6307\u5b9a\u5217\u67e5\u8be2</li> <li>\u652f\u6301\u8fc7\u6ee4\u5668</li> <li>\u4fee\u590d\u9ed8\u8ba4\u7528\u6237\u521b\u5efa\u65f6\u95f4\u4e3a\u7a7a</li> <li>\u652f\u6301\u6743\u9650</li> <li>\u56fa\u5b9a\u7528\u6237 createTime \u4e3a\u7a7a</li> </ul>"},{"location":"zh/release/1.10.0.html#web","title":"Web","text":"<ul> <li>\u4fee\u590d\u4e0d\u6e05\u9664\u7f51\u7edc\u6388\u6743\u4fe1\u606f</li> <li>\u4f18\u5316\u6570\u636e\u7ba1\u7406\u83b7\u53d6\u6570\u636e</li> <li>\u7981\u7528\u8b66\u544a\u8f93\u51fa\u5230\u63a7\u5236\u53f0</li> <li>\u589e\u52a0\u7f16\u8f91\u5668\u7f13\u51b2\u63d0\u793a\u9650\u5236</li> <li>\u5220\u9664\u9ed8\u8ba4\u6392\u5e8f\u89c4\u5219</li> <li>\u91cd\u547d\u540d\u7528\u6237\u4eea\u8868\u677f\u8def\u5f84</li> <li>\u6dfb\u52a0\u4eea\u8868\u677f\u804a\u5929\u98ce\u683c</li> <li>\u4fee\u590d\u5bfc\u822a\u6837\u5f0f</li> <li>\u6dfb\u52a0\u6570\u636e\u6e90\u52a0\u8f7d\u72b6\u6001</li> </ul>"},{"location":"zh/release/1.10.0.html#plugins","title":"Plugins","text":"<ul> <li>\u652f\u6301 apache pinot</li> <li>\u652f\u6301 mongo \u793e\u533a\u7248</li> </ul>"},{"location":"zh/release/1.10.0.html#dependencies","title":"Dependencies","text":"<ul> <li>\u5347\u7ea7 clickhouse-jdbc <code>0.3.2-patch9</code> \u5230 <code>0.4.6</code></li> <li>\u5347\u7ea7 oracle-xe <code>1.17.6</code> \u5230 <code>1.18.1</code></li> <li>\u5347\u7ea7 kyuubi-hive-jdbc-shaded <code>1.6.0-incubating</code> \u5230 <code>1.7.1</code></li> </ul>"},{"location":"zh/release/1.11.0.html","title":"1.11.0","text":"<p>Note</p> <p>\u5f53\u524d\u7248\u672c\u6d89\u53ca\u51e0\u4e2a\u4e3b\u8981\u66f4\u65b0\u3002</p> <p> DataCap \u5df2\u53d1\u5e03 </p> \u53d1\u5e03\u7248\u672c \u53d1\u5e03\u65f6\u95f4 <code>1.11.0</code> <code>2023-06-13</code>"},{"location":"zh/release/1.11.0.html#general","title":"General","text":"<ul> <li>\u6dfb\u52a0\u4e86\u67e5\u8be2\u5386\u53f2\u8fd4\u56de\u7684\u884c\u6570</li> <li>\u4fee\u590d\u4e86\u4e3b\u9875\u4e0a\u7684 404 \u9519\u8bef</li> <li>\u5c06\u63d2\u4ef6\u5265\u79bb\u5230\u5355\u72ec\u7684\u6587\u4ef6\u5939\u4e2d</li> </ul>"},{"location":"zh/release/1.11.0.html#web","title":"Web","text":"<ul> <li>\u91cd\u6784\u6587\u4ef6\u5939</li> <li>\u6dfb\u52a0\u83dc\u5355\u9762\u5305\u5c51</li> <li>\u540c\u6b65\u670d\u52a1\u5668\u8def\u7531</li> <li>\u6dfb\u52a0\u975e\u767b\u5f55\u9875\u9762</li> <li>\u6dfb\u52a0\u6e90\u7ba1\u7406\u5668\u8def\u7531</li> <li>\u4fee\u590d\u8def\u7531\u6784\u5efa\u5931\u8d25\u56de\u8c03\u5f02\u5e38</li> <li>\u4fee\u590d\u6570\u636e\u6e90\u7c7b\u578b\u6807\u8bb0\u5f02\u5e38</li> </ul>"},{"location":"zh/release/1.11.0.html#plugins","title":"Plugins","text":"<ul> <li>\u652f\u6301 apache cassandra</li> </ul>"},{"location":"zh/release/1.12.0.html","title":"1.12.0","text":"<p>Note</p> <p>\u5f53\u524d\u7248\u672c\u6d89\u53ca\u51e0\u4e2a\u4e3b\u8981\u66f4\u65b0\u3002</p> <p> DataCap \u5df2\u53d1\u5e03 </p> \u53d1\u5e03\u7248\u672c \u53d1\u5e03\u65f6\u95f4 <code>1.12.0</code> <code>2023-07-11</code>"},{"location":"zh/release/1.12.0.html#general","title":"General","text":"<ul> <li>\u5220\u9664\u65e5\u5fd7\u9ed8\u8ba4\u8c03\u8bd5\u7ea7\u522b</li> <li>\u62c6\u5206\u5404\u6a21\u5757</li> <li>\u4fee\u590d\u9519\u8bef\u4f9d\u8d56</li> <li>\u652f\u6301\u83dc\u5355\u91cd\u5b9a\u5411</li> <li>\u4fee\u590d\u4e86 SQL \u67b6\u6784</li> <li>\u652f\u6301\u662f\u5426\u529f\u80fd\u83dc\u5355</li> <li>\u5c06 openai sdk \u66ff\u6362\u4e3a <code>openai-java-sdk</code></li> <li>\u91cd\u6784 chatgpt</li> </ul>"},{"location":"zh/release/1.12.0.html#web","title":"Web","text":"<ul> <li>\u4fee\u590d\u7f13\u5b58\u4e0d\u6e05\u9664\uff0c\u9700\u8981\u91cd\u65b0\u70b9\u51fb\u7684\u95ee\u9898</li> <li>\u4fee\u590d\u4e86\u65e0\u6548\u4ee4\u724c\u7684\u9519\u8bef</li> <li>\u6dfb\u52a0\u7f13\u51b2\u533a\u6807\u7b7e\u540d\u79f0</li> <li>\u4fee\u590d\u4f7f\u7528h2\u6570\u636e\u5e93\u7684\u4e2a\u4eba\u8d44\u6599\u9875\u9762\u5f02\u5e38\u7684\u95ee\u9898</li> <li>\u4fee\u590d\u670d\u52a1\u91cd\u542f\u5bfc\u81f4404</li> </ul>"},{"location":"zh/release/1.13.0.html","title":"1.13.0","text":"<p>Note</p> <p>\u5f53\u524d\u7248\u672c\u6d89\u53ca\u51e0\u4e2a\u4e3b\u8981\u66f4\u65b0\u3002</p> <p> DataCap \u5df2\u53d1\u5e03 </p> \u53d1\u5e03\u7248\u672c \u53d1\u5e03\u65f6\u95f4 <code>1.13.0</code> <code>2023-08-09</code>"},{"location":"zh/release/1.13.0.html#general","title":"General","text":"<ul> <li>\u4fee\u590d\u4e86 <code>openai-java-sdk</code> \u7248\u672c</li> <li>\u6dfb\u52a0\u6570\u636e\u6e90\u7248\u672c</li> <li>\u6dfb\u52a0\u6570\u636e\u6e90\u626b\u63cf\u4efb\u52a1</li> <li>\u4f18\u5316\u72b6\u6001\u56fe\u6807</li> <li>\u5220\u9664\u5bf9\u5185\u7f6e H2 \u6570\u636e\u5e93\u7684\u652f\u6301</li> </ul>"},{"location":"zh/release/1.13.0.html#web","title":"Web","text":"<ul> <li>\u652f\u6301\u6587\u5b57</li> <li>\u4fee\u590d div \u7a7a\u767d</li> <li>\u6dfb\u52a0\u4e86\u65e5\u5386\u70ed\u56fe\u4e2d\u6587</li> <li>\u4fee\u590d\u4e86\u6570\u636e\u8d21\u732e\u56fe\u9519\u8bef</li> <li>\u5f53\u6570\u636e\u6e90\u4e0d\u53ef\u7528\u65f6\u5217\u8868\u7981\u7528\u9009\u62e9</li> </ul>"},{"location":"zh/release/1.13.0.html#kyuubi","title":"Kyuubi","text":"<ul> <li>\u4fee\u590d\u65e0\u6cd5\u6267\u884cset\u8bed\u6cd5sql\u7684\u95ee\u9898</li> <li>\u4fee\u590d\u8fde\u63a5\u672a\u5173\u95ed\u7684\u95ee\u9898</li> </ul>"},{"location":"zh/release/1.13.0.html#oracle","title":"Oracle","text":"<ul> <li>\u652f\u6301\u83b7\u53d6DBName\u548cTableName</li> </ul>"},{"location":"zh/release/1.13.0.html#clickhouse","title":"Clickhouse","text":"<ul> <li>\u4fee\u590d\u4e86 <code>default</code> \u6570\u636e\u5e93\u4e2d\u6ca1\u6709\u67e5\u8be2\u9519\u8bef\u7684\u95ee\u9898</li> </ul>"},{"location":"zh/release/1.14.0.html","title":"1.14.0","text":"<p>Note</p> <p>\u5f53\u524d\u7248\u672c\u6d89\u53ca\u51e0\u4e2a\u4e3b\u8981\u66f4\u65b0\u3002</p> <p> DataCap \u5df2\u53d1\u5e03 </p> \u53d1\u5e03\u7248\u672c \u53d1\u5e03\u65f6\u95f4 <code>1.14.0</code> <code>2023-09-14</code>"},{"location":"zh/release/1.14.0.html#general","title":"General","text":"<ul> <li>\u4fee\u590d\u6570\u636e\u6e90\u68c0\u67e5\u4efb\u52a1\u8fd4\u56de\u7a7a\u7684\u95ee\u9898</li> <li>\u6dfb\u52a0\u9a8c\u8bc1\u7801</li> <li>\u652f\u6301\u767b\u5f55\u9a8c\u8bc1\u7801</li> <li>\u652f\u6301\u9a8c\u8bc1\u7801\u5931\u8d25\u81ea\u52a8\u5237\u65b0</li> <li>\u652f\u6301\u6ce8\u518c\u9a8c\u8bc1\u7801</li> <li>\u652f\u6301\u6ce8\u518c\u542f\u7528</li> <li>\u79fb\u52a8 etc \u5230 configure</li> </ul>"},{"location":"zh/release/1.14.0.html#web","title":"Web","text":"<ul> <li>\u4fee\u590d\u7a7a\u7f16\u8f91\u5668\u7834\u574f\u5f02\u5e38</li> <li>\u516c\u5171\u9875\u9762\u589e\u52a0\u5e03\u5c40</li> <li>\u4fee\u590d\u4e86\u4e2a\u4eba\u8d44\u6599\u9875\u9762\u9519\u8bef</li> <li>\u4fee\u590d\u767b\u5f55\u9875\u9762\u6837\u5f0f\u5f02\u5e38\u7684\u95ee\u9898</li> </ul>"},{"location":"zh/release/1.14.0.html#pipeline-apache-seatunnel","title":"Pipeline (Apache Seatunnel)","text":"<ul> <li>\u652f\u6301 Kafka \u8f93\u5165\uff5c\u8f93\u51fa</li> <li>\u652f\u6301 ClickHouse \u8f93\u5165\uff5c\u8f93\u51fa</li> <li>\u652f\u6301\u5220\u9664</li> <li>\u6784\u5efa\u7ba1\u9053\u9875\u9762</li> <li>\u652f\u6301\u63d0\u4ea4</li> <li>\u652f\u6301 SWITCH \u5b57\u6bb5\u7c7b\u578b</li> <li>\u6dfb\u52a0\u6267\u884c\u8005\u6807\u5fd7</li> <li>\u652f\u6301\u9650\u6d41\u6392\u961f</li> <li>\u652f\u6301\u505c\u6b62</li> <li>\u670d\u52a1\u91cd\u542f\u65f6\u91cd\u7f6e\u6d41\u6c34\u7ebf</li> <li>\u6dfb\u52a0\u65e5\u5fd7\u754c\u9762\u5e76\u4f18\u5316UI</li> <li>\u652f\u6301\u5b57\u6bb5\u63cf\u8ff0</li> <li>\u652f\u6301\u5b57\u6bb5 SELECT \u7c7b\u578b</li> <li>\u652f\u6301\u5b57\u6bb5\u68c0\u67e5</li> <li>\u652f\u6301\u5b57\u6bb5\u6570\u7ec4</li> <li>\u652f\u6301 Redis \u8f93\u51fa</li> <li>\u652f\u6301\u6307\u5b9a\u8fd0\u884c\u65f6\u673a\u5236</li> </ul>"},{"location":"zh/release/1.14.0.html#dependencies","title":"Dependencies","text":"<ul> <li>\u5c06 com.google.guava:guava \u4ece 31.1-jre \u66f4\u6539\u4e3a 32.1.2-jre</li> <li>\u5c06 org.devlive.sdk:openai-java-sdk \u4ece 1.5.0 \u5347\u7ea7\u5230 1.9.0</li> <li>\u5c06 com.h2database:h2 \u4ece 2.1.214 \u63d0\u5347\u5230 2.2.220</li> <li>\u5c06 org.projectlombok:lombok \u4ece 1.18.24 \u66f4\u6539\u4e3a 1.18.28</li> <li>\u5c06 org.apache.kafka:kafka-clients \u4ece 2.8.0 \u5347\u7ea7\u5230 2.8.1</li> <li>\u5c06 org.duckdb:duckdb_jdbc \u4ece 0.7.0 \u5347\u7ea7\u5230 0.8.1</li> <li>\u5c06 com.github.eirslett:frontend-maven-plugin \u4ece 1.12.1 \u5347\u7ea7\u5230 1.13.4</li> <li>\u5c06 kotlin.version \u4ece 1.8.20 \u5347\u7ea7\u5230 1.9.10</li> <li>\u5c06 org.sonatype.plugins:nexus-staging-maven-plugin \u4ece 1.6 \u5347\u7ea7\u5230 1.6.13</li> </ul>"},{"location":"zh/release/1.15.0.html","title":"1.15.0","text":"<p>Note</p> <p>\u5f53\u524d\u7248\u672c\u6d89\u53ca\u51e0\u4e2a\u4e3b\u8981\u66f4\u65b0\u3002</p> <p> DataCap \u5df2\u53d1\u5e03 </p> \u53d1\u5e03\u7248\u672c \u53d1\u5e03\u65f6\u95f4 <code>1.15.0</code> <code>2023-10-18</code>"},{"location":"zh/release/1.15.0.html#general","title":"General","text":"<ul> <li>\u652f\u6301\u6570\u636e\u5e93\u540c\u6b65</li> <li>\u652f\u6301\u8868\u540c\u6b65</li> <li>\u652f\u6301\u5217\u540c\u6b65</li> <li>\u6dfb\u52a0\u8c03\u5ea6\u7a0b\u5e8f\u5386\u53f2\u8bb0\u5f55</li> <li>\u91cd\u6784\u5143\u6570\u636e\u6a21\u5757</li> <li>\u6539\u8fdb SQL \u6587\u4ef6</li> </ul>"},{"location":"zh/release/1.15.0.html#editor","title":"Editor","text":"<ul> <li>\u66ff\u6362 <code>monaco</code> \u4e3a <code>ace</code></li> </ul>"},{"location":"zh/release/1.15.0.html#docs","title":"Docs","text":"<ul> <li>\u6dfb\u52a0\u4e2d\u6587\u90e8\u7f72\u6587\u6863</li> <li>\u4f18\u5316\u7247\u6bb5\u548c\u6570\u636e\u6765\u6e90\u4e2d\u6587\u6587\u6863</li> </ul>"},{"location":"zh/release/1.9.0.html","title":"1.9.0","text":"<p>Note</p> <p>\u5f53\u524d\u7248\u672c\u6d89\u53ca\u51e0\u4e2a\u4e3b\u8981\u66f4\u65b0\u3002</p> <p> DataCap \u5df2\u53d1\u5e03 </p> \u53d1\u5e03\u7248\u672c \u53d1\u5e03\u65f6\u95f4 <code>1.9.0</code> <code>2023-05-04</code>"},{"location":"zh/release/1.9.0.html#general","title":"General","text":"<ul> <li>\u652f\u6301 github packages</li> <li>\u4f18\u5316 docker \u955c\u50cf\u53d1\u5e03\u6d41\u7a0b</li> <li>\u652f\u6301\u683c\u5f0f\u5316\u65e5\u671f</li> <li>\u6dfb\u52a0\u6570\u636e\u5e93\u8fde\u63a5\u6307\u5b9a\u65f6\u533a</li> <li>\u4fee\u590d\u4e86\u9ed8\u8ba4\u7684 h2 \u6570\u636e\u5e93\u672a\u521d\u59cb\u5316\u7684\u5b9a\u65f6\u4efb\u52a1</li> <li>\u5c06 <code>admin</code> \u7528\u6237\u6dfb\u52a0\u5230 README.md</li> <li>\u6dfb\u52a0 docker \u955c\u50cf\u6807\u7b7e</li> <li>\u5728 README.md \u4e2d\u6dfb\u52a0\u5fae\u4fe1\u4e8c\u7ef4\u7801</li> <li>\u6dfb\u52a0 docker \u5fbd\u7ae0</li> <li>\u4fee\u590d\u6570\u636e\u6e90\u521b\u5efa\u65f6\u95f4\u4e3a\u7a7a</li> </ul>"},{"location":"zh/release/1.9.0.html#docs","title":"Docs","text":"<ul> <li>\u6dfb\u52a0\u4e2d\u6587\u6587\u6863</li> <li>\u6dfb\u52a0 Rainbond \u90e8\u7f72\u6587\u6863</li> <li>\u6dfb\u52a0\u63d2\u4ef6\u6587\u6863</li> <li>\u652f\u6301\u9876\u90e8\u6eda\u52a8\u901a\u77e5</li> </ul>"},{"location":"zh/release/1.9.0.html#web","title":"Web","text":"<ul> <li>\u4fee\u590d\u6570\u636e\u8868\u65e0\u6548\u5206\u9875</li> <li>\u4fee\u590d\u4e86\u65e0\u6cd5\u6b63\u786e\u6e32\u67d3\u7684\u95ee\u9898</li> <li>\u4fee\u590d\u5305\u542b\u56fd\u9645\u5316\u6570\u636e\u7684\u6e32\u67d3\u7f3a\u5931\u7684\u7ffb\u8bd1\u7ed3\u679c</li> <li>\u652f\u6301\u590d\u5236\u591a\u9009\u884c</li> <li>\u4fee\u590d\u6570\u636e\u6e90\u6d4b\u8bd5\u72b6\u6001\u95ee\u9898</li> <li>\u652f\u6301\u5173\u95ed\u6d88\u606f</li> <li>\u6dfb\u52a0\u5b9a\u65f6\u4efb\u52a1\u94fe\u63a5</li> </ul>"},{"location":"zh/release/1.9.0.html#plugins","title":"Plugins","text":"<ul> <li>\u652f\u6301 ceresdb</li> <li>\u652f\u6301 greptimedb</li> <li>\u652f\u6301 questdb</li> <li>\u652f\u6301 apache doris</li> <li>\u652f\u6301 starrocks</li> <li>\u652f\u6301 hologres</li> <li>\u652f\u6301 apache hadoop hdfs</li> </ul>"},{"location":"zh/release/1.9.0.html#spi","title":"SPI","text":"<ul> <li>\u79fb\u9664 http \u91cd\u8bd5\u903b\u8f91</li> </ul>"},{"location":"zh/release/1.9.0.html#yandex-database","title":"Yandex Database","text":"<ul> <li>\u4fee\u590d\u4e86 ydb \u4f9d\u8d56\u51b2\u7a81</li> </ul>"},{"location":"zh/release/1.9.0.html#trino","title":"Trino","text":"<ul> <li>\u6dfb\u52a0\u914d\u7f6e\u6587\u4ef6</li> </ul>"},{"location":"zh/release/1.9.0.html#dependencies","title":"Dependencies","text":"<ul> <li>\u5347\u7ea7 trino-jdbc <code>397</code> \u5230 <code>414</code> (#331)</li> <li>\u5347\u7ea7 iotdb-jdbc <code>0.13.0</code> \u5230 <code>1.1.0</code> (#309)</li> </ul>"},{"location":"zh/release/latest.html","title":"1.16.0 (latest)","text":"<p>Note</p> <p>\u5f53\u524d\u7248\u672c\u6d89\u53ca\u51e0\u9879\u91cd\u5927\u66f4\u65b0\u3002</p> <p>DataCap \u53d1\u5e03!</p> \u53d1\u5e03\u7248\u672c \u53d1\u5e03\u65f6\u95f4 <code>1.16.0</code> <code>2023-11-01</code>"},{"location":"zh/release/latest.html#general","title":"General","text":"<ul> <li>\u652f\u6301\u5217\u987a\u5e8f </li> <li>\u652f\u6301\u5220\u9664\u884c</li> <li>\u652f\u6301\u5220\u9664\u591a\u884c </li> <li>\u652f\u6301\u65e0\u4e3b\u952e\u6570\u636e\u66f4\u65b0 </li> <li>\u652f\u6301\u6839\u636e\u4e3b\u952e\u66f4\u65b0 </li> <li>\u652f\u6301\u9884\u89c8\u5f85\u5904\u7406\u7684\u66f4\u6539</li> </ul>"},{"location":"zh/release/latest.html#editor","title":"Editor","text":"<ul> <li>\u652f\u6301\u9009\u62e9\u67e5\u8be2 </li> <li>\u652f\u6301\u81ea\u5b9a\u4e49\u914d\u7f6e </li> </ul>"},{"location":"zh/release/latest.html#docs","title":"Docs","text":"<ul> <li>\u6dfb\u52a0\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u6587\u6863</li> </ul>"},{"location":"zh/release/latest.html#dependencies","title":"Dependencies","text":"<ul> <li>\u66f4\u65b0 org.apache.maven.plugins:maven-javadoc-plugin <code>3.5.0</code> \u5230 <code>3.6.0</code></li> <li>\u66f4\u65b0 com.oceanbase:oceanbase-client <code>2.4.2</code> \u5230 <code>2.4.5</code></li> <li>\u66f4\u65b0 org.apache.maven.plugins:maven-javadoc-plugin <code>3.5.0</code> \u5230 <code>3.6.0</code></li> </ul>"},{"location":"index.html","title":"DataCap","text":"DataCap is integrated software for data transformation, integration, and visualization. Support a variety of data sources, file types, big data related database, relational database, NoSQL database, etc. Through the software can realize the management of multiple data sources, the data under the source of various operations conversion, making data charts, monitoring data sources and other functions.               Get Started             Download             Join Us On GitHub             View online examples"},{"location":"index.html#overview","title":"Overview","text":"<p> Datacap is fast, lightweight, intuitive system. </p> <ul> <li> <p>Powerful yet easy to use </p> <p>Quickly and easily integrate and explore your data, using simple SQL IDE.</p> </li> <li> <p>Integrates with modern databases</p> <p>DataCap can connect to any SQL based datasource through JDBC and Native and Http.</p> </li> <li> <p>Highly Customizable</p> <p>DataCap can quickly connect to new data sources by implementing the methods provided by SPI.</p> </li> <li> <p>Join (DingTalk \uff5c WeChat)</p> <p> </p> </li> </ul>"},{"location":"index.html#supported-connectors","title":"Supported Connectors","text":""},{"location":"download.html","title":"Download","text":"The current datacap release is version . Learn more details from the release notes.  <ul> <li> <p> Server packages</p> <p>Utilize the <code>.tar.gz</code> package to manually deploy. See Installation datacap for complete install instructions.</p> <p></p> <p>datacap-server-1.16.0.tar.gz</p> </li> <li> <p> Command line client</p> <p>You can run queries using the interactive command line interface.</p> <p></p> <p>datacap-client-cli-1.16.0.jar</p> </li> <li> <p> More package</p> <p>See The source code to install for complete install instructions.</p> <p></p> <p>Source Code</p> </li> </ul> <ul> <li> <p>Community resources</p> <ul> <li>Chat On Slack: edurtio.slack.com</li> <li>Issues: GitHub issues</li> <li>DingTalk: 16160001608</li> </ul> </li> <li> <p>Getting help</p> <p>If you need help using or running dbm, please ask a question on Slack. Please report any issue you find with dbm.</p> </li> </ul>"},{"location":"powered_by.html","title":"Use cases","text":"Add Your or Company <p>Note</p> <p>There are many companies, individuals and open source organizations that use this program. Some of them are listed below.</p>"},{"location":"powered_by.html#open-project","title":"Open Project","text":"<ul> <li> <p> DataCap developer</p> <p>DataCap is integrated software for data transformation, integration and visualization.   Getting started</p> </li> </ul>"},{"location":"powered_by.html#personal-user","title":"Personal user","text":"<ul> <li> <p> qianmoQ</p> <p>Source code contributors who love open source projects.  Visit qianmoQ</p> </li> <li> <p> Stacey1018</p> <p>I can make it through the rain. I can stand up once again on my own.  Visit Stacey1018</p> </li> </ul>"},{"location":"developer_guide/env.html","title":"Development environment","text":"<p>The development environment is mainly divided into two services and a document module. The following is a detailed description of the construction of each service environment.</p> <p>Warning</p> <p>Before development, please import the format files of the code into the editor, they are in the <code>configure</code> directory</p>"},{"location":"developer_guide/env.html#server","title":"Server","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment","title":"Depends on the environment","text":"Environment Version Required <code>JDK</code> &gt;= 1.8 Need <code>Maven</code> &gt;= 3.5 Optional"},{"location":"developer_guide/env.html#source-code-preparation","title":"Source code preparation","text":"<p>Fork the code in the code warehouse and clone the code to the local, enter the source code directory</p> <pre><code>git clone git@github.com:&lt;GitHubUser&gt;/datacap.git\n</code></pre>"},{"location":"developer_guide/env.html#load-source-code","title":"Load source code","text":"<p>Open idea to load the project</p> <p></p> <p>After opening the project, the right menu displays the project directory</p> <p></p> <ul> <li><code>configure</code> Some configurations used by the project</li> <li><code>dist</code> Binary file storage path after the project is packaged</li> <li><code>docs</code> Project Documentation Source Code</li> <li><code>plugin</code> Project plug-in source code</li> <li><code>server</code> Project main service source code</li> <li><code>spi</code> Project plug-in integration core source code</li> <li><code>web</code> Project web front-end source code</li> </ul>"},{"location":"developer_guide/env.html#service-start","title":"Service start","text":"<p>Service startup needs to modify the specified configuration file directory</p> <p></p> <p>Add <code>--spring.config.location=</code> configuration in <code>Program arguments</code></p> <p>The content of the configuration file is the current project startup service configuration, and the configuration source code is in <code>server/src/main/etc/conf</code></p> <p>After the service is configured, it can be started. After the service is started, access <code>http://localhost:9096/</code></p>"},{"location":"developer_guide/env.html#web","title":"Web","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment_1","title":"Depends on the environment","text":"Environment Version Required <code>Node</code> &gt;= v16.x Need <code>Npm</code> &gt;= 7.x Need <p><code>console-fe</code> The web front-end source code is in this directory</p>"},{"location":"developer_guide/env.html#service-start_1","title":"Service start","text":"<ul> <li>Go to the source code directory</li> </ul> <pre><code>cd web/console-fe\n</code></pre> <ul> <li>Start service</li> </ul> <pre><code>yarn run dev\n</code></pre> <p>After the command is executed, the source code will be compiled, and something similar to the following will appear after compilation</p> <pre><code>...\nUse /* eslint-disable */ to ignore all warnings in a file.\n\nApp running at:\n- Local:   http://localhost:8080/ \n- Network: http://192.168.32.53:8080/\n\nNote that the development build is not optimized.\nTo create a production build, run yarn build.\n\nNo issues found.\n</code></pre> <p>Access <code>http://localhost:8080</code> through a browser to debug the source code, do not use the address returned by <code>Network</code></p>"},{"location":"developer_guide/env.html#docs","title":"Docs","text":"<p>Warning</p> <p>Unnecessary problems are not avoided, please be sure to read the dependent environment configuration</p>"},{"location":"developer_guide/env.html#depends-on-the-environment_2","title":"Depends on the environment","text":"Environment Version Required <code>mkdocs</code> &gt;= 1.3.0 Need <p><code>docs/docs</code> Document source code is in this directory</p>"},{"location":"developer_guide/env.html#service-start_2","title":"Service start","text":"<ul> <li>Go to the source code directory</li> </ul> <pre><code>cd docs\n</code></pre> <ul> <li>Start service</li> </ul> <pre><code>mkdocs serve --dev-addr=0.0.0.0:8001\n</code></pre> <p>After the command is executed, the source code will be compiled, and something similar to the following will appear after compilation</p> <pre><code>...\nINFO     -  Documentation built in 1.07 seconds\nINFO     -  [13:16:03] Watching paths for changes: 'docs', 'mkdocs.yml'\nINFO     -  [13:16:03] Serving on http://0.0.0.0:8001/\nINFO     -  [13:16:03] Browser connected: http://0.0.0.0:8001/developer_guide/env.html\n</code></pre> <p>Access <code>http://0.0.0.0:8001</code> through a browser to debug the source code</p>"},{"location":"developer_guide/plugin-java.html","title":"Java Implementation","text":"<p>DataCap supports custom plug-ins, and users can write their own plug-ins and integrate them into the system. This document mainly explains how to quickly integrate a plug-in into the DataCap system.</p> <p>Note</p> <p>This article demonstrates by integrating the QuestDB data storage system based on the HTTP protocol.</p>"},{"location":"developer_guide/plugin-java.html#pomxml-depend","title":"<code>pom.xml</code> Depend","text":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-spi&lt;/artifactId&gt;\n    &lt;scope&gt;provided&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-common&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;commons-beanutils&lt;/groupId&gt;\n    &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.testcontainers&lt;/groupId&gt;\n    &lt;artifactId&gt;testcontainers&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>The above configuration adds <code>datacap-spi</code> and <code>datacap-common</code> modules, and others are some auxiliary dependencies.</p> <p>Warning</p> <p>It should be noted that if you open the project separately, you need to specify the version number of each dependency.</p>"},{"location":"developer_guide/plugin-java.html#plugin-loader","title":"Plugin Loader","text":"<pre><code>public class QuestDBPluginModule\n        extends AbstractPluginModule\n        implements PluginModule\n{\n    @Override\n    public String getName()\n    {\n        return \"QuestDB\";\n    }\n\n    @Override\n    public PluginType getType()\n    {\n        return PluginType.HTTP;\n    }\n\n    @Override\n    public AbstractPluginModule get()\n    {\n        return this;\n    }\n\n    protected void configure()\n    {\n        Multibinder&lt;Plugin&gt; plugin = Multibinder.newSetBinder(this.binder(), Plugin.class);\n        plugin.addBinding().to(QuestDBPlugin.class);\n    }\n}\n</code></pre> <p>The loader needs to inherit the <code>AbstractPluginModule</code> class and implement the <code>PluginModule</code> interface, so that the system will automatically load the plug-in into the system when it starts.</p> <p>Note</p> <p>It should be noted that you need to override the <code>configure()</code> method in the parent class and bind the plugin to the system.</p>"},{"location":"developer_guide/plugin-java.html#plugin-executor","title":"Plugin Executor","text":"<pre><code>@Slf4j\npublic class QuestDBPlugin\n        implements Plugin\n{\n    private HttpConfigure configure;\n    private HttpConnection connection;\n    private Response response;\n\n    @Override\n    public String name()\n    {\n        return \"QuestDB\";\n    }\n\n    @Override\n    public String description()\n    {\n        return \"Integrate QuestDB data sources\";\n    }\n\n    @Override\n    public PluginType type()\n    {\n        return PluginType.HTTP;\n    }\n\n    @Override\n    public void connect(Configure configure)\n    {\n        try {\n            this.response = new Response();\n            this.configure = new HttpConfigure();\n            BeanUtils.copyProperties(this.configure, configure);\n            this.connection = new HttpConnection(this.configure, this.response);\n        }\n        catch (Exception ex) {\n            this.response.setIsConnected(Boolean.FALSE);\n            this.response.setMessage(ex.getMessage());\n        }\n    }\n\n    @Override\n    public Response execute(String content)\n    {\n        if (ObjectUtils.isNotEmpty(this.connection)) {\n            log.info(\"Execute questdb plugin logic started\");\n            this.response = this.connection.getResponse();\n            QuestDBAdapter processor = new QuestDBAdapter(this.connection);\n            this.response = processor.handlerExecute(content);\n            log.info(\"Execute questdb plugin logic end\");\n        }\n        this.destroy();\n        return this.response;\n    }\n\n    @Override\n    public void destroy()\n    {\n        if (ObjectUtils.isNotEmpty(this.connection)) {\n            this.connection.destroy();\n        }\n    }\n}\n</code></pre> <p>The executor needs to implement the <code>Plugin</code> interface, which provides the following methods</p> <ul> <li><code>name()</code>: Plugins have unique names, and plugins with the same name will only take effect the first time they are loaded</li> <li><code>description()</code>: A description of the plugin</li> <li><code>type()</code>: Plugin type</li> <li><code>connect(Configure configure)</code>: Plug-ins need connection information in advance, such as the current plug-in plug-in, which is the connection phase of the plug-in (the system presets the HTTP connection method to be used directly).</li> <li><code>execute(String content)</code>: Execute the operation logic</li> <li><code>destroy()</code>:  The final destruction of the plug-in, note that the destruction needs to contain the information in the connection</li> </ul>"},{"location":"developer_guide/plugin-java.html#plugin-converter","title":"Plugin Converter","text":"<pre><code>@Slf4j\npublic class QuestDBAdapter\n        extends HttpAdapter\n{\n    public QuestDBAdapter(HttpConnection connection)\n    {\n        super(connection);\n    }\n\n    @Override\n    public Response handlerExecute(String content)\n    {\n        Time processorTime = new Time();\n        processorTime.setStart(new Date().getTime());\n        Response response = this.httpConnection.getResponse();\n        HttpConfigure configure = new HttpConfigure();\n        if (response.getIsConnected()) {\n            List&lt;String&gt; headers = new ArrayList&lt;&gt;();\n            List&lt;String&gt; types = new ArrayList&lt;&gt;();\n            List&lt;Object&gt; columns = new ArrayList&lt;&gt;();\n            try {\n                BeanUtils.copyProperties(configure, this.httpConnection.getConfigure());\n                configure.setAutoConnected(Boolean.FALSE);\n                configure.setRetry(0);\n                configure.setMethod(HttpMethod.GET);\n                configure.setPath(\"exec\");\n                Map&lt;String, String&gt; parameters = Maps.newHashMap();\n                parameters.put(\"query\", content);\n                configure.setParams(parameters);\n                configure.setDecoded(true);\n                HttpConnection httpConnection = new HttpConnection(configure, new Response());\n                HttpClient httpClient = HttpClient.getInstance(configure, httpConnection);\n                String body = httpClient.execute();\n                QuestDBResponse requestResponse = JSON.objectmapper.readValue(body, QuestDBResponse.class);\n                if (ObjectUtils.isNotEmpty(requestResponse.getQuery())) {\n                    response.setIsSuccessful(true);\n                    if (ObjectUtils.isNotEmpty(requestResponse.getColumns())) {\n                        requestResponse.getColumns()\n                                .forEach(schema -&gt; {\n                                    headers.add(schema.getName());\n                                    types.add(schema.getType());\n                                });\n                    }\n                    requestResponse.getDataset()\n                            .forEach(record -&gt; columns.add(handlerFormatter(configure.getFormat(), headers, record)));\n                }\n                else {\n                    response.setIsSuccessful(Boolean.FALSE);\n                    response.setMessage(requestResponse.getError());\n                }\n            }\n            catch (Exception ex) {\n                log.error(\"Execute content failed content {} exception \", content, ex);\n                response.setIsSuccessful(Boolean.FALSE);\n                response.setMessage(ex.getMessage());\n            }\n            finally {\n                response.setHeaders(headers);\n                response.setTypes(types);\n                response.setColumns(columns);\n            }\n        }\n        processorTime.setEnd(new Date().getTime());\n        response.setProcessor(processorTime);\n        return response;\n    }\n}\n</code></pre> <p>The plug-in converter is used to convert the result after the current plug-in is executed, and convert it into logic that can be used in DataCap. It is mainly used to encapsulate <code>Response</code> to return the result.</p> <p>This article is a JDBC-based plug-in, so some functions can be realized by directly inheriting the <code>HttpAdapter</code> parent class.</p>"},{"location":"developer_guide/plugin-java.html#spi-loader","title":"SPI loader","text":"<p>Add <code>META-INF</code> and <code>services</code> directory under <code>resources</code> source directory</p> <p>Warning</p> <p><code>services</code> needs to be in the <code>resources</code> directory</p> <p>Create the <code>io.edurt.datacap.spi.PluginModule</code> file, as follows</p> <pre><code>io.edurt.datacap.plugin.http.questdb.QuestDBPluginModule\n</code></pre> <p>The content of this file is the plugin loading module we defined.</p> <p>Warning</p> <p>The unit test of the plug-in can refer to the published plug-in for testing</p>"},{"location":"developer_guide/plugin-kotlin.html","title":"Kotlin Implementation","text":"<p>DataCap supports custom plug-ins, and users can write their own plug-ins and integrate them into the system. This document mainly explains how to quickly integrate a plug-in into the DataCap system.</p> <p>Note</p> <p>This article demonstrates by integrating the StarRocks data storage system based on the JDBC protocol.</p>"},{"location":"developer_guide/plugin-kotlin.html#pomxml-depend","title":"<code>pom.xml</code> Depend","text":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-spi&lt;/artifactId&gt;\n    &lt;scope&gt;provided&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.edurt.datacap&lt;/groupId&gt;\n    &lt;artifactId&gt;datacap-common&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;commons-beanutils&lt;/groupId&gt;\n    &lt;artifactId&gt;commons-beanutils&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n    &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.testcontainers&lt;/groupId&gt;\n    &lt;artifactId&gt;testcontainers&lt;/artifactId&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>The above configuration adds <code>datacap-spi</code> and <code>datacap-common</code> modules, and others are some auxiliary dependencies.</p> <p>Warning</p> <p>It should be noted that if you open the project separately, you need to specify the version number of each dependency.</p>"},{"location":"developer_guide/plugin-kotlin.html#plugin-loader","title":"Plugin Loader","text":"<pre><code>class StarRocksPluginModule : AbstractPluginModule(), PluginModule {\n    override fun getName(): String {\n        return \"StarRocks\"\n    }\n\n    override fun getType(): PluginType {\n        return PluginType.JDBC\n    }\n\n    override fun get(): AbstractPluginModule {\n        return this\n    }\n\n    override fun configure() {\n        val module = Multibinder.newSetBinder(binder(), String::class.java)\n        module.addBinding().toInstance(this.javaClass.simpleName)\n        val plugin: Multibinder&lt;Plugin&gt; = Multibinder.newSetBinder(binder(), Plugin::class.java)\n        plugin.addBinding().to(StarRocksPlugin::class.java)\n    }\n}\n</code></pre> <p>The loader needs to inherit the <code>AbstractPluginModule</code> class and implement the <code>PluginModule</code> interface, so that the system will automatically load the plug-in into the system when it starts.</p> <p>Note</p> <p>It should be noted that you need to override the <code>configure()</code> method in the parent class and bind the plugin to the system.</p>"},{"location":"developer_guide/plugin-kotlin.html#plugin-executor","title":"Plugin Executor","text":"<pre><code>class StarRocksPlugin : Plugin {\n    private val log = getLogger(StarRocksPlugin::class.java)\n\n    private var jdbcConfigure: JdbcConfigure? = null\n    private var jdbcConnection: JdbcConnection? = null\n    private var jdbcResponse: Response? = null\n\n    override fun name(): String {\n        return \"StarRocks\"\n    }\n\n    override fun description(): String {\n        return \"Integrate StarRocks data sources\"\n    }\n\n    override fun type(): PluginType {\n        return PluginType.JDBC\n    }\n\n    override fun connect(configure: Configure?) {\n        try {\n            log.info(\"Connecting to StarRocks\")\n            jdbcResponse = Response()\n            jdbcConfigure = JdbcConfigure()\n            BeanUtils.copyProperties(jdbcConfigure, configure)\n            jdbcConfigure!!.jdbcDriver = \"com.mysql.cj.jdbc.Driver\"\n            jdbcConfigure!!.jdbcType = \"mysql\"\n            jdbcConnection = object : JdbcConnection(jdbcConfigure, jdbcResponse) {}\n        } catch (ex: Exception) {\n            jdbcResponse!!.isConnected = false\n            jdbcResponse!!.message = ex.message\n        }\n    }\n\n    override fun execute(content: String?): Response {\n        if (ObjectUtils.isNotEmpty(jdbcConnection)) {\n            log.info(\"Execute starrocks plugin logic started\")\n            jdbcResponse = jdbcConnection?.response\n            val processor = JdbcAdapter(jdbcConnection)\n            jdbcResponse = processor.handlerExecute(content)\n            log.info(\"Execute starrocks plugin logic end\")\n        }\n        destroy()\n        return jdbcResponse!!\n    }\n\n    override fun destroy() {\n        if (ObjectUtils.isNotEmpty(jdbcConnection)) {\n            jdbcConnection?.destroy()\n            jdbcConnection = null\n        }\n    }\n}\n</code></pre> <p>The executor needs to implement the <code>Plugin</code> interface, which provides the following methods</p> <ul> <li><code>name()</code>: Plugins have unique names, and plugins with the same name will only take effect the first time they are loaded</li> <li><code>description()</code>: A description of the plugin</li> <li><code>type()</code>: Plugin type</li> <li><code>connect(Configure configure)</code>: Plug-ins need connection information in advance, such as the current plug-in plug-in, which is the connection phase of the plug-in (the system presets the HTTP connection method to be used directly).</li> <li><code>execute(String content)</code>: Execute the operation logic</li> <li><code>destroy()</code>:  The final destruction of the plug-in, note that the destruction needs to contain the information in the connection</li> </ul>"},{"location":"developer_guide/plugin-kotlin.html#plugin-converter","title":"Plugin Converter","text":"<p>The plug-in converter is used to convert the result after the current plug-in is executed, and convert it into logic that can be used in DataCap. It is mainly used to encapsulate <code>Response</code> to return the result.</p> <p>This article is a JDBC-based plug-in, so some functions can be realized by directly inheriting the <code>JdbcAdapter</code> parent class.</p>"},{"location":"developer_guide/plugin-kotlin.html#spi-loader","title":"SPI loader","text":"<p>Add <code>META-INF</code> and <code>services</code> directory under <code>resources</code> source directory</p> <p>Warning</p> <p><code>services</code> needs to be in the <code>resources</code> directory</p> <p>Create the <code>io.edurt.datacap.spi.PluginModule</code> file, as follows</p> <pre><code>io.edurt.datacap.plugin.jdbc.starrocks.StarRocksPluginModule\n</code></pre> <p>The content of this file is the plugin loading module we defined.</p> <p>Warning</p> <p>The unit test of the plug-in can refer to the published plug-in for testing</p>"},{"location":"developer_guide/pipeline/home.html","title":"Pipeline","text":"<p>In the DataCap system, users can configure the pipeline function at will and adjust it arbitrarily according to the version of the low-level executor. The system will automatically identify and compile the final configuration according to the configuration and send it to the executor.</p> <p>The configurations we can provide are:</p> Field Type Description <code>field</code> <code>String</code> Field name <code>origin</code> <code>String</code> The default is equal to the field value, and the custom column name is used. If it is in <code>host|port</code> format, the system will splice the fields through <code>:</code> <code>required</code> <code>Boolean</code> When the value is <code>true</code>, it means that the field is required <code>override</code> <code>Boolean</code> If this flag is <code>true</code>, it means that the field is extracted through user configuration, the default data will be discarded <code>input</code> <code>Boolean</code> Whether it is an input parameter <code>width</code> <code>Integer</code> Component width, default <code>300</code> <code>type</code> <code>FieldType</code> Field type, default <code>INPUT</code> <code>tooltip</code> <code>String</code> Prompt message <code>description</code> <code>String</code> Description <code>value</code> <code>Object</code> The result of the current configuration input <code>hidden</code> <code>Boolean</code> If this configuration item is <code>true</code>, the front end will not be displayed and will only be displayed after enabling it. <code>defaultValues</code> <code>Array</code> If the type is SELECT , you need to pass in default data <p>Danger</p> <p>We do not recommend users to modify the above configurations by themselves. If there are any configuration abnormalities, the plug-in will not be able to use this function.</p>"},{"location":"reference/admin/datasource/home.html","title":"Data Source","text":"<p>Note</p> <p>Through the data source feature, you can add support for various custom data sources, perform subsequent data source operations, and so on.</p> <p>Move the mouse over the <code>Admin</code> logo of the top menu, the drop-down box will pop up, click the first submenu in the drop-down box. A window similar to the following pops up, the default list is empty, you need to add it yourself.</p> <p></p> <p>If you added a data source, a page similar to the following appears</p> <p></p>"},{"location":"reference/admin/datasource/home.html#add-a-data-source","title":"Add a data source","text":"<p>Click the Add button on the right side of the list display area (it is a <code>+</code> icon), and after clicking it, the Add Data Source window will pop up as follows</p> <p></p> <p>When we select a certain type of data source, the data source configuration information will be displayed in the top tab bar, different data sources have different configuration items, and its configuration order is in the specified directory of service startup.</p> <p>When we select the source of type <code>MySQL</code>, a window similar to the following pops up</p> <p></p> <p>4 tabs appear in the configuration page, click on the different tabs to fill in the relevant information, and then click the <code>Test</code> button at the bottom, the following page will pop up:</p> <p></p> <p>When the data source is successfully tested, the version number of the current service will be displayed at the top, and you can save the data by clicking the <code>Save</code> button at the bottom.</p> <p>Note</p> <p>After the data source is saved, the list of data sources is automatically refreshed.</p>"},{"location":"reference/admin/datasource/home.html#modify-the-data-source","title":"Modify the data source","text":"<p>Click the first button in <code>Action</code> in a data source in the list to modify the data source, similar to the <code>Add Data Source</code> action</p>"},{"location":"reference/admin/datasource/home.html#delete-the-data-source","title":"Delete the data source","text":"<p>Click the second button in <code>Action</code> for a data source in the list to delete the data source, and the following will pop up after clicking</p> <p></p> <p>Click the small pop-up window and click <code>OK</code> to delete the selected data source.</p> <p>Danger</p> <p>It is important to note that when a data source is deleted, the query history associated with the data source is deleted.</p>"},{"location":"reference/admin/datasource/home.html#data-source-management","title":"Data source management","text":"<p>Click the third or fourth button in the <code>Action</code> of the data source in the list to jump to the data source management page.</p> <p></p> <p>The page is divided into two parts: left and right. The left side mainly displays the basic information of the data source, including:</p> <ul> <li>Select the relevant metadata for the data source</li> </ul>"},{"location":"reference/admin/datasource/home.html#information-module","title":"Information module","text":"<p>When we select the database and data table on the left, the content on the right is displayed as follows</p> <p></p> <p>Two tabs appear in the right content:</p> <ul> <li><code>Info</code>\uff08Default options\uff09</li> <li><code>Data</code></li> </ul> <p>Note</p> <p>By default, information about the current table is displayed under the Current tab.</p>"},{"location":"reference/admin/datasource/home.html#data-modules","title":"Data modules","text":"<p>Click the <code>Data</code> tab and a page similar to the following will appear, which displays the relevant data of the currently selected table.</p> <p></p> <p>The four buttons at the top are:</p> <ul> <li><code>First Page</code></li> <li><code>Previous Page</code></li> <li><code>Next Page</code></li> <li><code>Last Page</code></li> </ul> <p>The next button is to set the configuration for the data query:</p> <p></p> <ul> <li><code>Jump to Page</code></li> <li><code>Show Page Size</code></li> </ul> <p>Once the configuration is populated, click the <code>Apply</code> button to apply the current configuration information.</p> <p>There is also a button on the right, which will display the detailed <code>SQL</code> content used by the current query</p> <p></p> <p>Note</p> <p>The current SQL generation is based on the order in which it is synchronized to the metadata.</p> <p>Danger</p> <p>At present, not all data sources support management, you can add your own templates if needed. If you are interested, you can contribute the source code to us.</p>"},{"location":"reference/admin/functions/home.html","title":"Functions","text":"<p>Note</p> <p>We can enhance the automatic prompt function of the code editor through the function module provided by the system.</p>"},{"location":"reference/admin/functions/home.html#system-default-function","title":"System default function","text":"<p>The system has built-in the following data source functions by default (it does not mean that it is the most complete function of the new version, if there is something missing, please submit issues or pr to fix it):</p> <ul> <li>ClickHouse</li> <li>MySQL</li> <li>Hive</li> <li>Trino &amp; Presto (fit a part)</li> </ul>"},{"location":"reference/admin/functions/home.html#add-function","title":"Add function","text":"<p>After entering the system, click the corresponding <code>Function</code> submenu under the top <code>Settings</code> menu to go to the function configuration function</p> <p></p> <p>Click the Add button on the top right to add a new function, and the following window will pop up after clicking:</p> <p></p> <p>The following is a detailed parameter description:</p> <ul> <li><code>Name</code>: The name used to mark the function prompt, the suggestion is English</li> <li><code>Plugin</code>: The plugin this function applies to, multiple options can be selected</li> <li><code>Content</code>: The specific content of the function, which will be entered into the editor</li> <li><code>Description</code>: Description of the function</li> <li><code>Type</code>: Type of function, can be: <code>KeyWord</code>, <code>Operator</code>, <code>Function</code>, default is <code>KeyWord</code></li> <li><code>Example</code>: For the use example of this function, it is convenient for users to understand how to use the function</li> </ul> <p>When the above content is written, click the <code>Submit</code> button at the bottom to save the operation, and you can use it in the editor later.</p>"},{"location":"reference/admin/functions/home.html#batch-operation","title":"Batch operation","text":"<p>The system provides a way to import functions in batches. Currently, it supports the import of content and URI addresses. Next, let's take a look at how to do it.</p> <p>We perform the batch import function by clicking the import button on the top right.</p>"},{"location":"reference/admin/functions/home.html#content-import","title":"Content import","text":"<p>The content import method allows us to enter a list of functions, and they are divided according to each line. Adding the following keywords we need to import:</p> <pre><code>SHOW\nUSE\n</code></pre> <p>In <code>Plugin</code>, we choose to use the <code>ClickHouse</code> plug-in, and in <code>Type</code>, we choose <code>KeyWord</code>. After the operation is completed, we click the <code>Submit</code> button at the bottom to use the import function of the current input function.</p>"},{"location":"reference/admin/functions/home.html#uri-import","title":"URI import","text":"<p>The URI import method is relatively simple. We can import data in batches by specifying the remote server URI address, which can be your local server address or the address provided by the software.</p> <p>The URI address format provided by the software by default is</p> <pre><code>(http|https)://datacap.edurt.io/resources/functions/plugin/keywords.txt\n(http|https)://datacap.edurt.io/resources/functions/plugin/operators.txt\n(http|https)://datacap.edurt.io/resources/functions/plugin/functions.txt\n</code></pre> <p>We only need to replace the value of plugin in the address with the name of the plugin that needs to be imported.</p> <p>Warning</p> <p>It should be noted that due to local network problems, the URI import method may be slow.</p>"},{"location":"reference/admin/history/query/home.html","title":"Query history","text":"<p>Move the mouse over the <code>Admin</code> logo in the top menu, the drop-down box will pop up, click the <code>History</code> submenu in the drop-down box. A window similar to the following pops up, the default list is empty, and records can be automatically added by querying through the query page.</p> <p></p>"},{"location":"reference/admin/history/query/home.html#review-executing-sql","title":"Review Executing SQL","text":"<p>Click the first button in <code>Action</code> in a data in the list to view the specific code snippet content, and a dialog box will pop up, which is roughly as follows</p> <p></p> <p>The specific SQL statements queried in this query are displayed in the window.</p>"},{"location":"reference/admin/history/query/home.html#review-the-execution-errors","title":"Review the execution errors","text":"<p>Danger</p> <p>You can view error information only if the query is exceptional.</p> <p>Click the second button in <code>Action</code> in one of the data in the list to view the error message</p> <p></p>"},{"location":"reference/admin/pipeline/home.html","title":"Pipeline","text":"<p>In the DataCap software, the pipeline is a tool for users to perform some data operations such as data migration.</p>"},{"location":"reference/admin/pipeline/home.html#build-pipeline","title":"Build pipeline","text":"<p>After entering the system, click the corresponding <code>Pipeline</code> submenu under the <code>Admin</code> menu at the top to enter the pipeline list by default. Similar to the picture below:</p> <p></p> <p>Click the <code>+ Create</code> button on the right side of the list, and the system will pop up the configuration page:</p> <p></p> <p>The configuration page is divided into three configuration modules, namely:</p> <ul> <li><code>Description</code> mainly configures the SQL executed by the user</li> <li><code>From</code> configures the data access source</li> <li><code>To</code> configure data output source</li> </ul> <p>Each data source has different configuration properties. After selecting the data source, just follow the prompts to configure the relevant properties.</p> <p>When the task is successfully published, the task list will be refreshed by default, as shown in the following figure:</p> <p></p>"},{"location":"reference/admin/pipeline/home.html#pipeline-management","title":"Pipeline management","text":"<p>After the task is released, it will be started by default. The <code>Action</code> operation on the right side of the task contains the following functions:</p>"},{"location":"reference/admin/pipeline/home.html#view-errors","title":"View errors","text":"<p>When we click the first button in <code>Action</code>, the system will pop up an error message page.</p> <p>This feature will only be enabled if the task fails</p> <p></p>"},{"location":"reference/admin/pipeline/home.html#view-log","title":"View log","text":"<p>When we click the second button in <code>Action</code>, the system will pop up the log page.</p> <p></p>"},{"location":"reference/admin/pipeline/home.html#task-stopped","title":"Task stopped","text":"<p>When we click the third button in <code>Action</code>, the system will pop up the stop task page.</p> <p>This feature will only be enabled when the task is running</p> <p></p> <p>We enter the task name according to the information prompted in the window and click the <code>Stop</code> button.</p>"},{"location":"reference/admin/pipeline/home.html#task-deletion","title":"Task deletion","text":"<p>When we click the fourth button in <code>Action</code>, the system will pop up the delete task page.</p> <p></p> <p>We enter the task name according to the information prompted in the window and click the <code>Delete</code> button.</p>"},{"location":"reference/admin/processor/home.html","title":"Processor","text":"<p>Note</p> <p>Through the process monitoring function, you can view some specific processes currently being executed by the data source</p>"},{"location":"reference/admin/processor/home.html#view-all-processes","title":"View all processes","text":"<p>After entering the system, click the corresponding <code>Processor</code> submenu under the top <code>Admin</code> menu to go to the function configuration function</p> <p></p> <p>Select the data source we need to view the process through the drop-down box at the top, and it will be refreshed and displayed in the content area below</p> <p></p> <p>Danger</p> <p>It should be noted that different data sources have different presentation methods</p>"},{"location":"reference/admin/processor/home.html#not-support","title":"Not support","text":"<p>When we view the unsupported data source, the content of the page is as follows:</p> <p></p> <p>The system will prompt us to add SQL template or submit issues to support it</p>"},{"location":"reference/admin/profile/home.html","title":"Personal Data","text":"<p>Note</p> <p>The profile feature provides an overview of some of the query history and data source usage of individual users.</p> <p>Hover the mouse over the avatar menu on the far right of the top menu, a drop-down box will pop up, click the first submenu in the drop-down box. A window similar to the following pops up:</p> <p></p> <p>First of all, the top chart we see is the query calendar chart for the past year. It is calculated based on the summary of the total number of queries per day.</p> <p>The second chart shows the data source usage in the last 7 days. It is calculated based on a daily summary of data source usage.</p>"},{"location":"reference/admin/profile/home.html#profile","title":"Profile","text":"<p>When you click on the profile button (the first button on the left menu), you will see a pop-up window like this:</p> <p></p> <p>This page mainly displays the basic information of the profile.</p>"},{"location":"reference/admin/profile/home.html#login-logs","title":"Login logs","text":"<p>When you click the login log button (the second button on the left menu), the following window will pop up:</p> <p></p> <p>This page displays the login logs of the current user, including the login time, login location, and login method.</p>"},{"location":"reference/admin/profile/home.html#account-settings","title":"Account Settings","text":"<p>When you click on the Account Settings button (the third button on the left menu), the following window will pop up:</p> <p></p> <p>This page mainly shows some of the configuration functions that users can make.</p>"},{"location":"reference/admin/profile/home.html#username","title":"Username","text":"<p>When you click the Modify Username button, the following window will pop up:</p> <p></p> <p>Enter the modified username and current password, and click the OK button to complete the modification.</p> <p>Danger</p> <p>It should be noted that after changing the user name, you need to log in again. The system will log out of the current account by default.</p>"},{"location":"reference/admin/profile/home.html#password","title":"Password","text":"<p>When you click the Change Password button, the following window will pop up:</p> <p></p> <p>Enter the original password and the new password, and click the OK button to complete the modification.</p> <p>Danger</p> <p>It should be noted that after changing the password, you need to log in again. The system will log out of the current account by default.</p>"},{"location":"reference/admin/profile/home.html#chatgpt","title":"ChatGPT","text":"<p>When you click the ChatGPT button, the following window will pop up:</p> <p></p> <p>This page mainly shows some of the configuration features that ChatGPT can do.</p>"},{"location":"reference/admin/profile/home.html#editor","title":"Editor","text":"<p>When you click the editor button, the following window will pop up:</p> <p></p> <p>When you modify the editor, the modified configuration is synchronized to all locations in the system that use the editor.</p> <p>The editor's changes are WYSIWYG and show the current configuration scheme in real time.</p>"},{"location":"reference/admin/snippet/home.html","title":"Snippet","text":"<p>Note</p> <p>The snippet feature allows you to add support for various custom snippets, perform subsequent snippet operations, and more. The added code snippet is then added to the editor.</p> <p>Move your mouse over the <code>Admin</code> icon in the top menu to pop up the drop-down box, click the <code>Snippet</code> submenu in the drop-down box. A window similar to the following pops up, the default list is empty, you need to add it yourself.</p> <p></p> <p>If you added a fragment, a page similar to the following appears</p> <p></p>"},{"location":"reference/admin/snippet/home.html#add-snippet","title":"Add Snippet","text":"<p>Click the Add button on the right side of the list display area (it is a <code>+</code> icon), and after clicking it, the Add Data Source window will pop up as follows</p> <p></p> <p>In the window, we need to enter the following</p> Attribute Description <code>Name</code> Marks the name of the current snippet <code>Description</code> A description of the current code snippet <code>Snippet</code> The specific SQL content of the current code snippet <p>After filling in the above, click the <code>Submit</code> button at the bottom to save the code snippet.</p> <p>Note</p> <p>After the data is saved, the list of data sources is automatically refreshed.</p>"},{"location":"reference/admin/snippet/home.html#review-the-snippet-content","title":"Review the snippet content","text":"<p>Click the first button in <code>Action</code> in a data in the list to view the specific code snippet content, and a dialog box will pop up, which is roughly as follows</p> <p></p> <p>Click <code>OK</code> or <code>Cancel</code> to close the dialog box</p>"},{"location":"reference/admin/snippet/home.html#modify-the-code-snippet","title":"Modify the code snippet","text":"<p>Click the second button in <code>Action</code> in one of the data in the list to modify the snippet, similar to the <code>Add Snippet</code> action.</p>"},{"location":"reference/admin/snippet/home.html#quote-snippet","title":"Quote Snippet","text":"<p>Click the third button in <code>Action</code> of a piece of data in the list, reference the current code snippet, and you will be taken to the query page, and the fragment content will be entered directly into the editor.</p>"},{"location":"reference/admin/snippet/home.html#delete-the-snippet","title":"Delete the snippet","text":"<p>Click the fourth button in <code>Action</code> of a piece of data in the list to delete the snippet, and the following will pop up after clicking</p> <p></p> <p>Click the small pop-up window and click <code>OK</code> to remove the snippet.</p>"},{"location":"reference/admin/template/sql/home.html","title":"Sql","text":"<p>Note</p> <p>The system supports the SQL template function, through which the realization of some monitoring and other functions can be supported.</p>"},{"location":"reference/admin/template/sql/home.html#default-template","title":"Default template","text":"<p>The system supports some default templates, currently supports:</p> <ul> <li><code>getAllDatabaseAndTable</code></li> <li><code>getAllDatabase</code></li> <li><code>getAllTablesFromDatabase</code></li> </ul> <p>Of course, each template can support one or more plug-ins, and they will be used in subsequent operations of the system.</p>"},{"location":"reference/admin/template/sql/home.html#add-template","title":"Add template","text":"<p>After entering the system, click the corresponding <code>Sql</code> submenu under the top <code>Settings</code> menu to go to the function configuration function</p> <p></p> <p>Click the Add button on the top right to add a new function, and the following window will pop up after clicking:</p> <p></p> <p>The following is a detailed parameter description:</p> <ul> <li><code>Name</code>: The name used to mark the function prompt, the suggestion is English</li> <li><code>Plugin</code>: The plugin this function applies to, multiple options can be selected</li> <li><code>Description</code>: Description of the function</li> <li><code>Template</code>: The SQL statement executed by the template</li> </ul> <p>When the above content is written, click the <code>Submit</code> button at the bottom to save the operation, and you can use it in the editor later.</p> <p>Warning</p> <p>The default template does not carry any parameters and we can execute it directly.</p>"},{"location":"reference/admin/template/sql/home.html#dynamic-parameter-template","title":"Dynamic parameter template","text":"<p>We can realize the template dynamic parameter passing function by defining variables. Let's take an example, we need to display all the data tables under the <code>default</code> database, the normal SQL is</p> <pre><code>SHOW TABLES FROM default\n</code></pre> <p>When we use the template, the SQL changes to</p> <pre><code>SHOW TABLES FROM ${database:String}\n</code></pre> <p>The system parses the parameter into <code>database=String</code> by collecting <code>{database:String}</code> expression, where <code>database</code> is the parameter name, and <code>String</code> is the type of parameter passing.</p> <p>When we use the expression time, we only need to pass the <code>Map</code> type parameter, where key=parameter name, value=data value passed according to the type.</p>"},{"location":"reference/clients/cli.html","title":"Command line interface","text":"<p>The DataCap CLI provides a terminal-based, interactive shell for running queries. The CLI is a self-executing JAR file, which means it acts like a normal UNIX executable.</p>"},{"location":"reference/clients/cli.html#requirements","title":"Requirements","text":"<p>The CLI requires a Java virtual machine available on the path. It can be used with Java version 8 and higher.</p> <p>The CLI uses the DataCap client REST API over HTTP/HTTPS to communicate with the system.</p> <p>The CLI version should be identical to the version of system, or newer.</p>"},{"location":"reference/clients/cli.html#installation","title":"Installation","text":"<p>Download datacap-client-cli-1.6.0.jar, rename it to datacap, make it executable with <code>chmod +x</code>.</p>"},{"location":"reference/clients/cli.html#running-the-cli","title":"Running the CLI","text":"<pre><code>./datacap\n\nconnect -h 127.0.0.1 -p 9096 -u username -P password\n</code></pre> <p>If successful, you will get a prompt to execute commands. Use the <code>help</code> command to see a list of supported commands.</p> Command Description <code>source info</code> Get data source details <code>source list</code> Get a list of remote server data sources <code>source use &lt;SourceID&gt;</code> Set the data source flag for subsequent operations on the data source <code>source execute \"&lt;QuerySQL&gt;\"</code> Execute remote SQL"},{"location":"reference/connectors/index.html","title":"Connectors","text":"<p>This chapter describes the connectors available in DataCap to access data from different data sources.</p>"},{"location":"reference/connectors/index.html#jdbc","title":"JDBC","text":"<p>DuckDB Yandex Database Snowflake MySQL ClickHouse </p>"},{"location":"reference/connectors/index.html#native","title":"Native","text":"<p>H2 Database Apache Kafka Aliyun OSS Apache Zookeeper Redis </p>"},{"location":"reference/connectors/index.html#http","title":"Http","text":"<p>ClickHouse </p>"},{"location":"reference/connectors/cassandra.html","title":"Apache Cassandra","text":""},{"location":"reference/connectors/cassandra.html#what-is-cassandra","title":"What is Cassandra ?","text":"<p>Apache Cassandra\u00ae powers mission-critical deployments with improved performance and unparalleled levels of scale in the cloud.</p>"},{"location":"reference/connectors/cassandra.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.11.x</code></p> <p>Support Time: <code>2023-06-07</code></p>"},{"location":"reference/connectors/cassandra.html#configure","title":"Configure","text":"<p>Note</p> <p>If your plugin service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9042</code> Field Required Default Value <code>Database</code> <code>datacenter</code>"},{"location":"reference/connectors/cassandra.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>0.4.x</code></li> </ul>"},{"location":"reference/connectors/http/ceresdb.html","title":"CeresDB","text":""},{"location":"reference/connectors/http/ceresdb.html#what-is-ceresdb","title":"What is CeresDB ?","text":"<p>CeresDB is a high-performance, distributed, cloud native time-series database.</p>"},{"location":"reference/connectors/http/ceresdb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-12</code></p>"},{"location":"reference/connectors/http/ceresdb.html#configure","title":"Configure","text":"<p>Note</p> <p>If your CeresDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>5440</code>"},{"location":"reference/connectors/http/ceresdb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 1.x</li> </ul>"},{"location":"reference/connectors/http/clickhouse.html","title":"ClickHouse","text":""},{"location":"reference/connectors/http/clickhouse.html#what-is-clickhouse","title":"What is ClickHouse ?","text":"<p>ClickHouse\u00ae is a column-oriented database management system (DBMS) for online analytical processing of queries (OLAP). ClickHouse\u2019s performance exceeds all other column-oriented database management systems. It processes billions of rows and tens of gigabytes of data per server per second.</p>"},{"location":"reference/connectors/http/clickhouse.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.3.x</code></p> <p>Support Time: <code>2022-11-09</code></p>"},{"location":"reference/connectors/http/clickhouse.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default clickhouse.json</p> <p>Note</p> <p>If your ClickHouse service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>8123</code>"},{"location":"reference/connectors/http/clickhouse.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 19.x</li> <li> 20.x</li> <li> 21.x</li> </ul>"},{"location":"reference/connectors/http/greptimedb.html","title":"GreptimeDB","text":""},{"location":"reference/connectors/http/greptimedb.html#what-is-greptimedb","title":"What is GreptimeDB ?","text":"<p>An open-source, cloud-native, distributed time-series database with PromQL/SQL/Python supported.</p>"},{"location":"reference/connectors/http/greptimedb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-14</code></p>"},{"location":"reference/connectors/http/greptimedb.html#configure","title":"Configure","text":"<p>Note</p> <p>If your GreptimeDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>4000</code>"},{"location":"reference/connectors/http/greptimedb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 0.x</li> </ul>"},{"location":"reference/connectors/http/questdb.html","title":"QuestDB","text":""},{"location":"reference/connectors/http/questdb.html#what-is-questdb","title":"What is QuestDB ?","text":"<p>QuestDB is an open-source time-series database for high throughput ingestion and fast SQL queries with operational simplicity. It supports schema-agnostic ingestion using the InfluxDB line protocol, PostgreSQL wire protocol, and a REST API for bulk imports and exports.</p>"},{"location":"reference/connectors/http/questdb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-17</code></p>"},{"location":"reference/connectors/http/questdb.html#configure","title":"Configure","text":"<p>Note</p> <p>If your QuestDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code>"},{"location":"reference/connectors/http/questdb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 7.x</li> </ul>"},{"location":"reference/connectors/jdbc/clickhouse.html","title":"ClickHouse","text":""},{"location":"reference/connectors/jdbc/clickhouse.html#what-is-clickhouse","title":"What is ClickHouse ?","text":"<p>ClickHouse\u00ae is a column-oriented database management system (DBMS) for online analytical processing of queries (OLAP). ClickHouse\u2019s performance exceeds all other column-oriented database management systems. It processes billions of rows and tens of gigabytes of data per server per second.</p>"},{"location":"reference/connectors/jdbc/clickhouse.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.0.x</code></p> <p>Support Time: <code>2022-09-22</code></p>"},{"location":"reference/connectors/jdbc/clickhouse.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default clickhouse.json</p> <p>Note</p> <p>If your ClickHouse service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> - <p>Note</p> <p>You can add the already supported ClickHouse parameters by adding Key Value, the parameters can be reference document</p>"},{"location":"reference/connectors/jdbc/clickhouse.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 19.x</li> <li> 20.x</li> <li> 21.x</li> </ul>"},{"location":"reference/connectors/jdbc/doris.html","title":"Apache Doris","text":""},{"location":"reference/connectors/jdbc/doris.html#what-is-doris","title":"What is Doris ?","text":"<p>An easy-to-use, high-performance and unified analytical database</p>"},{"location":"reference/connectors/jdbc/doris.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-19</code></p>"},{"location":"reference/connectors/jdbc/doris.html#configure","title":"Configure","text":"<p>Note</p> <p>If your Doris service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9093</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"reference/connectors/jdbc/doris.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p>"},{"location":"reference/connectors/jdbc/duckdb.html","title":"DuckDB","text":""},{"location":"reference/connectors/jdbc/duckdb.html#what-is-duckdb","title":"What is DuckDB ?","text":"<p>DuckDB is an in-process SQL OLAP database management system.</p>"},{"location":"reference/connectors/jdbc/duckdb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.6.x</code></p> <p>Support Time: <code>2023-02-20</code></p>"},{"location":"reference/connectors/jdbc/duckdb.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default duckdb.json</p> <p>Note</p> <p>If your DuckDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>/root</code> <code>Port</code> <code>0</code> Field Required Default Value <code>Database</code> <code>local</code>"},{"location":"reference/connectors/jdbc/duckdb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 0.7.0</li> </ul>"},{"location":"reference/connectors/jdbc/hologres.html","title":"Hologres","text":""},{"location":"reference/connectors/jdbc/hologres.html#what-is-hologres","title":"What is Hologres ?","text":"<p>Hologres is an all-in-one real-time data warehouse engine that is compatible with PostgreSQL. It supports online analytical processing (OLAP) and ad hoc analysis of PB-scale data. Hologres supports online data serving at high concurrency and low latency. It is deeply integrated with MaxCompute, Flink and DataWorks, provides a full-stack data warehouse solution that integrates online and offline processing.</p>"},{"location":"reference/connectors/jdbc/hologres.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-25</code></p>"},{"location":"reference/connectors/jdbc/hologres.html#configure","title":"Configure","text":"<p>Note</p> <p>If your Hologres service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>hologres-cn-regison.aliyuncs.com</code> <code>Port</code> <code>80</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"reference/connectors/jdbc/hologres.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> all</li> </ul>"},{"location":"reference/connectors/jdbc/mysql.html","title":"MySQL","text":""},{"location":"reference/connectors/jdbc/mysql.html#what-is-mysql","title":"What is MySQL ?","text":"<p>MySQL is one of the most recognizable technologies in the modern big data ecosystem. Often called the most popular database and currently enjoying widespread, effective use regardless of industry, it\u2019s clear that anyone involved with enterprise data or general IT should at least aim for a basic familiarity of MySQL.</p>"},{"location":"reference/connectors/jdbc/mysql.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.0.x</code></p> <p>Support Time: <code>2022-09-19</code></p>"},{"location":"reference/connectors/jdbc/mysql.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default mysql.json</p> <p>Note</p> <p>If your MySQL service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>3306</code> Field Required Default Value <code>Username</code> - <code>Password</code> - <code>SSL</code> <code>false</code> Field Required Default Value <code>Database</code> <code>default</code> <p>Note</p> <p>You can add the already supported MySQL parameters by adding Key Value, the parameters can be reference document</p> <p>Default:</p> Key value <code>useOldAliasMetadataBehavior</code> <code>true</code>"},{"location":"reference/connectors/jdbc/mysql.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 5.x</li> <li> 6.x</li> <li> 7.x</li> </ul>"},{"location":"reference/connectors/jdbc/pinot.html","title":"Apache Pinot","text":""},{"location":"reference/connectors/jdbc/pinot.html#what-is-pinot","title":"What is Pinot ?","text":"<p>Apache Pinot is a real-time distributed OLAP datastore purpose-built for low-latency, high-throughput analytics, and perfect for user-facing analytical workloads.</p>"},{"location":"reference/connectors/jdbc/pinot.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.10.x</code></p> <p>Support Time: <code>2023-05-06</code></p>"},{"location":"reference/connectors/jdbc/pinot.html#configure","title":"Configure","text":"<p>Note</p> <p>If your Pinot service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorization Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9000</code> Field Required Default Value <code>Username</code> - <code>Password</code> -"},{"location":"reference/connectors/jdbc/pinot.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>0.8.x</code></li> </ul>"},{"location":"reference/connectors/jdbc/snowflake.html","title":"Snowflake","text":""},{"location":"reference/connectors/jdbc/snowflake.html#what-is-snowflake","title":"What is Snowflake ?","text":"<p>Execute your most critical workloads on top of Snowflake's multi-cluster shared data architecture in a fully managed platform that capitalizes on the near-infinite resources of the cloud.</p>"},{"location":"reference/connectors/jdbc/snowflake.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.4.x</code></p> <p>Support Time: <code>2023-01-29</code></p>"},{"location":"reference/connectors/jdbc/snowflake.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default snowflake.json</p> <p>Note</p> <p>If your Snowflake service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvancedCustom Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>80</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> - <p>Note</p> <p>You can add the already supported Snowflake parameters by adding Key Value, the parameters can be reference document</p>"},{"location":"reference/connectors/jdbc/snowflake.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p>"},{"location":"reference/connectors/jdbc/starrocks.html","title":"StarRocks","text":""},{"location":"reference/connectors/jdbc/starrocks.html#what-is-starrocks","title":"What is StarRocks ?","text":"<p>An Open-Source, High-Performance Analytical Database</p>"},{"location":"reference/connectors/jdbc/starrocks.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-20</code></p>"},{"location":"reference/connectors/jdbc/starrocks.html#configure","title":"Configure","text":"<p>Note</p> <p>If your StarRocks service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>9030</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> -"},{"location":"reference/connectors/jdbc/starrocks.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 2.2.x</li> </ul>"},{"location":"reference/connectors/jdbc/ydb.html","title":"Yandex Database","text":""},{"location":"reference/connectors/jdbc/ydb.html#what-is-ydb","title":"What is YDB ?","text":"<p>YDB is a fault-tolerant distributed SQL DBMS. YDB provides high availability, horizontal scalability, strict consistency, and ACID transaction support. Queries are made using an SQL dialect (YQL).</p>"},{"location":"reference/connectors/jdbc/ydb.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.4.x</code></p> <p>Support Time: <code>2023-01-30</code></p>"},{"location":"reference/connectors/jdbc/ydb.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default ydb.json</p> <p>Note</p> <p>If your YDB service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>2136</code> Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code> <code>local</code>"},{"location":"reference/connectors/jdbc/ydb.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 2.1.x</li> </ul>"},{"location":"reference/connectors/native/alioss.html","title":"AliYun OSS","text":""},{"location":"reference/connectors/native/alioss.html#what-is-aliyun-oss","title":"What is Aliyun OSS ?","text":"<p>Fully managed object storage service to store and access any amount of data from anywhere</p>"},{"location":"reference/connectors/native/alioss.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.6.x</code></p> <p>Support Time: <code>2023-02-23</code></p>"},{"location":"reference/connectors/native/alioss.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in Aliyun OSS on DataCap.</p>"},{"location":"reference/connectors/native/alioss.html#select","title":"SELECT","text":"<p>Synopsis</p> <pre><code>SELECT [ * | &lt;Columns&gt; ] select_expression [, ...]\nFROM from_item [. ...]\n</code></pre> <p>where <code>from_item</code> is one of</p> <pre><code>table_name [ `a.b` | a.b | `a`.`b`]\n</code></pre> <p>Danger</p> <p>When <code>table_name</code> is set to <code>all</code> the root directory is searched.</p> <p>Select expressions</p> <p>Each <code>select_expression</code> must be in one of the following forms:</p> <pre><code>expression [ column_alias ]\n</code></pre> <pre><code>*\n</code></pre> <p>In the case of <code>expression [ column_alias ]</code>, a single output column is defined.</p> <p>In the case of <code>*</code>, all columns of the relation defined by the query are included in the result set.</p> <pre><code>    *\n--------\n   data\n</code></pre> <p>Danger</p> <p>If it is a multi-level directory, such as <code>/oss/id/2</code>, it will be written `oss`.`id`.`2`, and use <code>.</code> to split between directories.</p>"},{"location":"reference/connectors/native/alioss.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default alioss.json</p> <p>Note</p> <p>If your Aliyun OSS service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - <code>Host</code> <code>https://oss-cn-regison.aliyuncs.com</code> Field Required Description Default Value <code>Username</code> access Id - <code>Password</code> access Secret - Field Required Description Default Value <code>Database</code> bucket name <code>default</code>"},{"location":"reference/connectors/native/alioss.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>all version</code></li> </ul>"},{"location":"reference/connectors/native/h2.html","title":"H2 Database","text":""},{"location":"reference/connectors/native/h2.html#what-is-h2","title":"What is h2 ?","text":"<p>H2 is an embedded database developed in Java that is itself just a class library. </p>"},{"location":"reference/connectors/native/h2.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.8.x</code></p> <p>Support Time: <code>2023-04-05</code></p>"},{"location":"reference/connectors/native/h2.html#configure","title":"Configure","text":"<p>Note</p> <p>If your h2 service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorizationAdvanced Field Required Default Value <code>Name</code> - Field Required Default Value <code>Username</code> - <code>Password</code> - Field Required Default Value <code>Database</code>"},{"location":"reference/connectors/native/h2.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>all</code></li> </ul>"},{"location":"reference/connectors/native/redis.html","title":"Redis","text":""},{"location":"reference/connectors/native/redis.html#what-is-redis","title":"What is Redis ?","text":"<p>The open source, in-memory data store used by millions of developers as a database, cache, streaming engine, and message broker.</p>"},{"location":"reference/connectors/native/redis.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.3.x</code></p> <p>Support Time: <code>2022-12-01</code></p>"},{"location":"reference/connectors/native/redis.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default redis.json</p> <p>Note</p> <p>If your Redis service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAuthorization Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1</code> <code>Port</code> <code>6379</code> Field Required Default Value <code>Password</code> -"},{"location":"reference/connectors/native/redis.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> 6.x</li> <li> 7.x</li> </ul>"},{"location":"reference/connectors/native/zookeeper.html","title":"Apache Zookeeper","text":""},{"location":"reference/connectors/native/zookeeper.html#what-is-zookeeper","title":"What is Zookeeper ?","text":"<p>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. </p>"},{"location":"reference/connectors/native/zookeeper.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.5.x</code></p> <p>Support Time: <code>2023-02-07</code></p>"},{"location":"reference/connectors/native/zookeeper.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in Zookeeper on DataCap.</p>"},{"location":"reference/connectors/native/zookeeper.html#select","title":"SELECT","text":"<p>Synopsis</p> <pre><code>SELECT [ * | &lt;Columns&gt; ] select_expression [, ...]\nFROM from_item [. ...]\n</code></pre> <p>where <code>from_item</code> is one of</p> <pre><code>table_name [ `a.b` | a.b | `a`.`b`]\n</code></pre> <p>Danger</p> <p>When <code>table_name</code> is set to <code>all</code> the root directory is searched.</p> <p>Select expressions</p> <p>Each <code>select_expression</code> must be in one of the following forms:</p> <pre><code>expression [ column_alias ]\n</code></pre> <pre><code>*\n</code></pre> <p>In the case of <code>expression [ column_alias ]</code>, a single output column is defined.</p> <p>In the case of <code>*</code>, all columns of the relation defined by the query are included in the result set.</p> <pre><code>    *\n--------\n   data\n</code></pre> <p>Danger</p> <p>If it is a multi-level directory, such as <code>/zookeeper/id/2</code>, it will be written `zookeeper`.`id`.`2`, and use <code>.</code> to split between directories.</p>"},{"location":"reference/connectors/native/zookeeper.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default zookeeper.json</p> <p>Note</p> <p>If your Zookeeper service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>127.0.0.1:2181</code> <code>Port</code> <code>1</code>"},{"location":"reference/connectors/native/zookeeper.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>3.1.x</code> - <code>3.7.x</code></li> </ul>"},{"location":"reference/connectors/native/hadoop/hdfs.html","title":"Apache Hadoop HDFS","text":""},{"location":"reference/connectors/native/hadoop/hdfs.html#what-is-hdfs","title":"What is HDFS ?","text":"<p>The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. It has many similarities with existing distributed file systems.</p>"},{"location":"reference/connectors/native/hadoop/hdfs.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.9.x</code></p> <p>Support Time: <code>2023-04-27</code></p>"},{"location":"reference/connectors/native/hadoop/hdfs.html#configure","title":"Configure","text":"<p>Note</p> <p>If your HDFS service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> ConfigureAdvanced Field Required Default Value <code>Name</code> - Field Required Description Default Value <code>file</code> <code>core-site.xml</code> <code>hdfs-site.xml</code> <code>[]</code>"},{"location":"reference/connectors/native/hadoop/hdfs.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>3.x</code></li> </ul>"},{"location":"reference/connectors/native/kafka/index.html","title":"Apache Kafka","text":""},{"location":"reference/connectors/native/kafka/index.html#what-is-apache-kafka","title":"What is Apache Kafka ?","text":"<p>Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.</p>"},{"location":"reference/connectors/native/kafka/index.html#environment","title":"Environment","text":"<p>Note</p> <p>If you need to use this data source, you need to upgrade the DataCap service to &gt;= <code>1.7.x</code></p> <p>Support Time: <code>2023-03-06</code></p>"},{"location":"reference/connectors/native/kafka/index.html#sql-statement-syntax","title":"SQL statement syntax","text":"<p>This chapter describes the SQL syntax used in DataCap Kafka plugin.</p> <p>SHOW TOPICS SHOW CONSUMERS</p>"},{"location":"reference/connectors/native/kafka/index.html#configure","title":"Configure","text":"<p>DataCap uses configuration files by default kafka.json</p> <p>Note</p> <p>If your Apache Kafka service version requires other special configurations, please refer to modifying the configuration file and restarting the DataCap service.</p> Configure Field Required Default Value <code>Name</code> - <code>Host</code> <code>localhost:9092</code>"},{"location":"reference/connectors/native/kafka/index.html#version-validation","title":"Version (Validation)","text":"<p>Warning</p> <p>The online service has not been tested yet, if you have detailed test results, please submit issues to us</p> <ul> <li> <code>1.0.0</code></li> <li> <code>1.1.0</code></li> <li> <code>1.2.0</code></li> </ul>"},{"location":"reference/get_started/install.html","title":"Deploying in Self Host","text":"<p>DataCap is a software for data transformation, integration and visualization.</p>"},{"location":"reference/get_started/install.html#system-requirements","title":"System Requirements","text":"<p>Warning</p> <p>The binary package of the software is compiled and tested based on the following systems. It has not been tested on other versions, and it is theoretically supported.</p> <p>If there is an unsupported system, use the source code compilation method to actively compile the binary file.</p> System Version JDK <code>&gt;=11</code> MySQL <code>&gt;=5.6.x</code>"},{"location":"reference/get_started/install.html#binary-install","title":"Binary install","text":"<p>Note</p> <p>Download the binary software package of the corresponding system from the following address for installation.</p> <ul> <li>Download Release</li> </ul>"},{"location":"reference/get_started/install.html#download-package","title":"Download package","text":"<p>Run the following command after downloading the binary to your local</p> <pre><code>tar -xvzf datacap-release.tar.gz\n</code></pre>"},{"location":"reference/get_started/install.html#configuration-software","title":"Configuration software","text":"<p>For the first installation of the software, you need to import the sql scripts in the <code>schema/datacap.sql</code> file to the MySQL server. Note that the scripts that need to be imported are matched according to the downloaded software package</p> <p>After importing the <code>SQL</code> script, modify the <code>configure/application.properties</code> configuration file to modify the configuration information of the MySQL server</p> <p>Add configuration</p> <pre><code>spring.datasource.url=jdbc:mysql://localhost:3306/datacap?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;allowMultiQueries=true&amp;useSSL=false&amp;useOldAliasMetadataBehavior=true&amp;jdbcCompliantTruncation=false&amp;sessionVariables=sql_mode='STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,PIPES_AS_CONCAT'\nspring.datasource.username=root\nspring.datasource.password=12345678\n</code></pre> <p>Warning</p> <p>If you need to modify the log configuration, just modify the <code>configure/logback.xml</code> configuration file</p>"},{"location":"reference/get_started/install.html#start-service","title":"Start service","text":"<p>DataCap service startup is very simple, execute the following script</p> <pre><code>./bin/startup.sh\n</code></pre>"},{"location":"reference/get_started/install.html#stop-service","title":"Stop service","text":"<p>Stop the service and execute the following script</p> <pre><code>./bin/shutdown.sh\n</code></pre> <p>Note</p> <p>If you want to debug the system, you can use <code>./bin/debug.sh</code> to start the service, but it will stop when you close the window</p>"},{"location":"reference/get_started/install.html#source-installation","title":"Source installation","text":"<p>Warning</p> <p>To manually compile and install DataCap, you need to perform the following steps.</p> <p>The system needs to install <code>JDK</code></p> <ul> <li>Clone the source code to this machine</li> </ul> <pre><code>git clone https://github.com/devlive-community/datacap.git\n</code></pre> <ul> <li>Compile and build the application</li> </ul> <pre><code>./mvnw clean install package -DskipTests -Dgpg.skip\n</code></pre> <p>Warning</p> <p>After compiling, the <code>datacap-release.tar.gz</code> package will be generated in the <code>dist</code> directory.</p> <p>Use the relevant packages to install it.</p> <p>Note</p> <p>If you do not want to install to the local software directory, you can use the following documents to start the development mode for software use.</p> <p>Developer</p>"},{"location":"reference/get_started/install_containers.html","title":"Deploying in a Docker container","text":"<p>The DataCap project provides the qianmoq/datacap Docker image that includes the DataCap server and a default configuration. The Docker image is published to Docker Hub and can be used with the Docker runtime, among several others.</p>"},{"location":"reference/get_started/install_containers.html#running-the-container","title":"Running the container","text":"<p>To run DataCap in Docker, you must have the Docker engine installed on your machine. You can download Docker from the Docker website, or use the packaging system of your operating systems.</p> <p>Use the docker command to create a container from the qianmoq/datacap image. Assign it the datacap name, to make it easier to reference it later. Run it in the background, and map the default DataCap port, which is <code>9096</code>, from inside the container to port <code>9096</code> on your workstation.</p> <pre><code>docker run -d -p 9909:9096 --name datacap qianmoq/datacap\n</code></pre> <p>Without specifying the container image tag, it defaults to <code>latest</code>, but a number of any released DataCap version can be used, for example <code>qianmoq/datacap:1.8.0</code>.</p> <p>Run <code>docker ps</code> to see all the containers running in the background.</p> <pre><code>-&gt; % docker ps\nCONTAINER ID   IMAGE                    COMMAND               CREATED      STATUS          PORTS                    NAMES\n2096fba19e2a   datacap:latest           \"sh ./bin/debug.sh\"   5 days ago   Up 14 seconds   0.0.0.0:9909-&gt;9096/tcp   datacap\n</code></pre>"},{"location":"reference/get_started/install_containers.html#cleaning-up","title":"Cleaning up","text":"<p>You can stop and start the container, using the <code>docker stop datacap</code> and <code>docker start datacap</code> commands. To fully remove the stopped container, run <code>docker rm datacap</code>.</p>"},{"location":"reference/get_started/install_rainbond.html","title":"Deploying in Rainbond","text":"<p>If you are unfamiliar with Kubernetes, and want to install DataCap in Kubernetes, you can use Rainbond to deploy. Rainbond is a cloud-native application management platform built on Kubernetes and simplifies the application deployment to Kubernetes.</p>"},{"location":"reference/get_started/install_rainbond.html#prerequisite","title":"Prerequisite","text":"<p>To install Rainbond, please refer to Rainbond Quick Install.</p>"},{"location":"reference/get_started/install_rainbond.html#deploy-datacap","title":"Deploy DataCap","text":"<p>DataCap has been released to the Rainbond Open Source App Store, DataCap can be deployed with one click through the Rainbond Open Source App Store.</p> <p>Go to the Rainbond Console's <code>Platform Management -&gt; App Marketplace -&gt; Open Source App Store</code> and search for <code>datacap</code> and install it.</p> <p></p> <p>Fill in the following information, and click <code>Confirm</code> button to install.</p> <ul> <li>Team: select a team or create a new team</li> <li>Cluster: select a cluster</li> <li>Application: select an application or create a new application</li> <li>Version: select a version</li> </ul> <p>After installation, DataCap can be accessed through the default domain name provided by Rainbond, Default user password <code>admin/12345678</code></p> <p></p>"},{"location":"reference/get_started/query.html","title":"Query","text":"<p>After entering the software UI interface, click the <code>Query</code> menu option at the top, and you will enter a page similar to the following:</p> <p></p>"},{"location":"reference/get_started/query.html#description","title":"Description","text":"<p>The query page is divided into two parts: the upper part is the SQL editor, and the lower part is the query result</p> <p></p> <p>There are 4 function boxes at the top of the editor, they are:</p> <ul> <li>The first one: <code>selection box</code> is used to select the data source we have created</li> <li>The second: <code>button</code> is to perform the operation</li> <li>The third: <code>button</code> is to format the SQL content we entered</li> <li>The fourth: <code>button</code> is used to cancel the query that takes too long to execute</li> </ul> <p>Danger</p> <p>The cancel function does not mean that the actual query is over, and the query will continue to run in the background.</p>"},{"location":"reference/get_started/query.html#example","title":"Example","text":"<p>We use the following SQL for testing</p> <pre><code>show databases\n</code></pre> <p>After we write the SQL into the editor, click the second function button at the top of the editor to run it. After running, a window similar to the following will be displayed:</p> <p></p> <p>The result window is divided into: the top menu is the data export function, which currently supports <code>CSV</code> export, and the lower part is the data result display.</p> <p>Note</p> <p>The specific result display content is returned according to the SQL query by the user</p>"},{"location":"reference/get_started/query.html#data-output","title":"Data output","text":"<p>Move the mouse to the top menu of the result display area, and a drop-down box will appear. Click the type to be exported, and a download dialog box will pop up, and the data can be downloaded to the local.</p>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html","title":"SHOW CONSUMERS","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW CONSUMERS\nSHOW CONSUMERS FROM topic\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_consumers.html#description","title":"Description","text":"<p>Returns a list of all defined consumers in the current cluster (if a topic is specified, a list of consumers for the specified topic will be returned). Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html","title":"SHOW DATABASES","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW DATABASES\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_databases.html#description","title":"Description","text":"<p>Returns a list of all defined topics in the current cluster. Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html","title":"SHOW TABLES","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW TABLES\nSHOW TABLES FROM `database`\n</code></pre> <p><code>database</code> kafka topic name</p>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_tables.html#description","title":"Description","text":"<p>Returns a list of all defined consumers in the current cluster (if a topic is specified, a list of consumers for the specified topic will be returned). Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html","title":"SHOW TOPICS","text":""},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html#synopsis","title":"Synopsis","text":"<pre><code>SHOW TOPICS\n</code></pre>"},{"location":"reference/sql_syntax/connectors/native/kafka/show_topics.html#description","title":"Description","text":"<p>Returns a list of all defined topics in the current cluster. Returns NULL for any information that is not populated or unavailable on the data source.</p> <p>The list data is returned as a row of each column, and the default header is <code>*</code>.</p> Column Description Notes <code>*</code> The name of the column <code>NULL</code> in the table summary row"},{"location":"release/1.0.0.20221015.html","title":"1.0.0.20221015","text":"<p>Note</p> <p>This is the first new version we've released.</p> <p> DataCap is released </p> Release Version Release Time <code>1.0.0.20221015</code> <code>2022-10-15</code>"},{"location":"release/1.0.0.20221015.html#general","title":"General","text":"<ul> <li>Building SPI supports multiple data sources</li> <li>Supports web visualization based on Vue architecture</li> <li>Support Data source usage history</li> <li>Data statistics for data sources and history</li> </ul>"},{"location":"release/1.0.0.20221015.html#plugins","title":"Plugins","text":"<ul> <li> Support ClickHouse</li> <li> Support MySQL</li> <li> Support Presto</li> <li> Support Redis</li> <li> Support PostgreSQL</li> <li> Support Trino</li> <li> Support ElasticSearch</li> <li> Support Apache Druid</li> <li> Support Apache Kyuubi</li> <li> Support Apache Hive</li> <li> Support Apache Kylin</li> <li> Support Apache Ignite</li> <li> Support IBM DB2</li> </ul>"},{"location":"release/1.0.0.20221015.html#thank-you","title":"Thank you","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @mlboy @qianmoQ"},{"location":"release/1.1.0.20221115.html","title":"1.1.0.20221115","text":"<p>Note</p> <p>The current release involves several major updates. The following link is Roadmap</p> <p> DataCap is released </p> Release Version Release Time <code>1.1.0.20221115</code> <code>2022-11-15</code>"},{"location":"release/1.1.0.20221115.html#general","title":"General","text":"<ul> <li>Replace plugin name to id</li> <li>Support for internationalization issues-82</li> <li>Reduce size of docker image</li> <li>Switch bash docker image to eclipse-temurin:8-jdk-focal</li> <li>Support ssl issues-75</li> <li>Extract the plug-in to get the global tool</li> <li>Support database write operation issues-70</li> <li>Supports user rights management</li> <li>Support code snippet issues-74</li> <li>Support editor auto completion</li> <li>Support to provide data source schema tree bar issues-106</li> <li>Support multiple editor issues-110</li> <li>Add profile for user</li> <li>Support change user password</li> <li>Add data source radar map within 7 days</li> <li>Add about page</li> <li>Add feedback issues-126</li> </ul>"},{"location":"release/1.1.0.20221115.html#spi","title":"SPI","text":"<ul> <li>Add custom validator</li> </ul>"},{"location":"release/1.1.0.20221115.html#plugins","title":"Plugins","text":"<ul> <li>Support MongoDB</li> <li>Support Dremio</li> <li>Support HBase jdbc for Phoenix issues-103</li> <li>Support H2</li> <li>Support SqlServer</li> <li>Support Oracle</li> </ul>"},{"location":"release/1.1.0.20221115.html#redis","title":"Redis","text":"<ul> <li>Fix cannot init RedisConnection issues-71</li> </ul>"},{"location":"release/1.1.0.20221115.html#elasticsearch","title":"ElasticSearch","text":"<ul> <li>Update version to <code>7.10.0</code></li> </ul>"},{"location":"release/1.1.0.20221115.html#kyuubi","title":"Kyuubi","text":"<ul> <li>Bump Kyuubi <code>1.6.0-incubating</code></li> </ul>"},{"location":"release/1.1.0.20221115.html#thank-you","title":"Thank you","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @pan3793 @javalover123 @shuangzishuai @GtoCm @why198852 @qianmoQ"},{"location":"release/1.10.0.html","title":"1.10.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.10.0</code> <code>2023-05-30</code>"},{"location":"release/1.10.0.html#general","title":"General","text":"<ul> <li>Fix service start default connection mongo</li> <li>Fixed h2 db update_time and create_time for sql template</li> <li>Improve the H2 metadata management to obtain type</li> <li>Improve the mysql metadata management to obtain type</li> <li>Fixed metadata management data page default to 1</li> <li>Reconstruct the data render table</li> <li>Support column type</li> <li>Add time consuming and view executing SQL</li> <li>Support for selectable totals per page</li> <li>Supports header hint data types</li> <li>Supports replication of selected data results</li> <li>Support for selecting specified column queries</li> <li>Support filter</li> <li>Fixed the default user creation time being null</li> <li>Support Permission</li> <li>Fixed user createTime is null</li> </ul>"},{"location":"release/1.10.0.html#web","title":"Web","text":"<ul> <li>None Network authorization information is not cleared</li> <li>Optimize data management to obtain data</li> <li>Disable warnings output to console</li> <li>Increased editor buffering prompt limit</li> <li>Removes the default collation rule</li> <li>Rename user dashboard path</li> <li>Add dashboard chat style</li> <li>Fix navigation style</li> <li>Add data source load state</li> </ul>"},{"location":"release/1.10.0.html#plugins","title":"Plugins","text":"<ul> <li>Support apache pinot</li> <li>Support mongo community</li> </ul>"},{"location":"release/1.10.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump clickhouse-jdbc from <code>0.3.2-patch9</code> to <code>0.4.6</code></li> <li>Bump oracle-xe from <code>1.17.6</code> to <code>1.18.1</code></li> <li>Bump kyuubi-hive-jdbc-shaded from <code>1.6.0-incubating</code> to <code>1.7.1</code></li> </ul>"},{"location":"release/1.11.0.html","title":"1.11.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.11.0</code> <code>2023-06-13</code>"},{"location":"release/1.11.0.html#general","title":"General","text":"<ul> <li>The number of rows returned by the query history is added</li> <li>Fixed a 404 error on the home page</li> <li>Strip plugins into separate folders</li> </ul>"},{"location":"release/1.11.0.html#web","title":"Web","text":"<ul> <li>Refactor the folder</li> <li>Add menu breadcrumbs</li> <li>Synchronous server routing</li> <li>Add not login page</li> <li>Add source manager route</li> <li>Fixed the callback exception of route construction failure</li> <li>Fix data source type marker exception</li> </ul>"},{"location":"release/1.11.0.html#plugins","title":"Plugins","text":"<ul> <li>Support apache cassandra</li> </ul>"},{"location":"release/1.12.0.html","title":"1.12.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.12.0</code> <code>2023-07-11</code>"},{"location":"release/1.12.0.html#general","title":"General","text":"<ul> <li>Remove log default debug level</li> <li>Split module</li> <li>Fixed depend</li> <li>Support redirect for menu</li> <li>Fixed sql schema</li> <li>Support whether to function menu</li> <li>Replace openai sdk to <code>openai-java-sdk</code></li> <li>Refactor chat</li> </ul>"},{"location":"release/1.12.0.html#web","title":"Web","text":"<ul> <li>Fixed cache not clear, need to click again</li> <li>Fixed an error with invalid token</li> <li>Adds buffer tag name</li> <li>Fixed abnormal profile page using h2 database</li> <li>404 caused by repair service restart</li> </ul>"},{"location":"release/1.13.0.html","title":"1.13.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.13.0</code> <code>2023-08-09</code>"},{"location":"release/1.13.0.html#general","title":"General","text":"<ul> <li>Fixed <code>openai-java-sdk</code> version</li> <li>Add version for source</li> <li>Add a data source scan task</li> <li>Optimized status icon</li> <li>Remove support for built-in H2 database</li> </ul>"},{"location":"release/1.13.0.html#web","title":"Web","text":"<ul> <li>Support text</li> <li>Fix div white-space</li> <li>Added calendar heatmap chinease</li> <li>Fixed data contribution graph error</li> <li>When the data source is not available list disables selection</li> </ul>"},{"location":"release/1.13.0.html#kyuubi","title":"Kyuubi","text":"<ul> <li>Fix unable to execute set syntax sql</li> <li>Fix connection not closed</li> </ul>"},{"location":"release/1.13.0.html#oracle","title":"Oracle","text":"<ul> <li>Support get DBName and TableName</li> </ul>"},{"location":"release/1.13.0.html#clickhouse","title":"Clickhouse","text":"<ul> <li>Fixed no query errors in the <code>default</code> database</li> </ul>"},{"location":"release/1.14.0.html","title":"1.14.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.14.0</code> <code>2023-09-14</code>"},{"location":"release/1.14.0.html#general","title":"General","text":"<ul> <li>Fix the issue where the data source check task returns an empty</li> <li>Add captcha</li> <li>Support login verification code</li> <li>Automatic refresh of verification code failure is supported</li> <li>Support signup verification code</li> <li>Support signup enable</li> <li>Move etc to configure</li> </ul>"},{"location":"release/1.14.0.html#web","title":"Web","text":"<ul> <li>Fixed empty editor destruction exception</li> <li>Global public page adds layout</li> <li>Fixed the profile page error</li> <li>Fixed the abnormal login page style</li> </ul>"},{"location":"release/1.14.0.html#pipeline-apache-seatunnel","title":"Pipeline (Apache Seatunnel)","text":"<ul> <li>Support kafka source and sink</li> <li>Support delete</li> <li>Build pipeline page</li> <li>Support submit</li> <li>Support SWITCH field type</li> <li>Add executor logo</li> <li>Supports traffic limiting queuing</li> <li>Support stop</li> <li>Reset the pipeline when the service restarts</li> <li>Add logging interface and optimize UI</li> <li>Support field description</li> <li>Support field select type</li> <li>Support field checker</li> <li>Support field array</li> <li>Support redis sink</li> <li>Supports specifying the runtime mechanism</li> </ul>"},{"location":"release/1.14.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump com.google.guava:guava from 31.1-jre to 32.1.2-jre</li> <li>Bump org.devlive.sdk:openai-java-sdk from 1.5.0 to 1.9.0</li> <li>Bump com.h2database:h2 from 2.1.214 to 2.2.220</li> <li>Bump org.projectlombok:lombok from 1.18.24 to 1.18.28</li> <li>Bump org.apache.kafka:kafka-clients from 2.8.0 to 2.8.1</li> <li>Bump org.duckdb:duckdb_jdbc from 0.7.0 to 0.8.1</li> <li>Bump com.github.eirslett:frontend-maven-plugin from 1.12.1 to 1.13.4</li> <li>Bump kotlin.version from 1.8.20 to 1.9.10</li> <li>Bump org.sonatype.plugins:nexus-staging-maven-plugin from 1.6 to 1.6.13</li> </ul>"},{"location":"release/1.15.0.html","title":"1.15.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.15.0</code> <code>2023-10-18</code>"},{"location":"release/1.15.0.html#general","title":"General","text":"<ul> <li>Support database synchronization</li> <li>Support table synchronization</li> <li>Support column synchronization</li> <li>Add scheduler history</li> <li>Refactor metadata module</li> <li>Improve SQL files</li> </ul>"},{"location":"release/1.15.0.html#editor","title":"Editor","text":"<ul> <li>Replace <code>monaco</code> to <code>ace</code></li> </ul>"},{"location":"release/1.15.0.html#docs","title":"Docs","text":"<ul> <li>Add deployment documents in Chinese</li> <li>Refine the fragment and data source Chinese documentation</li> </ul>"},{"location":"release/1.2.0.html","title":"1.2.0","text":"<p>Note</p> <p>The current release involves several major updates. The following link is Roadmap</p> <p> DataCap is released </p> Release Version Release Time <code>1.2.0</code> <code>2022-11-30</code>"},{"location":"release/1.2.0.html#general","title":"General","text":"<ul> <li>Support http protocol</li> </ul>"},{"location":"release/1.2.0.html#web","title":"Web","text":"<ul> <li>Support for data result column header hiding (#139)</li> <li>Support data result filtering (#132 #140)</li> <li>Replace <code>@antv/g2</code> to <code>echarts</code></li> <li>Replace <code>ant-design-vue</code> to <code>iview</code></li> <li>Replace <code>@antv/s2</code> to <code>ag-grid</code></li> <li>Optimize about page</li> <li>Optimize not found page</li> <li>Add not authorized page</li> <li>Add version badge</li> <li>Add not network page</li> <li>Support result visual line chart</li> </ul>"},{"location":"release/1.2.0.html#plugins","title":"Plugins","text":"<ul> <li>Support cratedb</li> <li>Support cratedb for http</li> <li>Support dameng</li> <li>Support clickhouse for http</li> <li>Support tdengine for jdbc</li> <li>Support impala for jdbc</li> </ul>"},{"location":"release/1.2.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.3.0.html","title":"1.3.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.3.0</code> <code>2022-12-16</code>"},{"location":"release/1.3.0.html#general","title":"General","text":"<ul> <li>Support change username</li> <li>Support custom sql template</li> <li>Support plugin function</li> <li>Add restart script</li> </ul>"},{"location":"release/1.3.0.html#web","title":"Web","text":"<ul> <li>Optimize the presentation of the data source list</li> <li>Add data source description and prompt</li> <li>Support query history id order</li> <li>Support quote query history</li> </ul>"},{"location":"release/1.3.0.html#plugins","title":"Plugins","text":"<ul> <li>Support oceanbase for jdbc</li> <li>Support redis for native</li> <li>Support neo4j for jdbc</li> <li>Support iotdb for jdbc</li> </ul>"},{"location":"release/1.3.0.html#redis","title":"Redis","text":"<ul> <li>Support auth for native</li> </ul>"},{"location":"release/1.3.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.4.0.html","title":"1.4.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.4.0</code> <code>2023-01-31</code>"},{"location":"release/1.4.0.html#general","title":"General","text":"<ul> <li>Fixed restart script</li> <li>Supports monitor process</li> <li>Do not modify the default system SQL template</li> <li>Fixed plugin template by name</li> <li>Support user login log</li> <li>Refactoring plug-in configuration extraction mode</li> </ul>"},{"location":"release/1.4.0.html#experimental","title":"Experimental","text":"<ul> <li>Support data source manager</li> <li>Add client cli</li> </ul>"},{"location":"release/1.4.0.html#web","title":"Web","text":"<ul> <li>Plug-in ICONS are displayed based on the plug-in type</li> <li>Optimize editor auto prompt</li> <li>Support watermark</li> <li>Templates are not supported for adding data sources</li> <li>Fixed footer link</li> </ul>"},{"location":"release/1.4.0.html#plugins","title":"Plugins","text":"<ul> <li>Support snowflake for jdbc</li> <li>Support ydb for jdbc</li> </ul>"},{"location":"release/1.4.0.html#docs","title":"Docs","text":"<ul> <li>Refactor some docs</li> </ul>"},{"location":"release/1.4.0.html#redis-native","title":"Redis (Native)","text":"<ul> <li>Fixed command multiple parameters</li> </ul>"},{"location":"release/1.4.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ @hometownglory"},{"location":"release/1.5.0.html","title":"1.5.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.5.0</code> <code>2023-02-16</code>"},{"location":"release/1.5.0.html#general","title":"General","text":"<ul> <li>Support dsl query</li> <li>Remove incubator</li> <li>Add sql parser</li> <li>Refactor the module directories</li> <li>Set port default value is 0</li> </ul>"},{"location":"release/1.5.0.html#spi","title":"SPI","text":"<ul> <li>Fixed jdbc no password exception is configured</li> </ul>"},{"location":"release/1.5.0.html#web","title":"Web","text":"<ul> <li>Support multi column sort</li> </ul>"},{"location":"release/1.5.0.html#plugins","title":"Plugins","text":"<ul> <li>Support zookeeper for native</li> </ul>"},{"location":"release/1.5.0.html#docs","title":"Docs","text":"<ul> <li>Add powered by page</li> </ul>"},{"location":"release/1.5.0.html#redis-native","title":"Redis (Native)","text":"<ul> <li>Fixed mget,hget value is displayed as null #219</li> </ul>"},{"location":"release/1.5.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump maven-javadoc-plugin from 2.10.4 to 3.4.1</li> <li>Bump ojdbc8 from 21.1.0.0 to 21.9.0.0</li> <li>Bump mongodb-jdbc from 2.0.0 to 2.0.2</li> </ul>"},{"location":"release/1.5.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.6.0.html","title":"1.6.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.6.0</code> <code>2023-03-02</code>"},{"location":"release/1.6.0.html#general","title":"General","text":"<ul> <li>Add logo</li> <li>Support <code>SHOW PATHS xxx</code></li> <li>Fixed function time field</li> <li>Refactor all module</li> <li>Add http lib</li> <li>Add logger lib</li> </ul>"},{"location":"release/1.6.0.html#spi","title":"SPI","text":"<ul> <li>JDBC: Repair Connection failure Do not close the connection</li> </ul>"},{"location":"release/1.6.0.html#web","title":"Web","text":"<ul> <li>Add default watermark</li> <li>Remove about page</li> <li>Add routing permission control</li> <li>Optimize lazy loading of the tree menu of the query page</li> </ul>"},{"location":"release/1.6.0.html#plugins","title":"Plugins","text":"<ul> <li>Support duckdb for jdbc close #249</li> <li>Support alioss for native #250</li> </ul>"},{"location":"release/1.6.0.html#zookeeper-native","title":"Zookeeper (Native)","text":"<ul> <li>Support <code>SHOW PATHS</code></li> </ul>"},{"location":"release/1.6.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump maven-javadoc-plugin from <code>3.4.1</code> to <code>3.5.1</code></li> <li>Bump oceanbas-client from <code>2.4.0</code> to <code>2.4.2</code></li> </ul>"},{"location":"release/1.6.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @why198852 @mlboy @qianmoQ"},{"location":"release/1.7.0.html","title":"1.7.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.7.0</code> <code>2023-03-20</code>"},{"location":"release/1.7.0.html#general","title":"General","text":"<ul> <li>Add other issues template</li> <li>Add role</li> <li>Upgrade JDK <code>8</code> to <code>11</code></li> <li>Support chatgpt</li> <li>Add submit pipeline api</li> </ul>"},{"location":"release/1.7.0.html#experimental","title":"Experimental","text":"<ul> <li>Add seatunnel executor</li> </ul>"},{"location":"release/1.7.0.html#client","title":"Client","text":"<ul> <li>Support execute sql on source</li> <li>Fixed code bugs</li> </ul>"},{"location":"release/1.7.0.html#docs","title":"Docs","text":"<ul> <li>Add icon to connectors</li> </ul>"},{"location":"release/1.7.0.html#spi","title":"SPI","text":"<ul> <li>Add executor spi</li> </ul>"},{"location":"release/1.7.0.html#web","title":"Web","text":"<ul> <li>Fixed duplicate tree menu data</li> <li>Optimized type display icon</li> <li>Optimize data source testing\uff5csave interaction</li> <li>Support query history display plug-in type</li> <li>Add system announcement display</li> <li>Fixed the 'keyword' is repeated with tab page addition bug #208</li> <li>Replace markdown preview component</li> </ul>"},{"location":"release/1.7.0.html#plugins","title":"Plugins","text":"<ul> <li>Support kafka</li> </ul>"},{"location":"release/1.7.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Upgrade redis version from <code>3.6.3</code> to <code>4.3.1</code></li> <li>Bump maven-assembly-plugin from <code>3.1.1</code> to <code>3.5.0</code> #272</li> <li>Bump antlr4.version from <code>4.9.3</code> to <code>4.12.0</code> #262</li> <li>Bump jedis from <code>3.6.3</code> to <code>4.3.1</code> #254</li> <li>Bump DmJdbcDriver18 from <code>8.1.2.141</code> to <code>8.1.2.192</code> #234</li> </ul>"},{"location":"release/1.7.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @why198852 @Stacey1018 @qianmoQ"},{"location":"release/1.8.0.html","title":"1.8.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.8.0</code> <code>2023-04-10</code>"},{"location":"release/1.8.0.html#general","title":"General","text":"<ul> <li>Rename executor directory</li> <li>Optimize document release timing</li> <li>Fixed format connect url close #304</li> <li>Support proxy for chatgpt close #299</li> <li>ChatGPT is currently unable to associate context close #298</li> <li>Support returning parsing error results</li> <li>Add schedule lib</li> <li>Support the code editor supports automatic prompts for data source library tables and columns close #301</li> <li>Fix initialization sql script</li> <li>Support h2 database</li> <li>Remove some invalid jars</li> <li>Add docker publish ci</li> </ul>"},{"location":"release/1.8.0.html#docs","title":"Docs","text":"<ul> <li>Refactor install docs</li> </ul>"},{"location":"release/1.8.0.html#web","title":"Web","text":"<ul> <li>The code editor supports code fragments close #300</li> </ul>"},{"location":"release/1.8.0.html#plugins","title":"Plugins","text":"<ul> <li>Support h2 for native (memory)</li> </ul>"},{"location":"release/1.8.0.html#kafka","title":"Kafka","text":"<ul> <li>Perfect test case</li> <li>Support <code>SHOW DATABASES</code> and <code>SHOW TABLES</code> ...</li> </ul>"},{"location":"release/1.8.0.html#oracle","title":"Oracle","text":"<ul> <li>Fixed validation sql content</li> </ul>"},{"location":"release/1.8.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump jackson.version from <code>2.13.4</code> to <code>2.14.2</code></li> <li>Bump postgresql from <code>42.5.0</code> to <code>42.6.0</code></li> </ul>"},{"location":"release/1.8.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/1.9.0.html","title":"1.9.0","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p> DataCap is released </p> Release Version Release Time <code>1.9.0</code> <code>2023-05-04</code>"},{"location":"release/1.9.0.html#general","title":"General","text":"<ul> <li>Support github publish packages</li> <li>Optimized the docker image publishing process</li> <li>Support format date</li> <li>Add a connection to the database to specify the time zone</li> <li>Fixed default h2 database uninitialized scheduled task</li> <li>Add admin user to README.md</li> <li>Add docker image label</li> <li>Add wechat qr to README.md</li> <li>Add docker badge</li> <li>Fixed source create time is null</li> </ul>"},{"location":"release/1.9.0.html#docs","title":"Docs","text":"<ul> <li>Add chinese index</li> <li>Add the Rainbond deployment document</li> <li>Add plugin docs</li> <li>Top scrolling notifications are supported</li> </ul>"},{"location":"release/1.9.0.html#web","title":"Web","text":"<ul> <li>Fix invalid paging of data table</li> <li>Fixed not rendering properly</li> <li>Fix missing translation results for rendering containing translational data</li> <li>Support copy multiple selection rows</li> <li>Fix data source test status issues</li> <li>Support close message</li> <li>Add schedule link</li> </ul>"},{"location":"release/1.9.0.html#plugins","title":"Plugins","text":"<ul> <li>Support ceresdb</li> <li>Support greptimedb</li> <li>Support questdb</li> <li>Support apache doris</li> <li>Support starrocks</li> <li>Support hologres</li> <li>Support apache hadoop hdfs</li> </ul>"},{"location":"release/1.9.0.html#spi","title":"SPI","text":"<ul> <li>Remove http retry logic</li> </ul>"},{"location":"release/1.9.0.html#yandex-database","title":"Yandex Database","text":"<ul> <li>Fixed ydb dependency conflicts</li> </ul>"},{"location":"release/1.9.0.html#trino","title":"Trino","text":"<ul> <li>Add configure</li> </ul>"},{"location":"release/1.9.0.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump trino-jdbc from <code>397</code> to <code>414</code> (#331)</li> <li>Bump iotdb-jdbc from <code>0.13.0</code> to <code>1.1.0</code> (#309)</li> </ul>"},{"location":"release/1.9.0.html#contributors","title":"Contributors","text":"<p>Danger</p> <p>Many thanks to the following contributors for contributing to the source code of this release</p> <p>In no particular order</p> GitHub ID @qianmoQ"},{"location":"release/latest.html","title":"1.16.0 (latest)","text":"<p>Note</p> <p>The current release involves several major updates.</p> <p>DataCap is released!</p> Release Version Release Time <code>1.16.0</code> <code>2023-11-01</code>"},{"location":"release/latest.html#general","title":"General","text":"<ul> <li>Support column order </li> <li>Support delete rows</li> <li>Support delete multiple rows </li> <li>Supports data update without primary key </li> <li>Supports data update with primary key </li> <li>Support preview pending changes</li> </ul>"},{"location":"release/latest.html#editor","title":"Editor","text":"<ul> <li>Support selection query </li> <li>Support custom configure </li> </ul>"},{"location":"release/latest.html#docs","title":"Docs","text":"<ul> <li>Add user profile doc</li> </ul>"},{"location":"release/latest.html#dependencies","title":"Dependencies","text":"<ul> <li>Bump org.apache.maven.plugins:maven-javadoc-plugin from <code>3.5.0</code> to <code>3.6.0</code></li> <li>Bump com.oceanbase:oceanbase-client from <code>2.4.2</code> to <code>2.4.5</code></li> <li>Bump org.apache.maven.plugins:maven-javadoc-plugin from <code>3.5.0</code> to <code>3.6.0</code></li> </ul>"},{"location":"resources/functions/home.html","title":"Functions","text":"<ul> <li> <p>ClickHouse</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>MySQL</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>Hive</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> <li> <p>Trino &amp; Presto</p> <ul> <li>Keywords</li> <li>Functions</li> <li>Operators</li> </ul> </li> </ul>"}]}